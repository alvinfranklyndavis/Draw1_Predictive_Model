{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQTBRTuhcDSb3DbnRRQh5Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvinfranklyndavis/Project2023_v3/blob/main/Data_Prep_GPT_4_Bard_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1.1: Package Installation and Library Import\n",
        "\n",
        "# Upgrade pip and install required packages\n",
        "!pip install -U --upgrade-strategy eager pip\n",
        "!pip install -U --upgrade-strategy eager pandas numpy\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plnc-ffhAUCk",
        "outputId": "22800cfd-05f2-4a0d-cfb7-e04431f93c99"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.2: Data Loading from Google Drive and preprocessing Training / Testing dataset\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the directory for datasets in Google Drive\n",
        "drive_dataset_directory = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/'\n",
        "\n",
        "# Define the paths to the CSV files\n",
        "csv_filename_train_test = 'A_Initial_Train_Test_Data.csv'\n",
        "csv_filename_unseen = 'B_Initial_Unseen_Data.csv'\n",
        "\n",
        "drive_csv_path_train_test = os.path.join(drive_dataset_directory, csv_filename_train_test)\n",
        "drive_csv_path_unseen = os.path.join(drive_dataset_directory, csv_filename_unseen)\n",
        "\n",
        "# Check and load the datasets\n",
        "def load_dataset(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        print(\"File found. Proceeding to load the dataset.\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"File not found. Check the file path or the Google Drive mount.\")\n",
        "        return None\n",
        "\n",
        "train_test_data = load_dataset(drive_csv_path_train_test)\n",
        "unseen_data = load_dataset(drive_csv_path_unseen)\n"
      ],
      "metadata": {
        "id": "fP_Q74gUBGQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e503845-3344-4cbf-b9d7-d0add0c84386"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.3: Preprocessing Training/Testing Data\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Function to preprocess training/testing data\n",
        "def preprocess_train_test_data(data):\n",
        "    print(\"Initial data columns:\", data.columns)\n",
        "\n",
        "    # Remove rows where 'Draw1' is NaN\n",
        "    data = data.dropna(subset=['Draw1'])\n",
        "\n",
        "    # Convert 'Date' to datetime with the correct format\n",
        "    if 'Date' in data.columns:\n",
        "        print(\"Converting 'Date' to datetime...\")\n",
        "        data['Date'] = pd.to_datetime(data['Date'], format='%d-%m-%y')  # Specify the correct format here\n",
        "        data['Year'] = data['Date'].dt.year\n",
        "        data['Month'] = data['Date'].dt.month\n",
        "        data['Day'] = data['Date'].dt.day\n",
        "        print(\"After extracting Year, Month, Day:\", data.columns)\n",
        "        data.drop(columns=['Date'], inplace=True)\n",
        "        print(\"After dropping 'Date':\", data.columns)\n",
        "    else:\n",
        "        print(\"Date column not found in the given dataset.\")\n",
        "\n",
        "    # Initialize TARGET VARIABLE 'Prediction1' column with 'Draw1' values\n",
        "    data['Prediction1'] = data['Draw1']\n",
        "\n",
        "    # Create shifted columns for previous day's data\n",
        "    data['Prev_Morning'] = data['Draw1'].shift(1)\n",
        "    data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
        "    data['Prev_Evening'] = data['Draw3'].shift(1)\n",
        "    data['Prev_Night'] = data['Draw4'].shift(1)\n",
        "\n",
        "    # Handle NaN values\n",
        "    data['Prev_Morning'].fillna(13, inplace=True)\n",
        "    data['Prev_Afternoon'].fillna(34, inplace=True)\n",
        "    data['Prev_Evening'].fillna(32, inplace=True)\n",
        "    data['Prev_Night'].fillna(23, inplace=True)\n",
        "\n",
        "    # Select relevant columns, including 'Prediction1'\n",
        "    selected_columns = ['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
        "    'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night', 'Prediction1', 'Year', 'Month', 'Day']\n",
        "    data = data[selected_columns]\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply preprocessing to the training/testing dataset\n",
        "train_test_data = preprocess_train_test_data(train_test_data)\n",
        "\n",
        "# Save the preprocessed training/testing data to a temporary location\n",
        "temp_save_path = '/content/C_Preprocessed_Train_Test_Data.csv'\n",
        "train_test_data.to_csv(temp_save_path, index=False)\n",
        "\n",
        "# Move the saved CSV to your Google Drive folder\n",
        "save_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/'\n",
        "shutil.move(temp_save_path, os.path.join(save_path, 'C_Preprocessed_Train_Test_Data.csv'))\n",
        "\n",
        "# Display the first few rows of the preprocessed data for verification\n",
        "print(\"First few rows of preprocessed training/testing data:\")\n",
        "print(train_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aARJ03VjGuJY",
        "outputId": "3fc1b0e0-3b0b-434a-c4ed-665243749efa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial data columns: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg'],\n",
            "      dtype='object')\n",
            "Converting 'Date' to datetime...\n",
            "After extracting Year, Month, Day: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg', 'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "After dropping 'Date': Index(['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
            "       'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
            "       'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks', 'DR2_Prev_Entry',\n",
            "       'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg', 'Draw3',\n",
            "       'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry', 'DR3_Prev_Entry-2',\n",
            "       'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4', 'DR4_Prev_Week', 'DR4_2Weeks',\n",
            "       'DR4_Prev_Entry', 'DR4_Prev_Entry-2', 'DR4_Mov_Avg', 'DR4_Vert_Avg',\n",
            "       'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "First few rows of preprocessed training/testing data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training   19.0            7.0        27.0            23.0   \n",
            "1           2  Training   31.0           11.0         1.0             9.0   \n",
            "2           3  Training   15.0           19.0        21.0            12.0   \n",
            "3           4  Training   31.0           35.0        18.0            35.0   \n",
            "5           6  Training   31.0           18.0        22.0            16.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Prev_Morning  Prev_Afternoon  \\\n",
            "0              32.0         27.5          17.0          13.0            34.0   \n",
            "1              33.0         21.0           6.0          19.0            14.0   \n",
            "2              35.0         23.5          20.0          31.0             3.0   \n",
            "3              23.0         29.0          26.5          15.0             9.0   \n",
            "5              29.0         22.5          20.0          31.0            21.0   \n",
            "\n",
            "   Prev_Evening  Prev_Night  Prediction1  Year  Month  Day  \n",
            "0          32.0        23.0         19.0  2018      8    1  \n",
            "1          33.0         9.0         31.0  2018      8    2  \n",
            "2          35.0        12.0         15.0  2018      8    3  \n",
            "3          23.0        35.0         31.0  2018      8    4  \n",
            "5          29.0        16.0         31.0  2018      8    6  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-4376b41f1bd2>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Date'] = pd.to_datetime(data['Date'], format='%d-%m-%y')  # Specify the correct format here\n",
            "<ipython-input-12-4376b41f1bd2>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Year'] = data['Date'].dt.year\n",
            "<ipython-input-12-4376b41f1bd2>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Month'] = data['Date'].dt.month\n",
            "<ipython-input-12-4376b41f1bd2>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Day'] = data['Date'].dt.day\n",
            "<ipython-input-12-4376b41f1bd2>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.drop(columns=['Date'], inplace=True)\n",
            "<ipython-input-12-4376b41f1bd2>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prediction1'] = data['Draw1']\n",
            "<ipython-input-12-4376b41f1bd2>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Morning'] = data['Draw1'].shift(1)\n",
            "<ipython-input-12-4376b41f1bd2>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
            "<ipython-input-12-4376b41f1bd2>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Evening'] = data['Draw3'].shift(1)\n",
            "<ipython-input-12-4376b41f1bd2>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Night'] = data['Draw4'].shift(1)\n",
            "<ipython-input-12-4376b41f1bd2>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Morning'].fillna(13, inplace=True)\n",
            "<ipython-input-12-4376b41f1bd2>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Afternoon'].fillna(34, inplace=True)\n",
            "<ipython-input-12-4376b41f1bd2>:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Evening'].fillna(32, inplace=True)\n",
            "<ipython-input-12-4376b41f1bd2>:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Night'].fillna(23, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.4: Preprocessing Model Unseen Data\n",
        "\n",
        "# Define the path to the CSV file for model unseen data\n",
        "csv_filename_unseen = 'B_Initial_Unseen_Data.csv'\n",
        "drive_csv_path_unseen = os.path.join(drive_dataset_directory, csv_filename_unseen)\n",
        "\n",
        "# Load the model unseen data\n",
        "model_unseen_data = load_dataset(drive_csv_path_unseen)\n",
        "\n",
        "# Function to preprocess unseen data\n",
        "def preprocess_unseen_data(data):\n",
        "    print(\"Initial data columns:\", data.columns)\n",
        "\n",
        "    # Remove rows where 'Draw1' is NaN\n",
        "    data = data.dropna(subset=['Draw1'])\n",
        "\n",
        "    # Define possible date formats\n",
        "    date_formats = ['%d-%m-%y', '%d/%m/%Y']\n",
        "\n",
        "    # Try to convert 'Date' to datetime with different formats\n",
        "    for date_format in date_formats:\n",
        "        try:\n",
        "            if 'Date' in data.columns:\n",
        "                print(\"Converting 'Date' to datetime...\")\n",
        "                data['Date'] = pd.to_datetime(data['Date'], format=date_format)\n",
        "                data['Year'] = data['Date'].dt.year\n",
        "                data['Month'] = data['Date'].dt.month\n",
        "                data['Day'] = data['Date'].dt.day\n",
        "                print(\"After extracting Year, Month, Day:\", data.columns)\n",
        "                data.drop(columns=['Date'], inplace=True)\n",
        "                print(\"After dropping 'Date':\", data.columns)\n",
        "            else:\n",
        "                print(\"Date column not found in the given dataset.\")\n",
        "\n",
        "            # Initialize TARGET VARIABLE 'Prediction1' column with NaN values\n",
        "            data['Prediction1'] = np.nan\n",
        "\n",
        "            # Create shifted columns for previous day's data\n",
        "            data['Prev_Morning'] = data['Draw1'].shift(1)\n",
        "            data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
        "            data['Prev_Evening'] = data['Draw3'].shift(1)\n",
        "            data['Prev_Night'] = data['Draw4'].shift(1)\n",
        "\n",
        "            # Handle NaN values\n",
        "            data['Prev_Morning'].fillna(25, inplace=True)\n",
        "            data['Prev_Afternoon'].fillna(9, inplace=True)\n",
        "            data['Prev_Evening'].fillna(7, inplace=True)\n",
        "            data['Prev_Night'].fillna(5, inplace=True)\n",
        "\n",
        "            # Select relevant columns, including 'Prediction1'\n",
        "            selected_columns = ['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
        "            'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night', 'Prediction1', 'Year', 'Month', 'Day']\n",
        "            data = data[selected_columns]\n",
        "\n",
        "            # Save the preprocessed model unseen data to a temporary location\n",
        "            temp_save_path = '/content/D_Preprocessed_Unseen_Data.csv'\n",
        "            data.to_csv(temp_save_path, index=False)\n",
        "\n",
        "            # Move the saved CSV to your Google Drive folder\n",
        "            save_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/'\n",
        "            shutil.move(temp_save_path, os.path.join(save_path, 'D_Preprocessed_Unseen_Data.csv'))\n",
        "\n",
        "            # Display the first few rows of the preprocessed data for verification\n",
        "            print(\"First few rows of preprocessed model unseen data:\")\n",
        "            print(data.head())\n",
        "\n",
        "            break  # Break the loop if successful date conversion\n",
        "\n",
        "        except ValueError:\n",
        "            print(\"Failed to convert 'Date' with format:\", date_format)\n",
        "\n",
        "# Apply preprocessing to the model unseen data\n",
        "preprocess_unseen_data(model_unseen_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhcW-7C8XvpW",
        "outputId": "7c1270b6-1856-48be-eeec-971ccb65960b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "Initial data columns: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg'],\n",
            "      dtype='object')\n",
            "Converting 'Date' to datetime...\n",
            "Failed to convert 'Date' with format: %d-%m-%y\n",
            "Converting 'Date' to datetime...\n",
            "After extracting Year, Month, Day: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg', 'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "After dropping 'Date': Index(['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
            "       'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
            "       'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks', 'DR2_Prev_Entry',\n",
            "       'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg', 'Draw3',\n",
            "       'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry', 'DR3_Prev_Entry-2',\n",
            "       'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4', 'DR4_Prev_Week', 'DR4_2Weeks',\n",
            "       'DR4_Prev_Entry', 'DR4_Prev_Entry-2', 'DR4_Mov_Avg', 'DR4_Vert_Avg',\n",
            "       'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "First few rows of preprocessed model unseen data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0        1410    Unseen   13.0           27.0        25.0             5.0   \n",
            "1        1411    Unseen   21.0           33.0        12.0            18.0   \n",
            "2        1412    Unseen   15.0           27.0         3.0            28.0   \n",
            "3        1413    Unseen   13.0           20.0        11.0             2.0   \n",
            "4        1414    Unseen   12.0           29.0        14.0            12.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Prev_Morning  Prev_Afternoon  \\\n",
            "0               7.0          6.0          26.0          25.0             9.0   \n",
            "1              26.0         22.0          22.5          13.0            20.0   \n",
            "2               7.0         17.5          15.0          21.0            31.0   \n",
            "3               2.0          2.0          15.5          15.0             5.0   \n",
            "4              22.0         17.0          21.5          13.0            28.0   \n",
            "\n",
            "   Prev_Evening  Prev_Night  Prediction1  Year  Month  Day  \n",
            "0           7.0         5.0          NaN  2023      8    1  \n",
            "1          26.0        18.0          NaN  2023      8    2  \n",
            "2           7.0        28.0          NaN  2023      8    3  \n",
            "3           2.0         2.0          NaN  2023      8    4  \n",
            "4          22.0        12.0          NaN  2023      8    5  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-ddb4ea59f113>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Date'] = pd.to_datetime(data['Date'], format=date_format)\n",
            "<ipython-input-14-ddb4ea59f113>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Year'] = data['Date'].dt.year\n",
            "<ipython-input-14-ddb4ea59f113>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Month'] = data['Date'].dt.month\n",
            "<ipython-input-14-ddb4ea59f113>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Day'] = data['Date'].dt.day\n",
            "<ipython-input-14-ddb4ea59f113>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.drop(columns=['Date'], inplace=True)\n",
            "<ipython-input-14-ddb4ea59f113>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prediction1'] = np.nan\n",
            "<ipython-input-14-ddb4ea59f113>:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Morning'] = data['Draw1'].shift(1)\n",
            "<ipython-input-14-ddb4ea59f113>:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
            "<ipython-input-14-ddb4ea59f113>:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Evening'] = data['Draw3'].shift(1)\n",
            "<ipython-input-14-ddb4ea59f113>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Night'] = data['Draw4'].shift(1)\n",
            "<ipython-input-14-ddb4ea59f113>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Morning'].fillna(25, inplace=True)\n",
            "<ipython-input-14-ddb4ea59f113>:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Afternoon'].fillna(9, inplace=True)\n",
            "<ipython-input-14-ddb4ea59f113>:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Evening'].fillna(7, inplace=True)\n",
            "<ipython-input-14-ddb4ea59f113>:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Night'].fillna(5, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.1: Creating \"LINES\" feature for Training/Testing and Unseen Datasets\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the path to the CSV file for preprocessed training/testing data\n",
        "preprocessed_train_test_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/C_Preprocessed_Train_Test_Data.csv'\n",
        "\n",
        "# Define the path to the CSV file for preprocessed model unseen data\n",
        "preprocessed_unseen_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/D_Preprocessed_Unseen_Data.csv'\n",
        "\n",
        "# Load preprocessed training/testing data\n",
        "preprocessed_train_test_data = pd.read_csv(preprocessed_train_test_data_path)\n",
        "\n",
        "# Load preprocessed unseen data\n",
        "preprocessed_unseen_data = pd.read_csv(preprocessed_unseen_data_path)\n",
        "\n",
        "# List of columns to convert to integers\n",
        "int_columns = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
        "               'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night']\n",
        "\n",
        "# Convert specified columns to integers for both datasets\n",
        "preprocessed_train_test_data[int_columns] = preprocessed_train_test_data[int_columns].astype(int)\n",
        "preprocessed_unseen_data[int_columns] = preprocessed_unseen_data[int_columns].astype(int)\n",
        "\n",
        "# Function to assign \"Lines\" based on the sum of digits\n",
        "def assign_lines(data, column_name):\n",
        "    def get_lines(x):\n",
        "        try:\n",
        "            # Calculate the sum of digits\n",
        "            sum_of_digits = sum(map(int, str(x)))\n",
        "            # Ensure the sum is between 1 and 9\n",
        "            while sum_of_digits > 9:\n",
        "                sum_of_digits = sum(map(int, str(sum_of_digits)))\n",
        "            return sum_of_digits\n",
        "        except (ValueError, TypeError):\n",
        "            return None  # Handle non-convertible values by returning None\n",
        "\n",
        "    data[f'Lines_{column_name}'] = data[column_name].apply(get_lines)\n",
        "\n",
        "# Handle NaN values in the 'Prediction1' column for unseen data by filling them with 0\n",
        "preprocessed_unseen_data['Prediction1'].fillna(0, inplace=True)\n",
        "\n",
        "# Assign \"Lines\" for specified columns in both datasets\n",
        "columns_to_assign_lines = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "for column in columns_to_assign_lines:\n",
        "    assign_lines(preprocessed_train_test_data, column)\n",
        "    assign_lines(preprocessed_unseen_data, column)\n",
        "\n",
        "# Define file paths for the new CSVs with \"Lines\"\n",
        "lines_train_test_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/E_Lines_Train_Test_Data.csv'\n",
        "lines_unseen_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/F_Lines_Unseen_Data.csv'\n",
        "\n",
        "# Save the datasets with \"Lines\" to new CSVs\n",
        "preprocessed_train_test_data.to_csv(lines_train_test_data_path, index=False)\n",
        "preprocessed_unseen_data.to_csv(lines_unseen_data_path, index=False)\n",
        "\n",
        "# Display a sample of the processed data for verification\n",
        "print(\"Sample of preprocessed training/testing data with 'Lines_Draw1':\")\n",
        "print(preprocessed_train_test_data[['Row Number', 'Draw1', 'Lines_Draw1']].head())\n",
        "\n",
        "print(\"\\nSample of preprocessed unseen data with 'Lines_Draw1':\")\n",
        "print(preprocessed_unseen_data[['Row Number', 'Draw1', 'Lines_Draw1']].head())\n"
      ],
      "metadata": {
        "id": "zwgfUWQo0gEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e45afee-5a45-44c6-f811-1d389f8085f7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of preprocessed training/testing data with 'Lines_Draw1':\n",
            "   Row Number  Draw1  Lines_Draw1\n",
            "0           1     19            1\n",
            "1           2     31            4\n",
            "2           3     15            6\n",
            "3           4     31            4\n",
            "4           6     31            4\n",
            "\n",
            "Sample of preprocessed unseen data with 'Lines_Draw1':\n",
            "   Row Number  Draw1  Lines_Draw1\n",
            "0        1410     13            4\n",
            "1        1411     21            3\n",
            "2        1412     15            6\n",
            "3        1413     13            4\n",
            "4        1414     12            3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "feiR8iFN0hBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.3: Data Loading from Google Drive and Preprocessing Unseen Dataset\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the directory for datasets in Google Drive\n",
        "drive_dataset_directory = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/'\n",
        "\n",
        "# Define the path to the CSV file for unseen data\n",
        "csv_filename_unseen = 'Model_Unseen_Data.csv'\n",
        "drive_csv_path_unseen = os.path.join(drive_dataset_directory, csv_filename_unseen)\n",
        "\n",
        "# Check and load the dataset\n",
        "def load_dataset(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        print(\"File found. Proceeding to load the dataset.\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"File not found. Check the file path or the Google Drive mount.\")\n",
        "        return None\n",
        "\n",
        "unseen_data = load_dataset(drive_csv_path_unseen)\n",
        "\n",
        "# Function to preprocess unseen data\n",
        "def preprocess_unseen_data(data):\n",
        "    print(\"Initial data columns:\", data.columns)\n",
        "\n",
        "    # Convert 'Date' to datetime and extract 'Year', 'Month', and 'Day'\n",
        "    if 'Date' in data.columns:\n",
        "        print(\"Converting 'Date' to datetime...\")\n",
        "        data['Date'] = pd.to_datetime(data['Date'])\n",
        "        data['Year'] = data['Date'].dt.year\n",
        "        data['Month'] = data['Date'].dt.month\n",
        "        data['Day'] = data['Date'].dt.day\n",
        "        print(\"After extracting Year, Month, Day:\", data.columns)\n",
        "        data.drop(columns=['Date'], inplace=True)\n",
        "        print(\"After dropping 'Date':\", data.columns)\n",
        "    else:\n",
        "        print(\"Date column not found in the given dataset.\")\n",
        "\n",
        "    # Initialize 'Prediction1' column with NaNs for unseen data\n",
        "    data['Prediction1'] = np.nan\n",
        "\n",
        "    # Create shifted columns for previous day's data\n",
        "    data['Prev_Morning'] = data['Morning'].shift(1)\n",
        "    data['Prev_Afternoon'] = data['Afternoon'].shift(1)\n",
        "    data['Prev_Evening'] = data['Evening'].shift(1)\n",
        "\n",
        "    # Calculate moving averages excluding current row\n",
        "    initial_window_size = 3  # Increased by 1 to exclude the current row\n",
        "    columns_to_average = ['Morning', 'Afternoon', 'Evening', 'Night']\n",
        "    target_columns = ['Mov_Avg_Mor', 'Mov_Avg_Aft', 'Mov_Avg_Eve', 'Mov_Avg_Nig']\n",
        "\n",
        "    for col, target_col in zip(columns_to_average, target_columns):\n",
        "    # Roll over an additional row and then shift to exclude the current row\n",
        "        data[target_col] = data[col].rolling(window=initial_window_size, min_periods=1).mean().shift(1)\n",
        "    # Manually set the value for the first row\n",
        "    unseen_data.at[0, 'Mov_Avg_Mor'] = 6\n",
        "    unseen_data.at[1, 'Mov_Avg_Mor'] = 22\n",
        "    unseen_data.at[2, 'Mov_Avg_Mor'] = 17.5\n",
        "    unseen_data.at[3, 'Mov_Avg_Mor'] = 2\n",
        "    unseen_data.at[4, 'Mov_Avg_Mor'] = 17\n",
        "\n",
        "    # Calculate vertical averages excluding current row\n",
        "    vertical_target_columns = ['Vert_Avg_Mor', 'Vert_Avg_Aft', 'Vert_Avg_Eve', 'Vert_Avg_Nig']\n",
        "    for col, target_col in zip(columns_to_average, vertical_target_columns):\n",
        "        data[target_col] = data[col].rolling(window=3, min_periods=1).mean().shift(1)\n",
        "\n",
        "    # Handle NaN values\n",
        "    data['Prev_Morning'].fillna(25, inplace=True)\n",
        "    data['Prev_Afternoon'].fillna(9, inplace=True)\n",
        "    data['Prev_Evening'].fillna(7, inplace=True)\n",
        "\n",
        "    # Select relevant columns, including 'Prediction1'\n",
        "    selected_columns = ['Row Number', 'Data_Type', 'Year', 'Month', 'Day', 'Prev_Week', 'Prev_Entry', 'Mov_Avg_Mor', 'Vert_Avg_Mor', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prediction1']\n",
        "    data[selected_columns]\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply preprocessing to the unseen dataset\n",
        "unseen_data = preprocess_unseen_data(unseen_data)\n",
        "\n",
        "# Display the preprocessed unseen data\n",
        "print(\"First few rows of preprocessed unseen data:\")\n",
        "print(unseen_data.head())"
      ],
      "metadata": {
        "id": "WsY7Mvh7Jp1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.4: # Save the preprocessed training/testing dataset\n",
        "preprocessed_train_test_path = os.path.join(drive_dataset_directory, '1_preprocessed_train_test_data.csv')\n",
        "train_test_data.to_csv(preprocessed_train_test_path, index=False)\n",
        "print(\"Preprocessed training/testing data saved to Google Drive.\")\n",
        "\n",
        "# Display the first few rows of the preprocessed training/testing data\n",
        "print(\"First few rows of preprocessed training/testing data:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "# Check for NaN values in the entire dataset\n",
        "nan_counts = train_test_data.isnull().sum()\n",
        "print(\"Count of NaN values in training/testing data:\")\n",
        "print(nan_counts)\n",
        "\n",
        "# Save the preprocessed unseen dataset\n",
        "preprocessed_unseen_path = os.path.join(drive_dataset_directory, '2_preprocessed_unseen_data.csv')\n",
        "unseen_data.to_csv(preprocessed_unseen_path, index=False)\n",
        "print(\"Preprocessed unseen data saved to Google Drive.\")\n",
        "\n",
        "# Display the first few rows of the preprocessed unseen data\n",
        "print(\"First few rows of preprocessed unseen data:\")\n",
        "print(unseen_data.head())\n",
        "\n",
        "# Check for NaN values in the entire dataset\n",
        "nan_counts = unseen_data.isnull().sum()\n",
        "print(\"Count of NaN values in unseen data:\")\n",
        "print(nan_counts)\n"
      ],
      "metadata": {
        "id": "ncZjXqqlHgvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define the directory for datasets in Google Drive\n",
        "drive_dataset_directory = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/'\n",
        "\n",
        "# Define the path to the preprocessed unseen data\n",
        "preprocessed_unseen_path = os.path.join(drive_dataset_directory, '2_preprocessed_unseen_data.csv')\n",
        "\n",
        "# Load the preprocessed unseen data\n",
        "unseen_data = pd.read_csv(preprocessed_unseen_path)\n",
        "logger.info(\"Preprocessed unseen data loaded successfully.\")\n",
        "\n",
        "# Define the provided data for imputation\n",
        "provided_data = [\n",
        "    {\n",
        "        'Row Number': 1410,\n",
        "        'Morning': 13,\n",
        "        'Prev_Week': 27,\n",
        "        '2WeeksM': 25,\n",
        "        'Prev_Entry': 5,\n",
        "        'Prev_Entry-2': 7,\n",
        "        'Mov_Avg_Mor': 6,\n",
        "        'Vert_Avg_Mor': 26,\n",
        "        'Afternoon': 20,\n",
        "        'Prev_Week': 7,\n",
        "        '2WeeksA': 34,\n",
        "        'Prev_Entry': 13,\n",
        "        'Prev_Entry-2': 5,\n",
        "        'Mov_Avg_Aft': 9,\n",
        "        'Vert_Avg_Aft': 20.5,\n",
        "        'Evening': 26,\n",
        "        'Prev_Week': 26,\n",
        "        '2WeeksE': 24,\n",
        "        'Prev_Entry': 20,\n",
        "        'Prev_Entry-2': 13,\n",
        "        'Mov_Avg_Eve': 16.5,\n",
        "        'Vert_Avg_Eve': 25,\n",
        "        'Night': 18,\n",
        "        'Prev_Week': 26,\n",
        "        '2WeeksN': 3,\n",
        "        'Prev_Entry': 26,\n",
        "        'Prev_Entry-2': 20,\n",
        "        'Mov_Avg_Nig': 23,\n",
        "        'Vert_Avg_Nig': 14.5\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1411,\n",
        "        'Morning': 21,\n",
        "        'Prev_Week': 33,\n",
        "        '2WeeksM': 12,\n",
        "        'Prev_Entry': 18,\n",
        "        'Prev_Entry-2': 26,\n",
        "        'Mov_Avg_Mor': 22,\n",
        "        'Vert_Avg_Mor': 22.5,\n",
        "        'Afternoon': 31,\n",
        "        'Prev_Week': 18,\n",
        "        '2WeeksA': 36,\n",
        "        'Prev_Entry': 21,\n",
        "        'Prev_Entry-2': 18,\n",
        "        'Mov_Avg_Aft': 19.5,\n",
        "        'Vert_Avg_Aft': 27,\n",
        "        'Evening': 7,\n",
        "        'Prev_Week': 9,\n",
        "        '2WeeksE': 3,\n",
        "        'Prev_Entry': 31,\n",
        "        'Prev_Entry-2': 21,\n",
        "        'Mov_Avg_Eve': 26,\n",
        "        'Vert_Avg_Eve': 6,\n",
        "        'Night': 28,\n",
        "        'Prev_Week': 8,\n",
        "        '2WeeksN': 5,\n",
        "        'Prev_Entry': 7,\n",
        "        'Prev_Entry-2': 31,\n",
        "        'Mov_Avg_Nig': 19,\n",
        "        'Vert_Avg_Nig': 6.5\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1412,\n",
        "        'Morning': 15,\n",
        "        'Prev_Week': 27,\n",
        "        '2WeeksM': 3,\n",
        "        'Prev_Entry': 28,\n",
        "        'Prev_Entry-2': 7,\n",
        "        'Mov_Avg_Mor': 17.5,\n",
        "        'Vert_Avg_Mor': 15,\n",
        "        'Afternoon': 5,\n",
        "        'Prev_Week': 22,\n",
        "        '2WeeksA': 10,\n",
        "        'Prev_Entry': 15,\n",
        "        'Prev_Entry-2': 28,\n",
        "        'Mov_Avg_Aft': 21.5,\n",
        "        'Vert_Avg_Aft': 16,\n",
        "        'Evening': 2,\n",
        "        'Prev_Week': 32,\n",
        "        '2WeeksE': 4,\n",
        "        'Prev_Entry': 5,\n",
        "        'Prev_Entry-2': 15,\n",
        "        'Mov_Avg_Eve': 10,\n",
        "        'Vert_Avg_Eve': 18,\n",
        "        'Night': 2,\n",
        "        'Prev_Week': 30,\n",
        "        '2WeeksN': 6,\n",
        "        'Prev_Entry': 2,\n",
        "        'Prev_Entry-2': 5,\n",
        "        'Mov_Avg_Nig': 3.5,\n",
        "        'Vert_Avg_Nig': 18\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1413,\n",
        "        'Morning': 13,\n",
        "        'Prev_Week': 20,\n",
        "        '2WeeksM': 11,\n",
        "        'Prev_Entry': 2,\n",
        "        'Prev_Entry-2': 2,\n",
        "        'Mov_Avg_Mor': 2,\n",
        "        'Vert_Avg_Mor': 15.5,\n",
        "        'Row Number': 1413,\n",
        "        'Afternoon': 28,\n",
        "        'Prev_Week': 29,\n",
        "        '2WeeksA': 19,\n",
        "        'Prev_Entry': 13,\n",
        "        'Prev_Entry-2': 2,\n",
        "        'Mov_Avg_Aft': 7.5,\n",
        "        'Vert_Avg_Aft': 24,\n",
        "        'Evening': 22,\n",
        "        'Prev_Week': 23,\n",
        "        '2WeeksE': 29,\n",
        "        'Prev_Entry': 28,\n",
        "        'Prev_Entry-2': 13,\n",
        "        'Mov_Avg_Eve': 20.5,\n",
        "        'Vert_Avg_Eve': 26,\n",
        "        'Night': 12,\n",
        "        'Prev_Week': 2,\n",
        "        '2WeeksN': 7,\n",
        "        'Prev_Entry': 22,\n",
        "        'Prev_Entry-2': 28,\n",
        "        'Mov_Avg_Nig': 25,\n",
        "        'Vert_Avg_Nig': 4.5\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1414,\n",
        "        'Morning': 12,\n",
        "        'Prev_Week': 29,\n",
        "        '2WeeksM': 14,\n",
        "        'Prev_Entry': 12,\n",
        "        'Prev_Entry-2': 22,\n",
        "        'Mov_Avg_Mor': 17,\n",
        "        'Vert_Avg_Mor': 21.5,\n",
        "        'Row Number': 1414,\n",
        "        'Afternoon': 35,\n",
        "        'Prev_Week': 7,\n",
        "        '2WeeksA': 31,\n",
        "        'Prev_Entry': 12,\n",
        "        'Prev_Entry-2': 12,\n",
        "        'Mov_Avg_Aft': 12,\n",
        "        'Vert_Avg_Aft': 19,\n",
        "        'Evening': 31,\n",
        "        'Prev_Week': 5,\n",
        "        '2WeeksE': 32,\n",
        "        'Prev_Entry': 35,\n",
        "        'Prev_Entry-2': 12,\n",
        "        'Mov_Avg_Eve': 23.5,\n",
        "        'Vert_Avg_Eve': 18.5,\n",
        "        'Night': 11,\n",
        "        'Prev_Week': 3,\n",
        "        '2WeeksN': 18,\n",
        "        'Prev_Entry': 31,\n",
        "        'Prev_Entry-2': 35,\n",
        "        'Mov_Avg_Nig': 33,\n",
        "        'Vert_Avg_Nig': 10.5\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1415,\n",
        "        'Morning': 14,\n",
        "        'Prev_Week': 25,\n",
        "        '2WeeksM': 5,\n",
        "        'Prev_Entry': 11,\n",
        "        'Prev_Entry-2': 31,\n",
        "        'Mov_Avg_Mor': 21,\n",
        "        'Vert_Avg_Mor': 15,\n",
        "        'Row Number': 1415,\n",
        "        'Afternoon': 2,\n",
        "        'Prev_Week': 9,\n",
        "        '2WeeksA': 14,\n",
        "        'Prev_Entry': 14,\n",
        "        'Prev_Entry-2': 11,\n",
        "        'Mov_Avg_Aft': 12.5,\n",
        "        'Vert_Avg_Aft': 11.5,\n",
        "        'Evening': 23,\n",
        "        'Prev_Week': 7,\n",
        "        '2WeeksE': 30,\n",
        "        'Prev_Entry': 2,\n",
        "        'Prev_Entry-2': 14,\n",
        "        'Mov_Avg_Eve': 8,\n",
        "        'Vert_Avg_Eve': 18.5,\n",
        "        'Row Number': 1415,\n",
        "        'Night': 25,\n",
        "        'Prev_Week': 5,\n",
        "        '2WeeksN': 22,\n",
        "        'Prev_Entry': 23,\n",
        "        'Prev_Entry-2': 2,\n",
        "        'Mov_Avg_Nig': 12.5,\n",
        "        'Vert_Avg_Nig': 13.5\n",
        "    }\n",
        "]\n",
        "\n",
        "# Iterate through the provided data to update the corresponding columns in the DataFrame\n",
        "for data in provided_data:\n",
        "    row_number = data['Row Number']\n",
        "    for column in data.keys():\n",
        "        if column != 'Row Number':\n",
        "            unseen_data.loc[unseen_data['Row Number'] == row_number, column] = data[column]\n",
        "\n",
        "# Display the dataset after NaN handling\n",
        "print(\"First few rows of unseen data after NaN handling:\")\n",
        "print(unseen_data.head())\n",
        "\n",
        "# Check for NaN values in the entire dataset\n",
        "nan_counts = unseen_data.isnull().sum()\n",
        "print(\"Count of NaN values in unseen data:\")\n",
        "print(nan_counts)\n",
        "\n",
        "# Save the updated unseen data\n",
        "updated_unseen_path = os.path.join(drive_dataset_directory, '2_preprocessed_unseen_data.csv')\n",
        "unseen_data.to_csv(updated_unseen_path, index=False)\n",
        "logger.info(\"Updated unseen data saved successfully.\")\n"
      ],
      "metadata": {
        "id": "Jt0eLKc5qADl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}