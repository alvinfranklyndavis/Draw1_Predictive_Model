{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlmGhtGsuhBvaCQdACEmib",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvinfranklyndavis/Project2023_v3/blob/main/Data_Prep_GPT_4_Bard_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1.1: Package Installation and Library Import\n",
        "\n",
        "# Check for existing libraries\n",
        "!pip show pandas numpy\n",
        "\n",
        "# Install or upgrade required packages\n",
        "!pip install -U --upgrade-strategy eager pip\n",
        "!pip install -U --upgrade-strategy eager pandas==<desired_version> numpy==<desired_version>\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Set up logging to save logs in a file\n",
        "log_file = 'project.log'\n",
        "logging.basicConfig(filename=log_file, level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Set up virtual environment (optional but recommended)\n",
        "# You can create a virtual environment with: !python -m venv myenv\n",
        "# And activate it with: source myenv/bin/activate (Linux/macOS) or myenv\\Scripts\\activate (Windows)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plnc-ffhAUCk",
        "outputId": "b4cc1086-6848-4aae-b74e-90d0b91ce399"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pandas\n",
            "Version: 1.5.3\n",
            "Summary: Powerful data structures for data analysis, time series, and statistics\n",
            "Home-page: https://pandas.pydata.org\n",
            "Author: The Pandas Development Team\n",
            "Author-email: pandas-dev@python.org\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, python-dateutil, pytz\n",
            "Required-by: altair, arviz, bigframes, bokeh, bqplot, cmdstanpy, cufflinks, datascience, db-dtypes, dopamine-rl, fastai, geemap, geopandas, google-colab, gspread-dataframe, holoviews, ibis-framework, lida, mizani, mlxtend, pandas-datareader, pandas-gbq, panel, pins, plotnine, prophet, pymc, seaborn, sklearn-pandas, statsmodels, vega-datasets, xarray, yfinance\n",
            "---\n",
            "Name: numpy\n",
            "Version: 1.23.5\n",
            "Summary: NumPy is the fundamental package for array computing with Python.\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: \n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: albumentations, altair, arviz, astropy, autograd, blis, bokeh, bqplot, chex, cmdstanpy, contourpy, cufflinks, cupy-cuda12x, cvxpy, datascience, db-dtypes, dopamine-rl, ecos, flax, folium, geemap, gensim, gym, h5py, holoviews, hyperopt, ibis-framework, imageio, imbalanced-learn, imgaug, jax, jaxlib, librosa, lida, lightgbm, matplotlib, matplotlib-venn, missingno, mizani, ml-dtypes, mlxtend, moviepy, music21, nibabel, numba, numexpr, opencv-contrib-python, opencv-python, opencv-python-headless, opt-einsum, optax, orbax-checkpoint, osqp, pandas, pandas-gbq, patsy, plotnine, prophet, pyarrow, pycocotools, pyerfa, pymc, pytensor, python-louvain, PyWavelets, qdldl, qudida, scikit-image, scikit-learn, scipy, scs, seaborn, shapely, sklearn-pandas, soxr, spacy, stanio, statsmodels, tables, tensorboard, tensorflow, tensorflow-datasets, tensorflow-hub, tensorflow-probability, tensorstore, thinc, tifffile, torchtext, torchvision, transformers, wordcloud, xarray, xarray-einstats, xgboost, yellowbrick, yfinance\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.2\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `pip install -U --upgrade-strategy eager pandas==<desired_version> numpy==<desired_version>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.2: Data Loading from Google Drive Training / Testing  and Unseen datasets\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the directory for datasets in Google Drive\n",
        "drive_dataset_directory = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/'\n",
        "\n",
        "# Define the paths to the CSV files\n",
        "csv_filename_train_test = 'A_Initial_Train_Test_Data.csv'\n",
        "csv_filename_unseen = 'B_Initial_Unseen_Data.csv'\n",
        "\n",
        "drive_csv_path_train_test = os.path.join(drive_dataset_directory, csv_filename_train_test)\n",
        "drive_csv_path_unseen = os.path.join(drive_dataset_directory, csv_filename_unseen)\n",
        "\n",
        "# Check and load the datasets\n",
        "def load_dataset(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        print(\"File found. Proceeding to load the dataset.\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"File not found. Check the file path or the Google Drive mount.\")\n",
        "        return None\n",
        "\n",
        "# Load training/testing data\n",
        "train_test_data = load_dataset(drive_csv_path_train_test)\n",
        "\n",
        "# Load unseen data\n",
        "unseen_data = load_dataset(drive_csv_path_unseen)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of training/testing data:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data:\")\n",
        "print(unseen_data.head())\n"
      ],
      "metadata": {
        "id": "fP_Q74gUBGQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "065d07d3-39e3-4eb6-feb0-c40b24deb1ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of training/testing data:\n",
            "       Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  01-08-18           1  Training   19.0            7.0        27.0   \n",
            "1  02-08-18           2  Training   31.0           11.0         1.0   \n",
            "2  03-08-18           3  Training   15.0           19.0        21.0   \n",
            "3  04-08-18           4  Training   31.0           35.0        18.0   \n",
            "4  05-08-18           5       NaN    NaN            NaN         NaN   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0            23.0              32.0         27.5          17.0  ...   \n",
            "1             9.0              33.0         21.0           6.0  ...   \n",
            "2            12.0              35.0         23.5          20.0  ...   \n",
            "3            35.0              23.0         29.0          26.5  ...   \n",
            "4             NaN               NaN          NaN           NaN  ...   \n",
            "\n",
            "   DR3_Prev_Entry-2  DR3_Mov_Avg  DR3_Vert_Avg  Draw4  DR4_Prev_Week  \\\n",
            "0              19.0         16.5          15.0    9.0            2.0   \n",
            "1              31.0         17.0          17.0   12.0           35.0   \n",
            "2              15.0         12.0          10.0   35.0           11.0   \n",
            "3              31.0         26.0          23.5   16.0           13.0   \n",
            "4               NaN          NaN           NaN    NaN            NaN   \n",
            "\n",
            "   DR4_2Weeks  DR4_Prev_Entry  DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  \n",
            "0        24.0            33.0              14.0         23.5          13.0  \n",
            "1        26.0            35.0               3.0         19.0          30.5  \n",
            "2        29.0            23.0               9.0         16.0          20.0  \n",
            "3        17.0            29.0              21.0         25.0          15.0  \n",
            "4         NaN             NaN               NaN          NaN           NaN  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "First few rows of unseen data:\n",
            "       Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  1/8/2023        1410    Unseen   13.0           27.0        25.0   \n",
            "1  2/8/2023        1411    Unseen   21.0           33.0        12.0   \n",
            "2  3/8/2023        1412    Unseen   15.0           27.0         3.0   \n",
            "3  4/8/2023        1413    Unseen   13.0           20.0        11.0   \n",
            "4  5/8/2023        1414    Unseen   12.0           29.0        14.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0             5.0               7.0          6.0          26.0  ...   \n",
            "1            18.0              26.0         22.0          22.5  ...   \n",
            "2            28.0               7.0         17.5          15.0  ...   \n",
            "3             2.0               2.0          2.0          15.5  ...   \n",
            "4            12.0              22.0         17.0          21.5  ...   \n",
            "\n",
            "   DR3_Prev_Entry-2  DR3_Mov_Avg  DR3_Vert_Avg  Draw4  DR4_Prev_Week  \\\n",
            "0              13.0         16.5          25.0   18.0           26.0   \n",
            "1              21.0         26.0           6.0   28.0            8.0   \n",
            "2              15.0         10.0          18.0    2.0           30.0   \n",
            "3              13.0         20.5          26.0   12.0            2.0   \n",
            "4              12.0         23.5          18.5   11.0            3.0   \n",
            "\n",
            "   DR4_2Weeks  DR4_Prev_Entry  DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  \n",
            "0         3.0            26.0              20.0         23.0          14.5  \n",
            "1         5.0             7.0              31.0         19.0           6.5  \n",
            "2         6.0             2.0               5.0          3.5          18.0  \n",
            "3         7.0            22.0              28.0         25.0           4.5  \n",
            "4        18.0            31.0              35.0         33.0          10.5  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.3: Surveillance Check for NaNs within both datasets\n",
        "\n",
        "# Check for NaN values in training/testing data\n",
        "print(\"NaN check for training/testing data:\")\n",
        "print(train_test_data.isna().sum())\n",
        "\n",
        "# Check for NaN values in unseen data\n",
        "print(\"\\nNaN check for unseen data:\")\n",
        "print(unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2THl1IOP57A7",
        "outputId": "565d5073-0d03-4a59-88a7-45bb93304185"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN check for training/testing data:\n",
            "Date                  0\n",
            "Row Number            0\n",
            "Data_Type           239\n",
            "Draw1               239\n",
            "DR1_Prev_Week       239\n",
            "DR1_2Weeks          239\n",
            "DR1_Prev_Entry      239\n",
            "DR1_Prev_Entry-2    239\n",
            "DR1_Mov_Avg         239\n",
            "DR1_Vert_Avg        239\n",
            "Draw2               239\n",
            "DR2_Prev_Week       239\n",
            "DR2_2Weeks          239\n",
            "DR2_Prev_Entry      239\n",
            "DR2_Prev_Entry-2    239\n",
            "DR2_Mov_Avg         239\n",
            "DR2_Vert_Avg        239\n",
            "Draw3               239\n",
            "DR3_Prev_Week       239\n",
            "DR3_2Weeks          239\n",
            "DR3_Prev_Entry      239\n",
            "DR3_Prev_Entry-2    239\n",
            "DR3_Mov_Avg         239\n",
            "DR3_Vert_Avg        239\n",
            "Draw4               239\n",
            "DR4_Prev_Week       239\n",
            "DR4_2Weeks          239\n",
            "DR4_Prev_Entry      239\n",
            "DR4_Prev_Entry-2    239\n",
            "DR4_Mov_Avg         239\n",
            "DR4_Vert_Avg        239\n",
            "dtype: int64\n",
            "\n",
            "NaN check for unseen data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           4\n",
            "Draw1               4\n",
            "DR1_Prev_Week       4\n",
            "DR1_2Weeks          4\n",
            "DR1_Prev_Entry      4\n",
            "DR1_Prev_Entry-2    4\n",
            "DR1_Mov_Avg         4\n",
            "DR1_Vert_Avg        4\n",
            "Draw2               4\n",
            "DR2_Prev_Week       4\n",
            "DR2_2Weeks          4\n",
            "DR2_Prev_Entry      4\n",
            "DR2_Prev_Entry-2    4\n",
            "DR2_Mov_Avg         4\n",
            "DR2_Vert_Avg        4\n",
            "Draw3               4\n",
            "DR3_Prev_Week       4\n",
            "DR3_2Weeks          4\n",
            "DR3_Prev_Entry      4\n",
            "DR3_Prev_Entry-2    4\n",
            "DR3_Mov_Avg         4\n",
            "DR3_Vert_Avg        4\n",
            "Draw4               4\n",
            "DR4_Prev_Week       4\n",
            "DR4_2Weeks          4\n",
            "DR4_Prev_Entry      4\n",
            "DR4_Prev_Entry-2    4\n",
            "DR4_Mov_Avg         4\n",
            "DR4_Vert_Avg        4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.1: NaN handling and new CSV saving for Training / Testing  and Unseen datasets\n",
        "\n",
        "\n",
        "# Impute NaN values with zeros in training/testing data\n",
        "train_test_data = train_test_data.fillna(0)\n",
        "\n",
        "# Impute NaN values with zeros in unseen data\n",
        "unseen_data = unseen_data.fillna(0)\n",
        "\n",
        "# Define new CSV file names\n",
        "new_csv_filename_train_test = 'C_NaN_Handled_Train_Test_Data.csv'\n",
        "new_csv_filename_unseen = 'D_NaN_Handled_Unseen_Data.csv'\n",
        "\n",
        "# Define the paths for saving the new CSV files\n",
        "new_csv_path_train_test = os.path.join(drive_dataset_directory, new_csv_filename_train_test)\n",
        "new_csv_path_unseen = os.path.join(drive_dataset_directory, new_csv_filename_unseen)\n",
        "\n",
        "# Save the preprocessed training/testing data as a new CSV file\n",
        "train_test_data.to_csv(new_csv_path_train_test, index=False)\n",
        "\n",
        "# Save the preprocessed unseen data as a new CSV file\n",
        "unseen_data.to_csv(new_csv_path_unseen, index=False)\n",
        "\n",
        "# Print a message to confirm that the preprocessing and saving is complete\n",
        "print(\"Preprocessing and saving of datasets is complete.\")\n",
        "\n",
        "# Check for NaN values in the preprocessed training/testing data\n",
        "print(\"\\nNaN check for preprocessed training/testing data:\")\n",
        "print(train_test_data.isna().sum())\n",
        "\n",
        "# Check for NaN values in the preprocessed unseen data\n",
        "print(\"\\nNaN check for preprocessed unseen data:\")\n",
        "print(unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7QU7JyA8B8b",
        "outputId": "bb05bc20-9233-43eb-9d33-51b216e30b5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing and saving of datasets is complete.\n",
            "\n",
            "NaN check for preprocessed training/testing data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "dtype: int64\n",
            "\n",
            "NaN check for preprocessed unseen data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.2: Extract Y/M/D from Date and new CSV saving for Training / Testing  and Unseen datasets\n",
        "\n",
        "# Load the NaN-handled training/testing data\n",
        "nan_handled_train_test_data = load_dataset(new_csv_path_train_test)\n",
        "\n",
        "# Load the NaN-handled unseen data\n",
        "nan_handled_unseen_data = load_dataset(new_csv_path_unseen)\n",
        "\n",
        "# Check and load the datasets\n",
        "def load_dataset(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        print(\"File found. Proceeding to load the dataset.\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"File not found. Check the file path.\")\n",
        "        return None\n",
        "\n",
        "# Function to extract 'Year', 'Month', and 'Day' from the 'Date' column\n",
        "def extract_date_features(data):\n",
        "    if 'Date' in data.columns:\n",
        "        print(\"Converting 'Date' to datetime and extracting Year, Month, and Day...\")\n",
        "        date_formats = ['%d-%m-%y', '%d/%m/%Y']\n",
        "        for date_format in date_formats:\n",
        "            try:\n",
        "                data['Date'] = pd.to_datetime(data['Date'], format=date_format)\n",
        "                data['Year'] = data['Date'].dt.year.fillna(0).astype(int)\n",
        "                data['Month'] = data['Date'].dt.month.fillna(0).astype(int)\n",
        "                data['Day'] = data['Date'].dt.day.fillna(0).astype(int)\n",
        "                data.drop(columns=['Date'], inplace=True)\n",
        "                print(\"After extracting Year, Month, and Day:\", data.columns)\n",
        "                break  # Break the loop if successful date conversion\n",
        "            except ValueError:\n",
        "                print(f\"Failed to convert 'Date' with format: {date_format}\")\n",
        "    else:\n",
        "        print(\"'Date' column not found in the dataset.\")\n",
        "\n",
        "# Extract 'Year', 'Month', and 'Day' from the 'Date' column in training/testing data\n",
        "extract_date_features(nan_handled_train_test_data)\n",
        "\n",
        "# Extract 'Year', 'Month', and 'Day' from the 'Date' column in unseen data\n",
        "extract_date_features(nan_handled_unseen_data)\n",
        "\n",
        "# Define new CSV file names\n",
        "new_csv_filename_train_test_date = 'E_Date_Extracted_Train_Test_Data.csv'\n",
        "new_csv_filename_unseen_date = 'F_Date_Extracted_Unseen_Data.csv'\n",
        "\n",
        "# Define the paths for saving the new CSV files\n",
        "new_csv_path_train_test_date = os.path.join(drive_dataset_directory, new_csv_filename_train_test_date)\n",
        "new_csv_path_unseen_date = os.path.join(drive_dataset_directory, new_csv_filename_unseen_date)\n",
        "\n",
        "# Save the datasets with extracted date features as new CSV files\n",
        "nan_handled_train_test_data.to_csv(new_csv_path_train_test_date, index=False)\n",
        "nan_handled_unseen_data.to_csv(new_csv_path_unseen_date, index=False)\n",
        "\n",
        "# Print a message to confirm that the date extraction and saving is complete\n",
        "print(\"Date extraction and saving of datasets is complete.\")\n",
        "\n",
        "# Check for NaN values in the datasets with extracted date features\n",
        "print(\"\\nNaN check for training/testing data with extracted date features:\")\n",
        "print(nan_handled_train_test_data.isna().sum())\n",
        "\n",
        "print(\"\\nNaN check for unseen data with extracted date features:\")\n",
        "print(nan_handled_unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEbg8-qg8NiZ",
        "outputId": "3e853dd4-46f6-43c1-f3b0-125561b25ae4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "Converting 'Date' to datetime and extracting Year, Month, and Day...\n",
            "After extracting Year, Month, and Day: Index(['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
            "       'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
            "       'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks', 'DR2_Prev_Entry',\n",
            "       'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg', 'Draw3',\n",
            "       'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry', 'DR3_Prev_Entry-2',\n",
            "       'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4', 'DR4_Prev_Week', 'DR4_2Weeks',\n",
            "       'DR4_Prev_Entry', 'DR4_Prev_Entry-2', 'DR4_Mov_Avg', 'DR4_Vert_Avg',\n",
            "       'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "Converting 'Date' to datetime and extracting Year, Month, and Day...\n",
            "Failed to convert 'Date' with format: %d-%m-%y\n",
            "After extracting Year, Month, and Day: Index(['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
            "       'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
            "       'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks', 'DR2_Prev_Entry',\n",
            "       'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg', 'Draw3',\n",
            "       'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry', 'DR3_Prev_Entry-2',\n",
            "       'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4', 'DR4_Prev_Week', 'DR4_2Weeks',\n",
            "       'DR4_Prev_Entry', 'DR4_Prev_Entry-2', 'DR4_Mov_Avg', 'DR4_Vert_Avg',\n",
            "       'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "Date extraction and saving of datasets is complete.\n",
            "\n",
            "NaN check for training/testing data with extracted date features:\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "dtype: int64\n",
            "\n",
            "NaN check for unseen data with extracted date features:\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.3: Create shifted columns for previous day's data\n",
        "\n",
        "# Function to create shifted columns for previous day's data\n",
        "def create_shifted_columns(data):\n",
        "    data['Prev_Morning'] = data['Draw1'].shift(1)\n",
        "    data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
        "    data['Prev_Evening'] = data['Draw3'].shift(1)\n",
        "    data['Prev_Night'] = data['Draw4'].shift(1)\n",
        "    data[['Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night']] = data[['Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night']].fillna(0).astype(int)\n",
        "\n",
        "# Load the date extracted training/testing data\n",
        "date_extracted_train_test_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/E_Date_Extracted_Train_Test_Data.csv')\n",
        "\n",
        "# Apply the function to create shifted columns\n",
        "create_shifted_columns(date_extracted_train_test_data)\n",
        "\n",
        "# Save the updated training/testing data with shifted columns\n",
        "date_extracted_train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/G_Shifted_Train_Test_Data.csv', index=False)\n",
        "\n",
        "# Load the date extracted unseen data\n",
        "date_extracted_unseen_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/F_Date_Extracted_Unseen_Data.csv')\n",
        "\n",
        "# Apply the function to create shifted columns\n",
        "create_shifted_columns(date_extracted_unseen_data)\n",
        "\n",
        "# Save the updated unseen data with shifted columns\n",
        "date_extracted_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/H_Shifted_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of date extracted training/testing data:\")\n",
        "print(date_extracted_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of date extracted unseen data:\")\n",
        "print(date_extracted_unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YbHzP7wBUY1",
        "outputId": "21a2b09c-94b0-4273-d879-93b4f007284e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of date extracted training/testing data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training   19.0            7.0        27.0            23.0   \n",
            "1           2  Training   31.0           11.0         1.0             9.0   \n",
            "2           3  Training   15.0           19.0        21.0            12.0   \n",
            "3           4  Training   31.0           35.0        18.0            35.0   \n",
            "4           5         0    0.0            0.0         0.0             0.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  DR4_Prev_Entry-2  \\\n",
            "0              32.0         27.5          17.0   14.0  ...              14.0   \n",
            "1              33.0         21.0           6.0    3.0  ...               3.0   \n",
            "2              35.0         23.5          20.0    9.0  ...               9.0   \n",
            "3              23.0         29.0          26.5   21.0  ...              21.0   \n",
            "4               0.0          0.0           0.0    0.0  ...               0.0   \n",
            "\n",
            "   DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  \\\n",
            "0         23.5          13.0  2018      8    1             0               0   \n",
            "1         19.0          30.5  2018      8    2            19              14   \n",
            "2         16.0          20.0  2018      8    3            31               3   \n",
            "3         25.0          15.0  2018      8    4            15               9   \n",
            "4          0.0           0.0  2018      8    5            31              21   \n",
            "\n",
            "   Prev_Evening  Prev_Night  \n",
            "0             0           0  \n",
            "1            33           9  \n",
            "2            35          12  \n",
            "3            23          35  \n",
            "4            29          16  \n",
            "\n",
            "[5 rows x 37 columns]\n",
            "\n",
            "First few rows of date extracted unseen data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0        1410    Unseen   13.0           27.0        25.0             5.0   \n",
            "1        1411    Unseen   21.0           33.0        12.0            18.0   \n",
            "2        1412    Unseen   15.0           27.0         3.0            28.0   \n",
            "3        1413    Unseen   13.0           20.0        11.0             2.0   \n",
            "4        1414    Unseen   12.0           29.0        14.0            12.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  DR4_Prev_Entry-2  \\\n",
            "0               7.0          6.0          26.0   20.0  ...              20.0   \n",
            "1              26.0         22.0          22.5   31.0  ...              31.0   \n",
            "2               7.0         17.5          15.0    5.0  ...               5.0   \n",
            "3               2.0          2.0          15.5   28.0  ...              28.0   \n",
            "4              22.0         17.0          21.5   35.0  ...              35.0   \n",
            "\n",
            "   DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  \\\n",
            "0         23.0          14.5  2023      8    1             0               0   \n",
            "1         19.0           6.5  2023      8    2            13              20   \n",
            "2          3.5          18.0  2023      8    3            21              31   \n",
            "3         25.0           4.5  2023      8    4            15               5   \n",
            "4         33.0          10.5  2023      8    5            13              28   \n",
            "\n",
            "   Prev_Evening  Prev_Night  \n",
            "0             0           0  \n",
            "1            26          18  \n",
            "2             7          28  \n",
            "3             2           2  \n",
            "4            22          12  \n",
            "\n",
            "[5 rows x 37 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.4: Handle NaN values for previous day's data\n",
        "\n",
        "# Load the shifted training/testing data\n",
        "shifted_train_test_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/G_Shifted_Train_Test_Data.csv')\n",
        "\n",
        "# Manually set values for the first row of training/testing set\n",
        "shifted_train_test_data.at[0, 'Prev_Morning'] = 13\n",
        "shifted_train_test_data.at[0, 'Prev_Afternoon'] = 34\n",
        "shifted_train_test_data.at[0, 'Prev_Evening'] = 32\n",
        "shifted_train_test_data.at[0, 'Prev_Night'] = 23\n",
        "\n",
        "# Save the updated training/testing data\n",
        "shifted_train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/I_Handled_Shifted_Train_Test_Data.csv', index=False)\n",
        "\n",
        "# Load the shifted unseen data\n",
        "shifted_unseen_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/H_Shifted_Unseen_Data.csv')\n",
        "\n",
        "# Manually set values for the first row of unseen set\n",
        "shifted_unseen_data.at[0, 'Prev_Morning'] = 25\n",
        "shifted_unseen_data.at[0, 'Prev_Afternoon'] = 9\n",
        "shifted_unseen_data.at[0, 'Prev_Evening'] = 7\n",
        "shifted_unseen_data.at[0, 'Prev_Night'] = 5\n",
        "\n",
        "# Save the updated unseen data\n",
        "shifted_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/J_Handled_Shifted_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of handled shifted training/testing data:\")\n",
        "print(shifted_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of handled shifted unseen data:\")\n",
        "print(shifted_unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8U-4sqFGQXj",
        "outputId": "b58df0fa-8910-4ce2-bfe5-6018e05e580d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of handled shifted training/testing data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training   19.0            7.0        27.0            23.0   \n",
            "1           2  Training   31.0           11.0         1.0             9.0   \n",
            "2           3  Training   15.0           19.0        21.0            12.0   \n",
            "3           4  Training   31.0           35.0        18.0            35.0   \n",
            "4           5         0    0.0            0.0         0.0             0.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  DR4_Prev_Entry-2  \\\n",
            "0              32.0         27.5          17.0   14.0  ...              14.0   \n",
            "1              33.0         21.0           6.0    3.0  ...               3.0   \n",
            "2              35.0         23.5          20.0    9.0  ...               9.0   \n",
            "3              23.0         29.0          26.5   21.0  ...              21.0   \n",
            "4               0.0          0.0           0.0    0.0  ...               0.0   \n",
            "\n",
            "   DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  \\\n",
            "0         23.5          13.0  2018      8    1            13              34   \n",
            "1         19.0          30.5  2018      8    2            19              14   \n",
            "2         16.0          20.0  2018      8    3            31               3   \n",
            "3         25.0          15.0  2018      8    4            15               9   \n",
            "4          0.0           0.0  2018      8    5            31              21   \n",
            "\n",
            "   Prev_Evening  Prev_Night  \n",
            "0            32          23  \n",
            "1            33           9  \n",
            "2            35          12  \n",
            "3            23          35  \n",
            "4            29          16  \n",
            "\n",
            "[5 rows x 37 columns]\n",
            "\n",
            "First few rows of handled shifted unseen data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0        1410    Unseen   13.0           27.0        25.0             5.0   \n",
            "1        1411    Unseen   21.0           33.0        12.0            18.0   \n",
            "2        1412    Unseen   15.0           27.0         3.0            28.0   \n",
            "3        1413    Unseen   13.0           20.0        11.0             2.0   \n",
            "4        1414    Unseen   12.0           29.0        14.0            12.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  DR4_Prev_Entry-2  \\\n",
            "0               7.0          6.0          26.0   20.0  ...              20.0   \n",
            "1              26.0         22.0          22.5   31.0  ...              31.0   \n",
            "2               7.0         17.5          15.0    5.0  ...               5.0   \n",
            "3               2.0          2.0          15.5   28.0  ...              28.0   \n",
            "4              22.0         17.0          21.5   35.0  ...              35.0   \n",
            "\n",
            "   DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  \\\n",
            "0         23.0          14.5  2023      8    1            25               9   \n",
            "1         19.0           6.5  2023      8    2            13              20   \n",
            "2          3.5          18.0  2023      8    3            21              31   \n",
            "3         25.0           4.5  2023      8    4            15               5   \n",
            "4         33.0          10.5  2023      8    5            13              28   \n",
            "\n",
            "   Prev_Evening  Prev_Night  \n",
            "0             7           5  \n",
            "1            26          18  \n",
            "2             7          28  \n",
            "3             2           2  \n",
            "4            22          12  \n",
            "\n",
            "[5 rows x 37 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.1: # Initialize TARGET VARIABLE 'Prediction1' column\n",
        "\n",
        "# Load the handled shifted training/testing data\n",
        "handled_shifted_train_test_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/I_Handled_Shifted_Train_Test_Data.csv')\n",
        "\n",
        "# Set 'Prediction1' column equal to 'Draw1' for training/testing data\n",
        "handled_shifted_train_test_data['Prediction1'] = handled_shifted_train_test_data['Draw1']\n",
        "\n",
        "# Save the updated training/testing data\n",
        "handled_shifted_train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/K_Handled_Prediction1_Train_Test_Data.csv', index=False)\n",
        "\n",
        "# Load the handled shifted unseen data\n",
        "handled_shifted_unseen_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/J_Handled_Shifted_Unseen_Data.csv')\n",
        "\n",
        "# Initialize 'Prediction1' column with NaN values for the unseen data\n",
        "handled_shifted_unseen_data['Prediction1'] = np.nan\n",
        "\n",
        "# Save the updated unseen data\n",
        "handled_shifted_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/L_Handled_Prediction1_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of handled Prediction1 training/testing data:\")\n",
        "print(handled_shifted_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of handled Prediction1 unseen data:\")\n",
        "print(handled_shifted_unseen_data.head())\n"
      ],
      "metadata": {
        "id": "flDRfm_bLNeU",
        "outputId": "ff610d21-c6a3-48f1-81c9-dcaca8bd3496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of handled Prediction1 training/testing data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training   19.0            7.0        27.0            23.0   \n",
            "1           2  Training   31.0           11.0         1.0             9.0   \n",
            "2           3  Training   15.0           19.0        21.0            12.0   \n",
            "3           4  Training   31.0           35.0        18.0            35.0   \n",
            "4           5         0    0.0            0.0         0.0             0.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  DR4_Mov_Avg  \\\n",
            "0              32.0         27.5          17.0   14.0  ...         23.5   \n",
            "1              33.0         21.0           6.0    3.0  ...         19.0   \n",
            "2              35.0         23.5          20.0    9.0  ...         16.0   \n",
            "3              23.0         29.0          26.5   21.0  ...         25.0   \n",
            "4               0.0          0.0           0.0    0.0  ...          0.0   \n",
            "\n",
            "   DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  Prev_Evening  \\\n",
            "0          13.0  2018      8    1            13              34            32   \n",
            "1          30.5  2018      8    2            19              14            33   \n",
            "2          20.0  2018      8    3            31               3            35   \n",
            "3          15.0  2018      8    4            15               9            23   \n",
            "4           0.0  2018      8    5            31              21            29   \n",
            "\n",
            "   Prev_Night  Prediction1  \n",
            "0          23         19.0  \n",
            "1           9         31.0  \n",
            "2          12         15.0  \n",
            "3          35         31.0  \n",
            "4          16          0.0  \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "\n",
            "First few rows of handled Prediction1 unseen data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0        1410    Unseen   13.0           27.0        25.0             5.0   \n",
            "1        1411    Unseen   21.0           33.0        12.0            18.0   \n",
            "2        1412    Unseen   15.0           27.0         3.0            28.0   \n",
            "3        1413    Unseen   13.0           20.0        11.0             2.0   \n",
            "4        1414    Unseen   12.0           29.0        14.0            12.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  DR4_Mov_Avg  \\\n",
            "0               7.0          6.0          26.0   20.0  ...         23.0   \n",
            "1              26.0         22.0          22.5   31.0  ...         19.0   \n",
            "2               7.0         17.5          15.0    5.0  ...          3.5   \n",
            "3               2.0          2.0          15.5   28.0  ...         25.0   \n",
            "4              22.0         17.0          21.5   35.0  ...         33.0   \n",
            "\n",
            "   DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  Prev_Evening  \\\n",
            "0          14.5  2023      8    1            25               9             7   \n",
            "1           6.5  2023      8    2            13              20            26   \n",
            "2          18.0  2023      8    3            21              31             7   \n",
            "3           4.5  2023      8    4            15               5             2   \n",
            "4          10.5  2023      8    5            13              28            22   \n",
            "\n",
            "   Prev_Night  Prediction1  \n",
            "0           5          NaN  \n",
            "1          18          NaN  \n",
            "2          28          NaN  \n",
            "3           2          NaN  \n",
            "4          12          NaN  \n",
            "\n",
            "[5 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "adGQ6YMGOsYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qBmKgOFOskq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dmir-PCQOsw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U8TauDfPOtKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "::::"
      ],
      "metadata": {
        "id": "c7irQ4xrLOIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MYjrY8s4Dz5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.3: Preprocessing Training/Testing Data\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Function to preprocess training/testing data\n",
        "def preprocess_train_test_data(data):\n",
        "    print(\"Initial data columns:\", data.columns)\n",
        "\n",
        "    # Remove rows where 'Draw1' is NaN\n",
        "    data = data.dropna(subset=['Draw1'])\n",
        "\n",
        "    # Convert 'Date' to datetime with the correct format\n",
        "    if 'Date' in data.columns:\n",
        "        print(\"Converting 'Date' to datetime...\")\n",
        "        data['Date'] = pd.to_datetime(data['Date'], format='%d-%m-%y')  # Specify the correct format here\n",
        "        data['Year'] = data['Date'].dt.year\n",
        "        data['Month'] = data['Date'].dt.month\n",
        "        data['Day'] = data['Date'].dt.day\n",
        "        print(\"After extracting Year, Month, Day:\", data.columns)\n",
        "        data.drop(columns=['Date'], inplace=True)\n",
        "        print(\"After dropping 'Date':\", data.columns)\n",
        "    else:\n",
        "        print(\"Date column not found in the given dataset.\")\n",
        "\n",
        "    # Initialize TARGET VARIABLE 'Prediction1' column with 'Draw1' values\n",
        "    data['Prediction1'] = data['Draw1']\n",
        "\n",
        "    # Create shifted columns for previous day's data\n",
        "    data['Prev_Morning'] = data['Draw1'].shift(1)\n",
        "    data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
        "    data['Prev_Evening'] = data['Draw3'].shift(1)\n",
        "    data['Prev_Night'] = data['Draw4'].shift(1)\n",
        "\n",
        "    # Handle NaN values\n",
        "    data['Prev_Morning'].fillna(13, inplace=True)\n",
        "    data['Prev_Afternoon'].fillna(34, inplace=True)\n",
        "    data['Prev_Evening'].fillna(32, inplace=True)\n",
        "    data['Prev_Night'].fillna(23, inplace=True)\n",
        "\n",
        "    # Select relevant columns, including 'Prediction1'\n",
        "    selected_columns = ['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
        "    'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night', 'Prediction1', 'Year', 'Month', 'Day']\n",
        "    data = data[selected_columns]\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply preprocessing to the training/testing dataset\n",
        "train_test_data = preprocess_train_test_data(train_test_data)\n",
        "\n",
        "# Save the preprocessed model training/testing data directly to your Google Drive folder\n",
        "save_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/C_Preprocessed_Train_Test_Data.csv'\n",
        "train_test_data.to_csv(save_path, index=False)\n",
        "\n",
        "# Display the first few rows of the preprocessed data for verification\n",
        "print(\"First few rows of preprocessed training/testing data:\")\n",
        "print(train_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aARJ03VjGuJY",
        "outputId": "8f7528e0-bc41-489e-d9ff-a17c2595ad94"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial data columns: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg'],\n",
            "      dtype='object')\n",
            "Converting 'Date' to datetime...\n",
            "After extracting Year, Month, Day: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg', 'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "After dropping 'Date': Index(['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
            "       'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
            "       'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks', 'DR2_Prev_Entry',\n",
            "       'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg', 'Draw3',\n",
            "       'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry', 'DR3_Prev_Entry-2',\n",
            "       'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4', 'DR4_Prev_Week', 'DR4_2Weeks',\n",
            "       'DR4_Prev_Entry', 'DR4_Prev_Entry-2', 'DR4_Mov_Avg', 'DR4_Vert_Avg',\n",
            "       'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "First few rows of preprocessed training/testing data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training   19.0            7.0        27.0            23.0   \n",
            "1           2  Training   31.0           11.0         1.0             9.0   \n",
            "2           3  Training   15.0           19.0        21.0            12.0   \n",
            "3           4  Training   31.0           35.0        18.0            35.0   \n",
            "5           6  Training   31.0           18.0        22.0            16.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Prev_Morning  Prev_Afternoon  \\\n",
            "0              32.0         27.5          17.0          13.0            34.0   \n",
            "1              33.0         21.0           6.0          19.0            14.0   \n",
            "2              35.0         23.5          20.0          31.0             3.0   \n",
            "3              23.0         29.0          26.5          15.0             9.0   \n",
            "5              29.0         22.5          20.0          31.0            21.0   \n",
            "\n",
            "   Prev_Evening  Prev_Night  Prediction1  Year  Month  Day  \n",
            "0          32.0        23.0         19.0  2018      8    1  \n",
            "1          33.0         9.0         31.0  2018      8    2  \n",
            "2          35.0        12.0         15.0  2018      8    3  \n",
            "3          23.0        35.0         31.0  2018      8    4  \n",
            "5          29.0        16.0         31.0  2018      8    6  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-151e933bb8fa>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Date'] = pd.to_datetime(data['Date'], format='%d-%m-%y')  # Specify the correct format here\n",
            "<ipython-input-69-151e933bb8fa>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Year'] = data['Date'].dt.year\n",
            "<ipython-input-69-151e933bb8fa>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Month'] = data['Date'].dt.month\n",
            "<ipython-input-69-151e933bb8fa>:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Day'] = data['Date'].dt.day\n",
            "<ipython-input-69-151e933bb8fa>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.drop(columns=['Date'], inplace=True)\n",
            "<ipython-input-69-151e933bb8fa>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prediction1'] = data['Draw1']\n",
            "<ipython-input-69-151e933bb8fa>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Morning'] = data['Draw1'].shift(1)\n",
            "<ipython-input-69-151e933bb8fa>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
            "<ipython-input-69-151e933bb8fa>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Evening'] = data['Draw3'].shift(1)\n",
            "<ipython-input-69-151e933bb8fa>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Night'] = data['Draw4'].shift(1)\n",
            "<ipython-input-69-151e933bb8fa>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Morning'].fillna(13, inplace=True)\n",
            "<ipython-input-69-151e933bb8fa>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Afternoon'].fillna(34, inplace=True)\n",
            "<ipython-input-69-151e933bb8fa>:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Evening'].fillna(32, inplace=True)\n",
            "<ipython-input-69-151e933bb8fa>:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Night'].fillna(23, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.4: Preprocessing Model Unseen Data\n",
        "\n",
        "# Define the path to the CSV file for model unseen data\n",
        "csv_filename_unseen = 'B_Initial_Unseen_Data.csv'\n",
        "drive_csv_path_unseen = os.path.join(drive_dataset_directory, csv_filename_unseen)\n",
        "\n",
        "# Load the model unseen data\n",
        "model_unseen_data = load_dataset(drive_csv_path_unseen)\n",
        "\n",
        "# Function to preprocess unseen data\n",
        "def preprocess_unseen_data(data):\n",
        "    print(\"Initial data columns:\", data.columns)\n",
        "\n",
        "    # Remove rows where 'Draw1' is NaN\n",
        "    data = data.dropna(subset=['Draw1'])\n",
        "\n",
        "    # Define possible date formats\n",
        "    date_formats = ['%d-%m-%y', '%d/%m/%Y']\n",
        "\n",
        "    # Try to convert 'Date' to datetime with different formats\n",
        "    for date_format in date_formats:\n",
        "        try:\n",
        "            if 'Date' in data.columns:\n",
        "                print(\"Converting 'Date' to datetime...\")\n",
        "                data['Date'] = pd.to_datetime(data['Date'], format=date_format)\n",
        "                data['Year'] = data['Date'].dt.year\n",
        "                data['Month'] = data['Date'].dt.month\n",
        "                data['Day'] = data['Date'].dt.day\n",
        "                print(\"After extracting Year, Month, Day:\", data.columns)\n",
        "                data.drop(columns=['Date'], inplace=True)\n",
        "                print(\"After dropping 'Date':\", data.columns)\n",
        "\n",
        "            # Initialize TARGET VARIABLE 'Prediction1' column with NaN values\n",
        "            data['Prediction1'] = np.nan\n",
        "\n",
        "            # Create shifted columns for previous day's data\n",
        "            data['Prev_Morning'] = data['Draw1'].shift(1)\n",
        "            data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
        "            data['Prev_Evening'] = data['Draw3'].shift(1)\n",
        "            data['Prev_Night'] = data['Draw4'].shift(1)\n",
        "\n",
        "            # Handle NaN values\n",
        "            data['Prev_Morning'].fillna(25, inplace=True)\n",
        "            data['Prev_Afternoon'].fillna(9, inplace=True)\n",
        "            data['Prev_Evening'].fillna(7, inplace=True)\n",
        "            data['Prev_Night'].fillna(5, inplace=True)\n",
        "\n",
        "            # Select relevant columns, including 'Prediction1'\n",
        "            selected_columns = ['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
        "            'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night', 'Prediction1', 'Year', 'Month', 'Day']\n",
        "            data = data[selected_columns]\n",
        "\n",
        "            # Save the preprocessed model unseen data directly to your Google Drive folder\n",
        "            save_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/D_Preprocessed_Unseen_Data.csv'\n",
        "            model_unseen_data.to_csv(save_path, index=False)\n",
        "\n",
        "            # Display the first few rows of the preprocessed data for verification\n",
        "            print(\"First few rows of preprocessed model unseen data:\")\n",
        "            print(model_unseen_data.head())\n",
        "\n",
        "\n",
        "            break  # Break the loop if successful date conversion\n",
        "\n",
        "        except ValueError:\n",
        "            print(\"Failed to convert 'Date' with format:\", date_format)\n",
        "\n",
        "# Apply preprocessing to the model unseen data\n",
        "preprocess_unseen_data(model_unseen_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhcW-7C8XvpW",
        "outputId": "9a58f6cd-c707-42a6-a3ec-a8805ca33692"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "Initial data columns: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg'],\n",
            "      dtype='object')\n",
            "Converting 'Date' to datetime...\n",
            "Failed to convert 'Date' with format: %d-%m-%y\n",
            "Converting 'Date' to datetime...\n",
            "After extracting Year, Month, Day: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg', 'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "After dropping 'Date': Index(['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
            "       'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
            "       'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks', 'DR2_Prev_Entry',\n",
            "       'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg', 'Draw3',\n",
            "       'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry', 'DR3_Prev_Entry-2',\n",
            "       'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4', 'DR4_Prev_Week', 'DR4_2Weeks',\n",
            "       'DR4_Prev_Entry', 'DR4_Prev_Entry-2', 'DR4_Mov_Avg', 'DR4_Vert_Avg',\n",
            "       'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "First few rows of preprocessed model unseen data:\n",
            "       Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  1/8/2023        1410    Unseen   13.0           27.0        25.0   \n",
            "1  2/8/2023        1411    Unseen   21.0           33.0        12.0   \n",
            "2  3/8/2023        1412    Unseen   15.0           27.0         3.0   \n",
            "3  4/8/2023        1413    Unseen   13.0           20.0        11.0   \n",
            "4  5/8/2023        1414    Unseen   12.0           29.0        14.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0             5.0               7.0          6.0          26.0  ...   \n",
            "1            18.0              26.0         22.0          22.5  ...   \n",
            "2            28.0               7.0         17.5          15.0  ...   \n",
            "3             2.0               2.0          2.0          15.5  ...   \n",
            "4            12.0              22.0         17.0          21.5  ...   \n",
            "\n",
            "   DR3_Prev_Entry-2  DR3_Mov_Avg  DR3_Vert_Avg  Draw4  DR4_Prev_Week  \\\n",
            "0              13.0         16.5          25.0   18.0           26.0   \n",
            "1              21.0         26.0           6.0   28.0            8.0   \n",
            "2              15.0         10.0          18.0    2.0           30.0   \n",
            "3              13.0         20.5          26.0   12.0            2.0   \n",
            "4              12.0         23.5          18.5   11.0            3.0   \n",
            "\n",
            "   DR4_2Weeks  DR4_Prev_Entry  DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  \n",
            "0         3.0            26.0              20.0         23.0          14.5  \n",
            "1         5.0             7.0              31.0         19.0           6.5  \n",
            "2         6.0             2.0               5.0          3.5          18.0  \n",
            "3         7.0            22.0              28.0         25.0           4.5  \n",
            "4        18.0            31.0              35.0         33.0          10.5  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-f7e2b7ad31b0>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Date'] = pd.to_datetime(data['Date'], format=date_format)\n",
            "<ipython-input-70-f7e2b7ad31b0>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Year'] = data['Date'].dt.year\n",
            "<ipython-input-70-f7e2b7ad31b0>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Month'] = data['Date'].dt.month\n",
            "<ipython-input-70-f7e2b7ad31b0>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Day'] = data['Date'].dt.day\n",
            "<ipython-input-70-f7e2b7ad31b0>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.drop(columns=['Date'], inplace=True)\n",
            "<ipython-input-70-f7e2b7ad31b0>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prediction1'] = np.nan\n",
            "<ipython-input-70-f7e2b7ad31b0>:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Morning'] = data['Draw1'].shift(1)\n",
            "<ipython-input-70-f7e2b7ad31b0>:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
            "<ipython-input-70-f7e2b7ad31b0>:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Evening'] = data['Draw3'].shift(1)\n",
            "<ipython-input-70-f7e2b7ad31b0>:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Night'] = data['Draw4'].shift(1)\n",
            "<ipython-input-70-f7e2b7ad31b0>:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Morning'].fillna(25, inplace=True)\n",
            "<ipython-input-70-f7e2b7ad31b0>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Afternoon'].fillna(9, inplace=True)\n",
            "<ipython-input-70-f7e2b7ad31b0>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Evening'].fillna(7, inplace=True)\n",
            "<ipython-input-70-f7e2b7ad31b0>:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Night'].fillna(5, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.5: Print and investigate presence of NaNs in Model Unseen Data\n",
        "\n",
        "# Check for NaN values in training/testing data\n",
        "print(\"NaN check for training/testing data:\")\n",
        "print(train_test_data.isna().sum())\n",
        "\n",
        "# Check for NaN values in model unseen data\n",
        "print(\"\\nNaN check for model unseen data:\")\n",
        "print(model_unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9PH8HbW1ToU",
        "outputId": "90c7ca7a-7c05-47b6-df7f-9a4f72a2e572"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN check for training/testing data:\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Prev_Morning        0\n",
            "Prev_Afternoon      0\n",
            "Prev_Evening        0\n",
            "Prev_Night          0\n",
            "Prediction1         0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "dtype: int64\n",
            "\n",
            "NaN check for model unseen data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           4\n",
            "Draw1               4\n",
            "DR1_Prev_Week       4\n",
            "DR1_2Weeks          4\n",
            "DR1_Prev_Entry      4\n",
            "DR1_Prev_Entry-2    4\n",
            "DR1_Mov_Avg         4\n",
            "DR1_Vert_Avg        4\n",
            "Draw2               4\n",
            "DR2_Prev_Week       4\n",
            "DR2_2Weeks          4\n",
            "DR2_Prev_Entry      4\n",
            "DR2_Prev_Entry-2    4\n",
            "DR2_Mov_Avg         4\n",
            "DR2_Vert_Avg        4\n",
            "Draw3               4\n",
            "DR3_Prev_Week       4\n",
            "DR3_2Weeks          4\n",
            "DR3_Prev_Entry      4\n",
            "DR3_Prev_Entry-2    4\n",
            "DR3_Mov_Avg         4\n",
            "DR3_Vert_Avg        4\n",
            "Draw4               4\n",
            "DR4_Prev_Week       4\n",
            "DR4_2Weeks          4\n",
            "DR4_Prev_Entry      4\n",
            "DR4_Prev_Entry-2    4\n",
            "DR4_Mov_Avg         4\n",
            "DR4_Vert_Avg        4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.1: Creating \"LINES\" feature for Training/Testing and Unseen Datasets\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the path to the CSV file for preprocessed training/testing data\n",
        "preprocessed_train_test_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/C_Preprocessed_Train_Test_Data.csv'\n",
        "\n",
        "# Define the path to the CSV file for preprocessed model unseen data\n",
        "preprocessed_unseen_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/D_Preprocessed_Unseen_Data.csv'\n",
        "\n",
        "# Load preprocessed training/testing data\n",
        "preprocessed_train_test_data = pd.read_csv(preprocessed_train_test_data_path)\n",
        "\n",
        "# Load preprocessed unseen data\n",
        "preprocessed_unseen_data = pd.read_csv(preprocessed_unseen_data_path)\n",
        "\n",
        "# List of columns to convert to integers\n",
        "int_columns = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
        "               'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night']\n",
        "\n",
        "# Convert specified columns to integers for both datasets\n",
        "preprocessed_train_test_data[int_columns] = preprocessed_train_test_data[int_columns].astype(int)\n",
        "preprocessed_unseen_data[int_columns] = preprocessed_unseen_data[int_columns].astype(int)\n",
        "\n",
        "# Function to assign \"Lines\" based on the sum of digits\n",
        "def assign_lines(data, column_name):\n",
        "    def get_lines(x):\n",
        "        try:\n",
        "            # Calculate the sum of digits\n",
        "            sum_of_digits = sum(map(int, str(x)))\n",
        "            # Ensure the sum is between 1 and 9\n",
        "            while sum_of_digits > 9:\n",
        "                sum_of_digits = sum(map(int, str(sum_of_digits)))\n",
        "            return sum_of_digits\n",
        "        except (ValueError, TypeError):\n",
        "            return None  # Handle non-convertible values by returning None\n",
        "\n",
        "    data[f'Lines_{column_name}'] = data[column_name].apply(get_lines)\n",
        "\n",
        "# Handle NaN values in the 'Prediction1' column for unseen data by filling them with 0\n",
        "preprocessed_unseen_data['Prediction1'].fillna(0, inplace=True)\n",
        "\n",
        "# Assign \"Lines\" for specified columns in both datasets\n",
        "columns_to_assign_lines = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "for column in columns_to_assign_lines:\n",
        "    assign_lines(preprocessed_train_test_data, column)\n",
        "    assign_lines(preprocessed_unseen_data, column)\n",
        "\n",
        "# Define file paths for the new CSVs with \"Lines\"\n",
        "lines_train_test_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/E_Lines_Train_Test_Data.csv'\n",
        "lines_unseen_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/F_Lines_Unseen_Data.csv'\n",
        "\n",
        "# Save the datasets with \"Lines\" to new CSVs\n",
        "preprocessed_train_test_data.to_csv(lines_train_test_data_path, index=False)\n",
        "preprocessed_unseen_data.to_csv(lines_unseen_data_path, index=False)\n",
        "\n",
        "# Display a sample of the processed data for verification\n",
        "print(\"Sample of preprocessed training/testing data with 'Lines_Draw1':\")\n",
        "print(preprocessed_train_test_data[['Row Number', 'Draw1', 'Lines_Draw1']].head())\n",
        "\n",
        "print(\"\\nSample of preprocessed unseen data with 'Lines_Draw1':\")\n",
        "print(preprocessed_unseen_data[['Row Number', 'Draw1', 'Lines_Draw1']].head())\n"
      ],
      "metadata": {
        "id": "zwgfUWQo0gEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "e8b2863c-d96e-40ae-8f00-4ca9e4afd03c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-a58687e21b99>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Convert specified columns to integers for both datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mpreprocessed_train_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessed_train_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mpreprocessed_unseen_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessed_unseen_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Function to assign \"Lines\" based on the sum of digits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3898\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3899\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6113\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6117\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6178\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6179\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6181\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.2: Loading Datasets for \"Special Groups\"\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define file paths for the preprocessed training/testing and unseen data\n",
        "preprocessed_train_test_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/C_Preprocessed_Train_Test_Data.csv'\n",
        "preprocessed_unseen_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/D_Preprocessed_Unseen_Data.csv'\n",
        "\n",
        "# Load preprocessed training/testing data\n",
        "preprocessed_train_test_data = pd.read_csv(preprocessed_train_test_data_path)\n",
        "\n",
        "# Load preprocessed unseen data\n",
        "preprocessed_unseen_data = pd.read_csv(preprocessed_unseen_data_path)\n",
        "\n",
        "# Display the first few rows of the loaded data to verify\n",
        "preprocessed_train_test_data.head()\n",
        "preprocessed_unseen_data.head()\n"
      ],
      "metadata": {
        "id": "feiR8iFN0hBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.3: Creating \"Special Groups\" feature for Training/Testing and Unseen Datasets\n",
        "\n",
        "# Define the mapping for \"Special Groups\"\n",
        "special_groups_mapping = {\n",
        "    2: 1, 15: 1, 16: 1, 24: 1, 31: 1,  # \"Ladies\"\n",
        "    4: 2, 5: 2, 12: 2, 29: 2, 34: 2,  # \"Men\"\n",
        "    11: 3, 17: 3, 26: 3,  # \"Birds\"\n",
        "    7: 4, 9: 4, 19: 4, 20: 4, 22: 4, 30: 4, 36: 4,  # \"Domestic Animals\"\n",
        "    8: 5, 10: 5, 13: 5, 25: 5,  # \"Wild Animals\"\n",
        "    18: 6, 28: 6, 32: 6,  # \"Ocean\"\n",
        "    1: 7, 27: 7, 33: 7, 35: 7,  # \"Snakes & Insects\"\n",
        "    3: 8, 6: 8, 14: 8, 21: 8, 23: 8  # \"Home\"\n",
        "}\n",
        "\n",
        "# Function to assign \"Special Groups\" based on the mapping\n",
        "def assign_special_groups(data, column_name, special_groups_mapping):\n",
        "    data[f'Special_Groups_{column_name}'] = data[column_name].map(special_groups_mapping).fillna(0).astype(int)\n",
        "\n",
        "# Assign \"Special Groups\" for specified columns in both datasets\n",
        "columns_to_assign_special_groups = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "for column in columns_to_assign_special_groups:\n",
        "    assign_special_groups(train_test_data, column, special_groups_mapping)\n",
        "    assign_special_groups(unseen_data, column, special_groups_mapping)\n",
        "\n",
        "# Save the datasets with \"Special Groups\" to new CSVs\n",
        "special_groups_train_test_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/G_Special_Groups_Train_Test_Data.csv'\n",
        "special_groups_unseen_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/H_Special_Groups_Unseen_Data.csv'\n",
        "\n",
        "train_test_data.to_csv(special_groups_train_test_data_path, index=False)\n",
        "unseen_data.to_csv(special_groups_unseen_data_path, index=False)\n",
        "\n",
        "# Load the datasets with \"Special Groups\"\n",
        "special_groups_train_test_data = pd.read_csv(special_groups_train_test_data_path)\n",
        "special_groups_unseen_data = pd.read_csv(special_groups_unseen_data_path)\n",
        "\n",
        "# Display the first few rows of the datasets to investigate the issue\n",
        "print(\"First few rows of special_groups_train_test_data:\")\n",
        "print(special_groups_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of special_groups_unseen_data:\")\n",
        "print(special_groups_unseen_data.head())"
      ],
      "metadata": {
        "id": "TgHqp-uTnTyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2NiVstWrZE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eYAyxCevrZZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ES57Mh6gnVmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.3: Data Loading from Google Drive and Preprocessing Unseen Dataset\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the directory for datasets in Google Drive\n",
        "drive_dataset_directory = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/'\n",
        "\n",
        "# Define the path to the CSV file for unseen data\n",
        "csv_filename_unseen = 'Model_Unseen_Data.csv'\n",
        "drive_csv_path_unseen = os.path.join(drive_dataset_directory, csv_filename_unseen)\n",
        "\n",
        "# Check and load the dataset\n",
        "def load_dataset(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        print(\"File found. Proceeding to load the dataset.\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"File not found. Check the file path or the Google Drive mount.\")\n",
        "        return None\n",
        "\n",
        "unseen_data = load_dataset(drive_csv_path_unseen)\n",
        "\n",
        "# Function to preprocess unseen data\n",
        "def preprocess_unseen_data(data):\n",
        "    print(\"Initial data columns:\", data.columns)\n",
        "\n",
        "    # Convert 'Date' to datetime and extract 'Year', 'Month', and 'Day'\n",
        "    if 'Date' in data.columns:\n",
        "        print(\"Converting 'Date' to datetime...\")\n",
        "        data['Date'] = pd.to_datetime(data['Date'])\n",
        "        data['Year'] = data['Date'].dt.year\n",
        "        data['Month'] = data['Date'].dt.month\n",
        "        data['Day'] = data['Date'].dt.day\n",
        "        print(\"After extracting Year, Month, Day:\", data.columns)\n",
        "        data.drop(columns=['Date'], inplace=True)\n",
        "        print(\"After dropping 'Date':\", data.columns)\n",
        "    else:\n",
        "        print(\"Date column not found in the given dataset.\")\n",
        "\n",
        "    # Initialize 'Prediction1' column with NaNs for unseen data\n",
        "    data['Prediction1'] = np.nan\n",
        "\n",
        "    # Create shifted columns for previous day's data\n",
        "    data['Prev_Morning'] = data['Morning'].shift(1)\n",
        "    data['Prev_Afternoon'] = data['Afternoon'].shift(1)\n",
        "    data['Prev_Evening'] = data['Evening'].shift(1)\n",
        "\n",
        "    # Calculate moving averages excluding current row\n",
        "    initial_window_size = 3  # Increased by 1 to exclude the current row\n",
        "    columns_to_average = ['Morning', 'Afternoon', 'Evening', 'Night']\n",
        "    target_columns = ['Mov_Avg_Mor', 'Mov_Avg_Aft', 'Mov_Avg_Eve', 'Mov_Avg_Nig']\n",
        "\n",
        "    for col, target_col in zip(columns_to_average, target_columns):\n",
        "    # Roll over an additional row and then shift to exclude the current row\n",
        "        data[target_col] = data[col].rolling(window=initial_window_size, min_periods=1).mean().shift(1)\n",
        "    # Manually set the value for the first row\n",
        "    unseen_data.at[0, 'Mov_Avg_Mor'] = 6\n",
        "    unseen_data.at[1, 'Mov_Avg_Mor'] = 22\n",
        "    unseen_data.at[2, 'Mov_Avg_Mor'] = 17.5\n",
        "    unseen_data.at[3, 'Mov_Avg_Mor'] = 2\n",
        "    unseen_data.at[4, 'Mov_Avg_Mor'] = 17\n",
        "\n",
        "    # Calculate vertical averages excluding current row\n",
        "    vertical_target_columns = ['Vert_Avg_Mor', 'Vert_Avg_Aft', 'Vert_Avg_Eve', 'Vert_Avg_Nig']\n",
        "    for col, target_col in zip(columns_to_average, vertical_target_columns):\n",
        "        data[target_col] = data[col].rolling(window=3, min_periods=1).mean().shift(1)\n",
        "\n",
        "    # Handle NaN values\n",
        "    data['Prev_Morning'].fillna(25, inplace=True)\n",
        "    data['Prev_Afternoon'].fillna(9, inplace=True)\n",
        "    data['Prev_Evening'].fillna(7, inplace=True)\n",
        "\n",
        "    # Select relevant columns, including 'Prediction1'\n",
        "    selected_columns = ['Row Number', 'Data_Type', 'Year', 'Month', 'Day', 'Prev_Week', 'Prev_Entry', 'Mov_Avg_Mor', 'Vert_Avg_Mor', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prediction1']\n",
        "    data[selected_columns]\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply preprocessing to the unseen dataset\n",
        "unseen_data = preprocess_unseen_data(unseen_data)\n",
        "\n",
        "# Display the preprocessed unseen data\n",
        "print(\"First few rows of preprocessed unseen data:\")\n",
        "print(unseen_data.head())"
      ],
      "metadata": {
        "id": "WsY7Mvh7Jp1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.4: # Save the preprocessed training/testing dataset\n",
        "preprocessed_train_test_path = os.path.join(drive_dataset_directory, '1_preprocessed_train_test_data.csv')\n",
        "train_test_data.to_csv(preprocessed_train_test_path, index=False)\n",
        "print(\"Preprocessed training/testing data saved to Google Drive.\")\n",
        "\n",
        "# Display the first few rows of the preprocessed training/testing data\n",
        "print(\"First few rows of preprocessed training/testing data:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "# Check for NaN values in the entire dataset\n",
        "nan_counts = train_test_data.isnull().sum()\n",
        "print(\"Count of NaN values in training/testing data:\")\n",
        "print(nan_counts)\n",
        "\n",
        "# Save the preprocessed unseen dataset\n",
        "preprocessed_unseen_path = os.path.join(drive_dataset_directory, '2_preprocessed_unseen_data.csv')\n",
        "unseen_data.to_csv(preprocessed_unseen_path, index=False)\n",
        "print(\"Preprocessed unseen data saved to Google Drive.\")\n",
        "\n",
        "# Display the first few rows of the preprocessed unseen data\n",
        "print(\"First few rows of preprocessed unseen data:\")\n",
        "print(unseen_data.head())\n",
        "\n",
        "# Check for NaN values in the entire dataset\n",
        "nan_counts = unseen_data.isnull().sum()\n",
        "print(\"Count of NaN values in unseen data:\")\n",
        "print(nan_counts)\n"
      ],
      "metadata": {
        "id": "ncZjXqqlHgvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define the directory for datasets in Google Drive\n",
        "drive_dataset_directory = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/'\n",
        "\n",
        "# Define the path to the preprocessed unseen data\n",
        "preprocessed_unseen_path = os.path.join(drive_dataset_directory, '2_preprocessed_unseen_data.csv')\n",
        "\n",
        "# Load the preprocessed unseen data\n",
        "unseen_data = pd.read_csv(preprocessed_unseen_path)\n",
        "logger.info(\"Preprocessed unseen data loaded successfully.\")\n",
        "\n",
        "# Define the provided data for imputation\n",
        "provided_data = [\n",
        "    {\n",
        "        'Row Number': 1410,\n",
        "        'Morning': 13,\n",
        "        'Prev_Week': 27,\n",
        "        '2WeeksM': 25,\n",
        "        'Prev_Entry': 5,\n",
        "        'Prev_Entry-2': 7,\n",
        "        'Mov_Avg_Mor': 6,\n",
        "        'Vert_Avg_Mor': 26,\n",
        "        'Afternoon': 20,\n",
        "        'Prev_Week': 7,\n",
        "        '2WeeksA': 34,\n",
        "        'Prev_Entry': 13,\n",
        "        'Prev_Entry-2': 5,\n",
        "        'Mov_Avg_Aft': 9,\n",
        "        'Vert_Avg_Aft': 20.5,\n",
        "        'Evening': 26,\n",
        "        'Prev_Week': 26,\n",
        "        '2WeeksE': 24,\n",
        "        'Prev_Entry': 20,\n",
        "        'Prev_Entry-2': 13,\n",
        "        'Mov_Avg_Eve': 16.5,\n",
        "        'Vert_Avg_Eve': 25,\n",
        "        'Night': 18,\n",
        "        'Prev_Week': 26,\n",
        "        '2WeeksN': 3,\n",
        "        'Prev_Entry': 26,\n",
        "        'Prev_Entry-2': 20,\n",
        "        'Mov_Avg_Nig': 23,\n",
        "        'Vert_Avg_Nig': 14.5\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1411,\n",
        "        'Morning': 21,\n",
        "        'Prev_Week': 33,\n",
        "        '2WeeksM': 12,\n",
        "        'Prev_Entry': 18,\n",
        "        'Prev_Entry-2': 26,\n",
        "        'Mov_Avg_Mor': 22,\n",
        "        'Vert_Avg_Mor': 22.5,\n",
        "        'Afternoon': 31,\n",
        "        'Prev_Week': 18,\n",
        "        '2WeeksA': 36,\n",
        "        'Prev_Entry': 21,\n",
        "        'Prev_Entry-2': 18,\n",
        "        'Mov_Avg_Aft': 19.5,\n",
        "        'Vert_Avg_Aft': 27,\n",
        "        'Evening': 7,\n",
        "        'Prev_Week': 9,\n",
        "        '2WeeksE': 3,\n",
        "        'Prev_Entry': 31,\n",
        "        'Prev_Entry-2': 21,\n",
        "        'Mov_Avg_Eve': 26,\n",
        "        'Vert_Avg_Eve': 6,\n",
        "        'Night': 28,\n",
        "        'Prev_Week': 8,\n",
        "        '2WeeksN': 5,\n",
        "        'Prev_Entry': 7,\n",
        "        'Prev_Entry-2': 31,\n",
        "        'Mov_Avg_Nig': 19,\n",
        "        'Vert_Avg_Nig': 6.5\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1412,\n",
        "        'Morning': 15,\n",
        "        'Prev_Week': 27,\n",
        "        '2WeeksM': 3,\n",
        "        'Prev_Entry': 28,\n",
        "        'Prev_Entry-2': 7,\n",
        "        'Mov_Avg_Mor': 17.5,\n",
        "        'Vert_Avg_Mor': 15,\n",
        "        'Afternoon': 5,\n",
        "        'Prev_Week': 22,\n",
        "        '2WeeksA': 10,\n",
        "        'Prev_Entry': 15,\n",
        "        'Prev_Entry-2': 28,\n",
        "        'Mov_Avg_Aft': 21.5,\n",
        "        'Vert_Avg_Aft': 16,\n",
        "        'Evening': 2,\n",
        "        'Prev_Week': 32,\n",
        "        '2WeeksE': 4,\n",
        "        'Prev_Entry': 5,\n",
        "        'Prev_Entry-2': 15,\n",
        "        'Mov_Avg_Eve': 10,\n",
        "        'Vert_Avg_Eve': 18,\n",
        "        'Night': 2,\n",
        "        'Prev_Week': 30,\n",
        "        '2WeeksN': 6,\n",
        "        'Prev_Entry': 2,\n",
        "        'Prev_Entry-2': 5,\n",
        "        'Mov_Avg_Nig': 3.5,\n",
        "        'Vert_Avg_Nig': 18\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1413,\n",
        "        'Morning': 13,\n",
        "        'Prev_Week': 20,\n",
        "        '2WeeksM': 11,\n",
        "        'Prev_Entry': 2,\n",
        "        'Prev_Entry-2': 2,\n",
        "        'Mov_Avg_Mor': 2,\n",
        "        'Vert_Avg_Mor': 15.5,\n",
        "        'Row Number': 1413,\n",
        "        'Afternoon': 28,\n",
        "        'Prev_Week': 29,\n",
        "        '2WeeksA': 19,\n",
        "        'Prev_Entry': 13,\n",
        "        'Prev_Entry-2': 2,\n",
        "        'Mov_Avg_Aft': 7.5,\n",
        "        'Vert_Avg_Aft': 24,\n",
        "        'Evening': 22,\n",
        "        'Prev_Week': 23,\n",
        "        '2WeeksE': 29,\n",
        "        'Prev_Entry': 28,\n",
        "        'Prev_Entry-2': 13,\n",
        "        'Mov_Avg_Eve': 20.5,\n",
        "        'Vert_Avg_Eve': 26,\n",
        "        'Night': 12,\n",
        "        'Prev_Week': 2,\n",
        "        '2WeeksN': 7,\n",
        "        'Prev_Entry': 22,\n",
        "        'Prev_Entry-2': 28,\n",
        "        'Mov_Avg_Nig': 25,\n",
        "        'Vert_Avg_Nig': 4.5\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1414,\n",
        "        'Morning': 12,\n",
        "        'Prev_Week': 29,\n",
        "        '2WeeksM': 14,\n",
        "        'Prev_Entry': 12,\n",
        "        'Prev_Entry-2': 22,\n",
        "        'Mov_Avg_Mor': 17,\n",
        "        'Vert_Avg_Mor': 21.5,\n",
        "        'Row Number': 1414,\n",
        "        'Afternoon': 35,\n",
        "        'Prev_Week': 7,\n",
        "        '2WeeksA': 31,\n",
        "        'Prev_Entry': 12,\n",
        "        'Prev_Entry-2': 12,\n",
        "        'Mov_Avg_Aft': 12,\n",
        "        'Vert_Avg_Aft': 19,\n",
        "        'Evening': 31,\n",
        "        'Prev_Week': 5,\n",
        "        '2WeeksE': 32,\n",
        "        'Prev_Entry': 35,\n",
        "        'Prev_Entry-2': 12,\n",
        "        'Mov_Avg_Eve': 23.5,\n",
        "        'Vert_Avg_Eve': 18.5,\n",
        "        'Night': 11,\n",
        "        'Prev_Week': 3,\n",
        "        '2WeeksN': 18,\n",
        "        'Prev_Entry': 31,\n",
        "        'Prev_Entry-2': 35,\n",
        "        'Mov_Avg_Nig': 33,\n",
        "        'Vert_Avg_Nig': 10.5\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1415,\n",
        "        'Morning': 14,\n",
        "        'Prev_Week': 25,\n",
        "        '2WeeksM': 5,\n",
        "        'Prev_Entry': 11,\n",
        "        'Prev_Entry-2': 31,\n",
        "        'Mov_Avg_Mor': 21,\n",
        "        'Vert_Avg_Mor': 15,\n",
        "        'Row Number': 1415,\n",
        "        'Afternoon': 2,\n",
        "        'Prev_Week': 9,\n",
        "        '2WeeksA': 14,\n",
        "        'Prev_Entry': 14,\n",
        "        'Prev_Entry-2': 11,\n",
        "        'Mov_Avg_Aft': 12.5,\n",
        "        'Vert_Avg_Aft': 11.5,\n",
        "        'Evening': 23,\n",
        "        'Prev_Week': 7,\n",
        "        '2WeeksE': 30,\n",
        "        'Prev_Entry': 2,\n",
        "        'Prev_Entry-2': 14,\n",
        "        'Mov_Avg_Eve': 8,\n",
        "        'Vert_Avg_Eve': 18.5,\n",
        "        'Row Number': 1415,\n",
        "        'Night': 25,\n",
        "        'Prev_Week': 5,\n",
        "        '2WeeksN': 22,\n",
        "        'Prev_Entry': 23,\n",
        "        'Prev_Entry-2': 2,\n",
        "        'Mov_Avg_Nig': 12.5,\n",
        "        'Vert_Avg_Nig': 13.5\n",
        "    }\n",
        "]\n",
        "\n",
        "# Iterate through the provided data to update the corresponding columns in the DataFrame\n",
        "for data in provided_data:\n",
        "    row_number = data['Row Number']\n",
        "    for column in data.keys():\n",
        "        if column != 'Row Number':\n",
        "            unseen_data.loc[unseen_data['Row Number'] == row_number, column] = data[column]\n",
        "\n",
        "# Display the dataset after NaN handling\n",
        "print(\"First few rows of unseen data after NaN handling:\")\n",
        "print(unseen_data.head())\n",
        "\n",
        "# Check for NaN values in the entire dataset\n",
        "nan_counts = unseen_data.isnull().sum()\n",
        "print(\"Count of NaN values in unseen data:\")\n",
        "print(nan_counts)\n",
        "\n",
        "# Save the updated unseen data\n",
        "updated_unseen_path = os.path.join(drive_dataset_directory, '2_preprocessed_unseen_data.csv')\n",
        "unseen_data.to_csv(updated_unseen_path, index=False)\n",
        "logger.info(\"Updated unseen data saved successfully.\")\n"
      ],
      "metadata": {
        "id": "Jt0eLKc5qADl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}