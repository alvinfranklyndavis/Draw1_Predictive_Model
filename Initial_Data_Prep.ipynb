{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAPiPWyruOaF7GZg/Q3QrW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvinfranklyndavis/Draw1_Predictive_Model/blob/main/Initial_Data_Prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1.1: Package Installation and Library Import\n",
        "\n",
        "# Check for existing libraries\n",
        "!pip show pandas numpy\n",
        "\n",
        "# Install or upgrade required packages\n",
        "!pip install -U --upgrade-strategy eager pip\n",
        "!pip install -U --upgrade-strategy eager pandas==<desired_version> numpy==<desired_version>\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Set up logging to save logs in a file\n",
        "log_file = 'project.log'\n",
        "logging.basicConfig(filename=log_file, level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Set up virtual environment (optional but recommended)\n",
        "# You can create a virtual environment with: !python -m venv myenv\n",
        "# And activate it with: source myenv/bin/activate (Linux/macOS) or myenv\\Scripts\\activate (Windows)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plnc-ffhAUCk",
        "outputId": "b1aeef98-43e6-455e-954b-c9c3f1af53b1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pandas\n",
            "Version: 1.5.3\n",
            "Summary: Powerful data structures for data analysis, time series, and statistics\n",
            "Home-page: https://pandas.pydata.org\n",
            "Author: The Pandas Development Team\n",
            "Author-email: pandas-dev@python.org\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, python-dateutil, pytz\n",
            "Required-by: altair, arviz, bigframes, bokeh, bqplot, cmdstanpy, cufflinks, datascience, db-dtypes, dopamine-rl, fastai, geemap, geopandas, google-colab, gspread-dataframe, holoviews, ibis-framework, mizani, mlxtend, pandas-datareader, pandas-gbq, panel, plotnine, prophet, pymc, seaborn, sklearn-pandas, statsmodels, vega-datasets, xarray, yfinance\n",
            "---\n",
            "Name: numpy\n",
            "Version: 1.25.2\n",
            "Summary: Fundamental package for array computing in Python\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: \n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: albumentations, altair, arviz, astropy, autograd, blis, bokeh, bqplot, chex, cmdstanpy, contourpy, cufflinks, cupy-cuda12x, cvxpy, datascience, db-dtypes, dopamine-rl, ecos, flax, folium, geemap, gensim, gym, h5py, holoviews, hyperopt, ibis-framework, imageio, imbalanced-learn, imgaug, jax, jaxlib, librosa, lightgbm, matplotlib, matplotlib-venn, missingno, mizani, ml-dtypes, mlxtend, moviepy, music21, nibabel, numba, numexpr, opencv-contrib-python, opencv-python, opencv-python-headless, opt-einsum, optax, orbax-checkpoint, osqp, pandas, pandas-gbq, patsy, plotnine, prophet, pyarrow, pycocotools, pyerfa, pymc, pytensor, python-louvain, PyWavelets, qdldl, qudida, scikit-image, scikit-learn, scipy, scs, seaborn, shapely, sklearn-pandas, soxr, spacy, stanio, statsmodels, tables, tensorboard, tensorflow, tensorflow-datasets, tensorflow-hub, tensorflow-probability, tensorstore, thinc, tifffile, torchtext, torchvision, transformers, wordcloud, xarray, xarray-einstats, xgboost, yellowbrick, yfinance\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `pip install -U --upgrade-strategy eager pandas==<desired_version> numpy==<desired_version>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.2: Data Loading from Google Drive Training / Testing  and Unseen datasets\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the directory for datasets in Google Drive\n",
        "drive_dataset_directory = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/'\n",
        "\n",
        "# Define the paths to the CSV files\n",
        "csv_filename_train_test = 'A_Initial_Train_Test_Data.csv'\n",
        "csv_filename_unseen = 'B_Initial_Unseen_Data.csv'\n",
        "\n",
        "drive_csv_path_train_test = os.path.join(drive_dataset_directory, csv_filename_train_test)\n",
        "drive_csv_path_unseen = os.path.join(drive_dataset_directory, csv_filename_unseen)\n",
        "\n",
        "# Check and load the datasets\n",
        "def load_dataset(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        print(\"File found. Proceeding to load the dataset.\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"File not found. Check the file path or the Google Drive mount.\")\n",
        "        return None\n",
        "\n",
        "# Load training/testing data\n",
        "train_test_data = load_dataset(drive_csv_path_train_test)\n",
        "\n",
        "# Load unseen data\n",
        "unseen_data = load_dataset(drive_csv_path_unseen)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of training/testing data:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data:\")\n",
        "print(unseen_data.head())\n"
      ],
      "metadata": {
        "id": "fP_Q74gUBGQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc9c134-1e5b-4675-daf4-2a9575277766"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of training/testing data:\n",
            "       Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  01-08-18           1  Training   19.0            7.0        27.0   \n",
            "1  02-08-18           2  Training   31.0           11.0         1.0   \n",
            "2  03-08-18           3  Training   15.0           19.0        21.0   \n",
            "3  04-08-18           4  Training   31.0           35.0        18.0   \n",
            "4  05-08-18           5       NaN    NaN            NaN         NaN   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0            23.0              32.0         27.5          17.0  ...   \n",
            "1             9.0              33.0         21.0           6.0  ...   \n",
            "2            12.0              35.0         23.5          20.0  ...   \n",
            "3            35.0              23.0         29.0          26.5  ...   \n",
            "4             NaN               NaN          NaN           NaN  ...   \n",
            "\n",
            "   DR3_Prev_Entry-2  DR3_Mov_Avg  DR3_Vert_Avg  Draw4  DR4_Prev_Week  \\\n",
            "0              19.0         16.5          15.0    9.0            2.0   \n",
            "1              31.0         17.0          17.0   12.0           35.0   \n",
            "2              15.0         12.0          10.0   35.0           11.0   \n",
            "3              31.0         26.0          23.5   16.0           13.0   \n",
            "4               NaN          NaN           NaN    NaN            NaN   \n",
            "\n",
            "   DR4_2Weeks  DR4_Prev_Entry  DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  \n",
            "0        24.0            33.0              14.0         23.5          13.0  \n",
            "1        26.0            35.0               3.0         19.0          30.5  \n",
            "2        29.0            23.0               9.0         16.0          20.0  \n",
            "3        17.0            29.0              21.0         25.0          15.0  \n",
            "4         NaN             NaN               NaN          NaN           NaN  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "First few rows of unseen data:\n",
            "       Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  1/8/2023        1673    Unseen   13.0           27.0        25.0   \n",
            "1  2/8/2023        1674    Unseen   21.0           33.0        12.0   \n",
            "2  3/8/2023        1675    Unseen   15.0           27.0         3.0   \n",
            "3  4/8/2023        1676    Unseen   13.0           20.0        11.0   \n",
            "4  5/8/2023        1677    Unseen   12.0           29.0        14.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0             5.0               7.0          6.0          26.0  ...   \n",
            "1            18.0              26.0         22.0          22.5  ...   \n",
            "2            28.0               7.0         17.5          15.0  ...   \n",
            "3             2.0               2.0          2.0          15.5  ...   \n",
            "4            12.0              22.0         17.0          21.5  ...   \n",
            "\n",
            "   DR3_Prev_Entry-2  DR3_Mov_Avg  DR3_Vert_Avg  Draw4  DR4_Prev_Week  \\\n",
            "0              13.0         16.5          25.0   18.0           26.0   \n",
            "1              21.0         26.0           6.0   28.0            8.0   \n",
            "2              15.0         10.0          18.0    2.0           30.0   \n",
            "3              13.0         20.5          26.0   12.0            2.0   \n",
            "4              12.0         23.5          18.5   11.0            3.0   \n",
            "\n",
            "   DR4_2Weeks  DR4_Prev_Entry  DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  \n",
            "0         3.0            26.0              20.0         23.0          14.5  \n",
            "1         5.0             7.0              31.0         19.0           6.5  \n",
            "2         6.0             2.0               5.0          3.5          18.0  \n",
            "3         7.0            22.0              28.0         25.0           4.5  \n",
            "4        18.0            31.0              35.0         33.0          10.5  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.3: Surveillance Check for NaNs within both datasets\n",
        "\n",
        "# Check for NaN values in training/testing data\n",
        "print(\"NaN check for training/testing data:\")\n",
        "print(train_test_data.isna().sum())\n",
        "\n",
        "# Check for NaN values in unseen data\n",
        "print(\"\\nNaN check for unseen data:\")\n",
        "print(unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2THl1IOP57A7",
        "outputId": "515c553c-8d6b-439a-bc9f-29c10f96d2e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN check for training/testing data:\n",
            "Date                  0\n",
            "Row Number            0\n",
            "Data_Type           239\n",
            "Draw1               239\n",
            "DR1_Prev_Week       239\n",
            "DR1_2Weeks          239\n",
            "DR1_Prev_Entry      239\n",
            "DR1_Prev_Entry-2    239\n",
            "DR1_Mov_Avg         239\n",
            "DR1_Vert_Avg        239\n",
            "Draw2               239\n",
            "DR2_Prev_Week       239\n",
            "DR2_2Weeks          239\n",
            "DR2_Prev_Entry      239\n",
            "DR2_Prev_Entry-2    239\n",
            "DR2_Mov_Avg         239\n",
            "DR2_Vert_Avg        239\n",
            "Draw3               239\n",
            "DR3_Prev_Week       239\n",
            "DR3_2Weeks          239\n",
            "DR3_Prev_Entry      239\n",
            "DR3_Prev_Entry-2    239\n",
            "DR3_Mov_Avg         239\n",
            "DR3_Vert_Avg        239\n",
            "Draw4               239\n",
            "DR4_Prev_Week       239\n",
            "DR4_2Weeks          239\n",
            "DR4_Prev_Entry      239\n",
            "DR4_Prev_Entry-2    239\n",
            "DR4_Mov_Avg         239\n",
            "DR4_Vert_Avg        239\n",
            "dtype: int64\n",
            "\n",
            "NaN check for unseen data:\n",
            "Date                 0\n",
            "Row Number           0\n",
            "Data_Type           17\n",
            "Draw1               17\n",
            "DR1_Prev_Week       17\n",
            "DR1_2Weeks          17\n",
            "DR1_Prev_Entry      17\n",
            "DR1_Prev_Entry-2    17\n",
            "DR1_Mov_Avg         17\n",
            "DR1_Vert_Avg        17\n",
            "Draw2               17\n",
            "DR2_Prev_Week       17\n",
            "DR2_2Weeks          17\n",
            "DR2_Prev_Entry      17\n",
            "DR2_Prev_Entry-2    17\n",
            "DR2_Mov_Avg         17\n",
            "DR2_Vert_Avg        17\n",
            "Draw3               17\n",
            "DR3_Prev_Week       17\n",
            "DR3_2Weeks          17\n",
            "DR3_Prev_Entry      17\n",
            "DR3_Prev_Entry-2    17\n",
            "DR3_Mov_Avg         17\n",
            "DR3_Vert_Avg        17\n",
            "Draw4               17\n",
            "DR4_Prev_Week       17\n",
            "DR4_2Weeks          17\n",
            "DR4_Prev_Entry      17\n",
            "DR4_Prev_Entry-2    17\n",
            "DR4_Mov_Avg         17\n",
            "DR4_Vert_Avg        17\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.1: NaN handling and new CSV saving for Training / Testing  and Unseen datasets\n",
        "\n",
        "\n",
        "# Impute NaN values with zeros in training/testing data\n",
        "train_test_data = train_test_data.fillna(0)\n",
        "\n",
        "# Impute NaN values with zeros in unseen data\n",
        "unseen_data = unseen_data.fillna(0)\n",
        "\n",
        "# Define new CSV file names\n",
        "new_csv_filename_train_test = 'C_NaN_Handled_Train_Test_Data.csv'\n",
        "new_csv_filename_unseen = 'D_NaN_Handled_Unseen_Data.csv'\n",
        "\n",
        "# Define the paths for saving the new CSV files\n",
        "new_csv_path_train_test = os.path.join(drive_dataset_directory, new_csv_filename_train_test)\n",
        "new_csv_path_unseen = os.path.join(drive_dataset_directory, new_csv_filename_unseen)\n",
        "\n",
        "# Save the preprocessed training/testing data as a new CSV file\n",
        "train_test_data.to_csv(new_csv_path_train_test, index=False)\n",
        "\n",
        "# Save the preprocessed unseen data as a new CSV file\n",
        "unseen_data.to_csv(new_csv_path_unseen, index=False)\n",
        "\n",
        "# Print a message to confirm that the preprocessing and saving is complete\n",
        "print(\"Preprocessing and saving of datasets is complete.\")\n",
        "\n",
        "# Check for NaN values in the preprocessed training/testing data\n",
        "print(\"\\nNaN check for preprocessed training/testing data:\")\n",
        "print(train_test_data.isna().sum())\n",
        "\n",
        "# Check for NaN values in the preprocessed unseen data\n",
        "print(\"\\nNaN check for preprocessed unseen data:\")\n",
        "print(unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7QU7JyA8B8b",
        "outputId": "342255e9-1350-45ee-e6cb-fd4f3ef7549c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing and saving of datasets is complete.\n",
            "\n",
            "NaN check for preprocessed training/testing data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "dtype: int64\n",
            "\n",
            "NaN check for preprocessed unseen data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.2: Extract Y/M/D from Date and new CSV saving for Training / Testing  and Unseen datasets\n",
        "\n",
        "# Load the NaN-handled training/testing data\n",
        "nan_handled_train_test_data = load_dataset(new_csv_path_train_test)\n",
        "\n",
        "# Load the NaN-handled unseen data\n",
        "nan_handled_unseen_data = load_dataset(new_csv_path_unseen)\n",
        "\n",
        "# Check and load the datasets\n",
        "def load_dataset(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        print(\"File found. Proceeding to load the dataset.\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"File not found. Check the file path.\")\n",
        "        return None\n",
        "\n",
        "# Function to extract 'Year', 'Month', and 'Day' from the 'Date' column\n",
        "def extract_date_features(data):\n",
        "    if 'Date' in data.columns:\n",
        "        print(\"Converting 'Date' to datetime and extracting Year, Month, and Day...\")\n",
        "        date_formats = ['%d-%m-%y', '%d/%m/%Y']\n",
        "        for date_format in date_formats:\n",
        "            try:\n",
        "                data['Date'] = pd.to_datetime(data['Date'], format=date_format)\n",
        "                data['Year'] = data['Date'].dt.year.fillna(0).astype(int)\n",
        "                data['Month'] = data['Date'].dt.month.fillna(0).astype(int)\n",
        "                data['Day'] = data['Date'].dt.day.fillna(0).astype(int)\n",
        "                print(\"After extracting Year, Month, and Day:\", data.columns)\n",
        "                break  # Break the loop if successful date conversion\n",
        "            except ValueError:\n",
        "                print(f\"Failed to convert 'Date' with format: {date_format}\")\n",
        "    else:\n",
        "        print(\"'Date' column not found in the dataset.\")\n",
        "\n",
        "# Extract 'Year', 'Month', and 'Day' from the 'Date' column in training/testing data\n",
        "extract_date_features(nan_handled_train_test_data)\n",
        "\n",
        "# Extract 'Year', 'Month', and 'Day' from the 'Date' column in unseen data\n",
        "extract_date_features(nan_handled_unseen_data)\n",
        "\n",
        "# Define new CSV file names\n",
        "new_csv_filename_train_test_date = 'E_Date_Extracted_Train_Test_Data.csv'\n",
        "new_csv_filename_unseen_date = 'F_Date_Extracted_Unseen_Data.csv'\n",
        "\n",
        "# Define the paths for saving the new CSV files\n",
        "new_csv_path_train_test_date = os.path.join(drive_dataset_directory, new_csv_filename_train_test_date)\n",
        "new_csv_path_unseen_date = os.path.join(drive_dataset_directory, new_csv_filename_unseen_date)\n",
        "\n",
        "# Save the datasets with extracted date features as new CSV files\n",
        "nan_handled_train_test_data.to_csv(new_csv_path_train_test_date, index=False)\n",
        "nan_handled_unseen_data.to_csv(new_csv_path_unseen_date, index=False)\n",
        "\n",
        "# Print a message to confirm that the date extraction and saving is complete\n",
        "print(\"Date extraction and saving of datasets is complete.\")\n",
        "\n",
        "# Check for NaN values in the datasets with extracted date features\n",
        "print(\"\\nNaN check for training/testing data with extracted date features:\")\n",
        "print(nan_handled_train_test_data.isna().sum())\n",
        "\n",
        "print(\"\\nNaN check for unseen data with extracted date features:\")\n",
        "print(nan_handled_unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEbg8-qg8NiZ",
        "outputId": "5d5f02e5-8446-4bc5-db0e-96025b36dfe1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "Converting 'Date' to datetime and extracting Year, Month, and Day...\n",
            "After extracting Year, Month, and Day: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg', 'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "Converting 'Date' to datetime and extracting Year, Month, and Day...\n",
            "Failed to convert 'Date' with format: %d-%m-%y\n",
            "After extracting Year, Month, and Day: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg', 'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "Date extraction and saving of datasets is complete.\n",
            "\n",
            "NaN check for training/testing data with extracted date features:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "dtype: int64\n",
            "\n",
            "NaN check for unseen data with extracted date features:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.3: Create shifted columns for previous day's data\n",
        "\n",
        "# Function to create shifted columns for previous day's data\n",
        "def create_shifted_columns(data):\n",
        "    data['Prev_Morning'] = data['Draw1'].shift(1)\n",
        "    data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
        "    data['Prev_Evening'] = data['Draw3'].shift(1)\n",
        "    data['Prev_Night'] = data['Draw4'].shift(1)\n",
        "    data[['Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night']] = data[['Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night']].fillna(0).astype(int)\n",
        "\n",
        "# Load the date extracted training/testing data\n",
        "date_extracted_train_test_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/E_Date_Extracted_Train_Test_Data.csv')\n",
        "\n",
        "# Apply the function to create shifted columns\n",
        "create_shifted_columns(date_extracted_train_test_data)\n",
        "\n",
        "# Save the updated training/testing data with shifted columns\n",
        "date_extracted_train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/G_Shifted_Train_Test_Data.csv', index=False)\n",
        "\n",
        "# Load the date extracted unseen data\n",
        "date_extracted_unseen_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/F_Date_Extracted_Unseen_Data.csv')\n",
        "\n",
        "# Apply the function to create shifted columns\n",
        "create_shifted_columns(date_extracted_unseen_data)\n",
        "\n",
        "# Save the updated unseen data with shifted columns\n",
        "date_extracted_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/H_Shifted_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of date extracted training/testing data:\")\n",
        "print(date_extracted_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of date extracted unseen data:\")\n",
        "print(date_extracted_unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YbHzP7wBUY1",
        "outputId": "e23608f5-737a-4738-9633-7b3e61ab3e5d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of date extracted training/testing data:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2018-08-01           1  Training   19.0            7.0        27.0   \n",
            "1  2018-08-02           2  Training   31.0           11.0         1.0   \n",
            "2  2018-08-03           3  Training   15.0           19.0        21.0   \n",
            "3  2018-08-04           4  Training   31.0           35.0        18.0   \n",
            "4  2018-08-05           5         0    0.0            0.0         0.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0            23.0              32.0         27.5          17.0  ...   \n",
            "1             9.0              33.0         21.0           6.0  ...   \n",
            "2            12.0              35.0         23.5          20.0  ...   \n",
            "3            35.0              23.0         29.0          26.5  ...   \n",
            "4             0.0               0.0          0.0           0.0  ...   \n",
            "\n",
            "   DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  \\\n",
            "0              14.0         23.5          13.0  2018      8    1   \n",
            "1               3.0         19.0          30.5  2018      8    2   \n",
            "2               9.0         16.0          20.0  2018      8    3   \n",
            "3              21.0         25.0          15.0  2018      8    4   \n",
            "4               0.0          0.0           0.0  2018      8    5   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  \n",
            "0             0               0             0           0  \n",
            "1            19              14            33           9  \n",
            "2            31               3            35          12  \n",
            "3            15               9            23          35  \n",
            "4            31              21            29          16  \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "\n",
            "First few rows of date extracted unseen data:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2023-08-01        1673    Unseen   13.0           27.0        25.0   \n",
            "1  2023-08-02        1674    Unseen   21.0           33.0        12.0   \n",
            "2  2023-08-03        1675    Unseen   15.0           27.0         3.0   \n",
            "3  2023-08-04        1676    Unseen   13.0           20.0        11.0   \n",
            "4  2023-08-05        1677    Unseen   12.0           29.0        14.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0             5.0               7.0          6.0          26.0  ...   \n",
            "1            18.0              26.0         22.0          22.5  ...   \n",
            "2            28.0               7.0         17.5          15.0  ...   \n",
            "3             2.0               2.0          2.0          15.5  ...   \n",
            "4            12.0              22.0         17.0          21.5  ...   \n",
            "\n",
            "   DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  \\\n",
            "0              20.0         23.0          14.5  2023      8    1   \n",
            "1              31.0         19.0           6.5  2023      8    2   \n",
            "2               5.0          3.5          18.0  2023      8    3   \n",
            "3              28.0         25.0           4.5  2023      8    4   \n",
            "4              35.0         33.0          10.5  2023      8    5   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  \n",
            "0             0               0             0           0  \n",
            "1            13              20            26          18  \n",
            "2            21              31             7          28  \n",
            "3            15               5             2           2  \n",
            "4            13              28            22          12  \n",
            "\n",
            "[5 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.4: Handle NaN values for previous day's data\n",
        "\n",
        "# Load the shifted training/testing data\n",
        "shifted_train_test_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/G_Shifted_Train_Test_Data.csv')\n",
        "\n",
        "# Manually set values for the first row of training/testing set\n",
        "shifted_train_test_data.at[0, 'Prev_Morning'] = 13\n",
        "shifted_train_test_data.at[0, 'Prev_Afternoon'] = 34\n",
        "shifted_train_test_data.at[0, 'Prev_Evening'] = 32\n",
        "shifted_train_test_data.at[0, 'Prev_Night'] = 23\n",
        "\n",
        "# Save the updated training/testing data\n",
        "shifted_train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/I_Handled_Shifted_Train_Test_Data.csv', index=False)\n",
        "\n",
        "# Load the shifted unseen data\n",
        "shifted_unseen_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/H_Shifted_Unseen_Data.csv')\n",
        "\n",
        "# Manually set values for the first row of unseen set\n",
        "shifted_unseen_data.at[0, 'Prev_Morning'] = 25\n",
        "shifted_unseen_data.at[0, 'Prev_Afternoon'] = 9\n",
        "shifted_unseen_data.at[0, 'Prev_Evening'] = 7\n",
        "shifted_unseen_data.at[0, 'Prev_Night'] = 5\n",
        "\n",
        "# Save the updated unseen data\n",
        "shifted_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/J_Handled_Shifted_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of handled shifted training/testing data:\")\n",
        "print(shifted_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of handled shifted unseen data:\")\n",
        "print(shifted_unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8U-4sqFGQXj",
        "outputId": "ed5a4201-055f-4428-f7cb-1bce149f3dc6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of handled shifted training/testing data:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2018-08-01           1  Training   19.0            7.0        27.0   \n",
            "1  2018-08-02           2  Training   31.0           11.0         1.0   \n",
            "2  2018-08-03           3  Training   15.0           19.0        21.0   \n",
            "3  2018-08-04           4  Training   31.0           35.0        18.0   \n",
            "4  2018-08-05           5         0    0.0            0.0         0.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0            23.0              32.0         27.5          17.0  ...   \n",
            "1             9.0              33.0         21.0           6.0  ...   \n",
            "2            12.0              35.0         23.5          20.0  ...   \n",
            "3            35.0              23.0         29.0          26.5  ...   \n",
            "4             0.0               0.0          0.0           0.0  ...   \n",
            "\n",
            "   DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  \\\n",
            "0              14.0         23.5          13.0  2018      8    1   \n",
            "1               3.0         19.0          30.5  2018      8    2   \n",
            "2               9.0         16.0          20.0  2018      8    3   \n",
            "3              21.0         25.0          15.0  2018      8    4   \n",
            "4               0.0          0.0           0.0  2018      8    5   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  \n",
            "0            13              34            32          23  \n",
            "1            19              14            33           9  \n",
            "2            31               3            35          12  \n",
            "3            15               9            23          35  \n",
            "4            31              21            29          16  \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "\n",
            "First few rows of handled shifted unseen data:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2023-08-01        1673    Unseen   13.0           27.0        25.0   \n",
            "1  2023-08-02        1674    Unseen   21.0           33.0        12.0   \n",
            "2  2023-08-03        1675    Unseen   15.0           27.0         3.0   \n",
            "3  2023-08-04        1676    Unseen   13.0           20.0        11.0   \n",
            "4  2023-08-05        1677    Unseen   12.0           29.0        14.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0             5.0               7.0          6.0          26.0  ...   \n",
            "1            18.0              26.0         22.0          22.5  ...   \n",
            "2            28.0               7.0         17.5          15.0  ...   \n",
            "3             2.0               2.0          2.0          15.5  ...   \n",
            "4            12.0              22.0         17.0          21.5  ...   \n",
            "\n",
            "   DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  \\\n",
            "0              20.0         23.0          14.5  2023      8    1   \n",
            "1              31.0         19.0           6.5  2023      8    2   \n",
            "2               5.0          3.5          18.0  2023      8    3   \n",
            "3              28.0         25.0           4.5  2023      8    4   \n",
            "4              35.0         33.0          10.5  2023      8    5   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  \n",
            "0            25               9             7           5  \n",
            "1            13              20            26          18  \n",
            "2            21              31             7          28  \n",
            "3            15               5             2           2  \n",
            "4            13              28            22          12  \n",
            "\n",
            "[5 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.1: # Initialize TARGET VARIABLE 'Prediction1' column\n",
        "\n",
        "# Load the handled shifted training/testing data\n",
        "handled_shifted_train_test_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/I_Handled_Shifted_Train_Test_Data.csv')\n",
        "\n",
        "# Set 'Prediction1' column equal to 'Draw1' for training/testing data\n",
        "handled_shifted_train_test_data['Prediction1'] = handled_shifted_train_test_data['Draw1']\n",
        "\n",
        "# Save the updated training/testing data\n",
        "handled_shifted_train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/K_Handled_Prediction1_Train_Test_Data.csv', index=False)\n",
        "\n",
        "# Load the handled shifted unseen data\n",
        "handled_shifted_unseen_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/J_Handled_Shifted_Unseen_Data.csv')\n",
        "\n",
        "# Initialize 'Prediction1' column with zero (0) for the unseen data\n",
        "handled_shifted_unseen_data['Prediction1'] = 0\n",
        "\n",
        "# Save the updated unseen data\n",
        "handled_shifted_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/L_Handled_Prediction1_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of handled Prediction1 training/testing data:\")\n",
        "print(handled_shifted_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of handled Prediction1 unseen data:\")\n",
        "print(handled_shifted_unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flDRfm_bLNeU",
        "outputId": "c0e8a608-8b2c-4b5b-f537-2ff03eaa4a9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of handled Prediction1 training/testing data:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2018-08-01           1  Training   19.0            7.0        27.0   \n",
            "1  2018-08-02           2  Training   31.0           11.0         1.0   \n",
            "2  2018-08-03           3  Training   15.0           19.0        21.0   \n",
            "3  2018-08-04           4  Training   31.0           35.0        18.0   \n",
            "4  2018-08-05           5         0    0.0            0.0         0.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0            23.0              32.0         27.5          17.0  ...   \n",
            "1             9.0              33.0         21.0           6.0  ...   \n",
            "2            12.0              35.0         23.5          20.0  ...   \n",
            "3            35.0              23.0         29.0          26.5  ...   \n",
            "4             0.0               0.0          0.0           0.0  ...   \n",
            "\n",
            "   DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  \\\n",
            "0         23.5          13.0  2018      8    1            13              34   \n",
            "1         19.0          30.5  2018      8    2            19              14   \n",
            "2         16.0          20.0  2018      8    3            31               3   \n",
            "3         25.0          15.0  2018      8    4            15               9   \n",
            "4          0.0           0.0  2018      8    5            31              21   \n",
            "\n",
            "   Prev_Evening  Prev_Night  Prediction1  \n",
            "0            32          23         19.0  \n",
            "1            33           9         31.0  \n",
            "2            35          12         15.0  \n",
            "3            23          35         31.0  \n",
            "4            29          16          0.0  \n",
            "\n",
            "[5 rows x 39 columns]\n",
            "\n",
            "First few rows of handled Prediction1 unseen data:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2023-08-01        1673    Unseen   13.0           27.0        25.0   \n",
            "1  2023-08-02        1674    Unseen   21.0           33.0        12.0   \n",
            "2  2023-08-03        1675    Unseen   15.0           27.0         3.0   \n",
            "3  2023-08-04        1676    Unseen   13.0           20.0        11.0   \n",
            "4  2023-08-05        1677    Unseen   12.0           29.0        14.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0             5.0               7.0          6.0          26.0  ...   \n",
            "1            18.0              26.0         22.0          22.5  ...   \n",
            "2            28.0               7.0         17.5          15.0  ...   \n",
            "3             2.0               2.0          2.0          15.5  ...   \n",
            "4            12.0              22.0         17.0          21.5  ...   \n",
            "\n",
            "   DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  \\\n",
            "0         23.0          14.5  2023      8    1            25               9   \n",
            "1         19.0           6.5  2023      8    2            13              20   \n",
            "2          3.5          18.0  2023      8    3            21              31   \n",
            "3         25.0           4.5  2023      8    4            15               5   \n",
            "4         33.0          10.5  2023      8    5            13              28   \n",
            "\n",
            "   Prev_Evening  Prev_Night  Prediction1  \n",
            "0             7           5            0  \n",
            "1            26          18            0  \n",
            "2             7          28            0  \n",
            "3             2           2            0  \n",
            "4            22          12            0  \n",
            "\n",
            "[5 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.2: Converting the columns to integer in both datasets (excluding 'Date')\n",
        "\n",
        "# Load the most recent CSVs\n",
        "train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/K_Handled_Prediction1_Train_Test_Data.csv')\n",
        "unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/L_Handled_Prediction1_Unseen_Data.csv')\n",
        "\n",
        "# List of columns to convert to integer (excluding 'Data_Type' and 'Date')\n",
        "columns_to_convert_train_test = [col for col in train_test_data.columns if col not in ['Data_Type', 'Date']]\n",
        "columns_to_convert_unseen = [col for col in unseen_data.columns if col not in ['Data_Type', 'Date']]\n",
        "\n",
        "# Convert columns to integer\n",
        "train_test_data[columns_to_convert_train_test] = train_test_data[columns_to_convert_train_test].astype(int)\n",
        "unseen_data[columns_to_convert_unseen] = unseen_data[columns_to_convert_unseen].astype(int)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/K_Handled_Prediction1_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/L_Handled_Prediction1_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the data types of the columns after conversion\n",
        "print(\"Data types of columns in train/test data after conversion:\")\n",
        "print(train_test_data.dtypes)\n",
        "\n",
        "print(\"\\nData types of columns in unseen data after conversion:\")\n",
        "print(unseen_data.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adGQ6YMGOsYv",
        "outputId": "15a80939-05e2-456d-d29d-4a92ca2477e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types of columns in train/test data after conversion:\n",
            "Date                object\n",
            "Row Number           int64\n",
            "Data_Type           object\n",
            "Draw1                int64\n",
            "DR1_Prev_Week        int64\n",
            "DR1_2Weeks           int64\n",
            "DR1_Prev_Entry       int64\n",
            "DR1_Prev_Entry-2     int64\n",
            "DR1_Mov_Avg          int64\n",
            "DR1_Vert_Avg         int64\n",
            "Draw2                int64\n",
            "DR2_Prev_Week        int64\n",
            "DR2_2Weeks           int64\n",
            "DR2_Prev_Entry       int64\n",
            "DR2_Prev_Entry-2     int64\n",
            "DR2_Mov_Avg          int64\n",
            "DR2_Vert_Avg         int64\n",
            "Draw3                int64\n",
            "DR3_Prev_Week        int64\n",
            "DR3_2Weeks           int64\n",
            "DR3_Prev_Entry       int64\n",
            "DR3_Prev_Entry-2     int64\n",
            "DR3_Mov_Avg          int64\n",
            "DR3_Vert_Avg         int64\n",
            "Draw4                int64\n",
            "DR4_Prev_Week        int64\n",
            "DR4_2Weeks           int64\n",
            "DR4_Prev_Entry       int64\n",
            "DR4_Prev_Entry-2     int64\n",
            "DR4_Mov_Avg          int64\n",
            "DR4_Vert_Avg         int64\n",
            "Year                 int64\n",
            "Month                int64\n",
            "Day                  int64\n",
            "Prev_Morning         int64\n",
            "Prev_Afternoon       int64\n",
            "Prev_Evening         int64\n",
            "Prev_Night           int64\n",
            "Prediction1          int64\n",
            "dtype: object\n",
            "\n",
            "Data types of columns in unseen data after conversion:\n",
            "Date                object\n",
            "Row Number           int64\n",
            "Data_Type           object\n",
            "Draw1                int64\n",
            "DR1_Prev_Week        int64\n",
            "DR1_2Weeks           int64\n",
            "DR1_Prev_Entry       int64\n",
            "DR1_Prev_Entry-2     int64\n",
            "DR1_Mov_Avg          int64\n",
            "DR1_Vert_Avg         int64\n",
            "Draw2                int64\n",
            "DR2_Prev_Week        int64\n",
            "DR2_2Weeks           int64\n",
            "DR2_Prev_Entry       int64\n",
            "DR2_Prev_Entry-2     int64\n",
            "DR2_Mov_Avg          int64\n",
            "DR2_Vert_Avg         int64\n",
            "Draw3                int64\n",
            "DR3_Prev_Week        int64\n",
            "DR3_2Weeks           int64\n",
            "DR3_Prev_Entry       int64\n",
            "DR3_Prev_Entry-2     int64\n",
            "DR3_Mov_Avg          int64\n",
            "DR3_Vert_Avg         int64\n",
            "Draw4                int64\n",
            "DR4_Prev_Week        int64\n",
            "DR4_2Weeks           int64\n",
            "DR4_Prev_Entry       int64\n",
            "DR4_Prev_Entry-2     int64\n",
            "DR4_Mov_Avg          int64\n",
            "DR4_Vert_Avg         int64\n",
            "Year                 int64\n",
            "Month                int64\n",
            "Day                  int64\n",
            "Prev_Morning         int64\n",
            "Prev_Afternoon       int64\n",
            "Prev_Evening         int64\n",
            "Prev_Night           int64\n",
            "Prediction1          int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.1: Introducing \"Lines\" as a new feature in both datasets\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define the directory for file paths\n",
        "base_dir = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/'\n",
        "\n",
        "# Load the most recent CSVs\n",
        "train_test_data = pd.read_csv(base_dir + 'K_Handled_Prediction1_Train_Test_Data.csv')\n",
        "unseen_data = pd.read_csv(base_dir + 'L_Handled_Prediction1_Unseen_Data.csv')\n",
        "\n",
        "# Directory of lines with corresponding numbers\n",
        "lines_directory = {\n",
        "    1: [1, 10, 19, 28],\n",
        "    2: [2, 11, 20, 29],\n",
        "    3: [3, 12, 21, 30],\n",
        "    4: [4, 13, 22, 31],\n",
        "    5: [5, 14, 23, 32],\n",
        "    6: [6, 15, 24, 33],\n",
        "    7: [7, 16, 25, 34],\n",
        "    8: [8, 17, 26, 35],\n",
        "    9: [9, 18, 27, 36],\n",
        "}\n",
        "\n",
        "# Function to calculate the sum of digits and map to a 'Line'\n",
        "def sum_to_line(x):\n",
        "    try:\n",
        "        sum_of_digits = sum(int(digit) for digit in str(x))\n",
        "        # Ensure the sum is between 1 and 9\n",
        "        while sum_of_digits > 9:\n",
        "            sum_of_digits = sum(int(digit) for digit in str(sum_of_digits))\n",
        "        return sum_of_digits\n",
        "    except ValueError:\n",
        "        # Return 0 if the value cannot be converted to an integer (e.g., missing or non-numeric data)\n",
        "        return 0\n",
        "\n",
        "# Create the 'Line_Prev_Entry' column\n",
        "train_test_data['Line_Prev_Entry'] = train_test_data['DR1_Prev_Entry'].apply(sum_to_line)\n",
        "unseen_data['Line_Prev_Entry'] = unseen_data['DR1_Prev_Entry'].apply(sum_to_line)\n",
        "\n",
        "# Function to extract numbers from the line subset for the active line\n",
        "def extract_line_numbers(row, lines_dict):\n",
        "    active_line = row['Line_Prev_Entry']\n",
        "    # Check if it's a day with no draws or an invalid line number\n",
        "    if active_line == 0 or active_line not in lines_dict:\n",
        "        # Set all numbers for this row to zero or NaN\n",
        "        for i in range(1, 5):\n",
        "            row[f'Line_PE_Num_{i}'] = 0  # Or use NaN if that's preferred\n",
        "    else:\n",
        "        # Populate the row with numbers from the active line\n",
        "        for i, num in enumerate(lines_dict[active_line], start=1):\n",
        "            row[f'Line_PE_Num_{i}'] = num\n",
        "    return row\n",
        "\n",
        "# Apply the function to each row of the DataFrame\n",
        "train_test_data = train_test_data.apply(lambda row: extract_line_numbers(row, lines_directory), axis=1)\n",
        "unseen_data = unseen_data.apply(lambda row: extract_line_numbers(row, lines_directory), axis=1)\n",
        "\n",
        "# Save the updated datasets with 'Lines' as new features\n",
        "train_test_data.to_csv(base_dir + 'M_Lines_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv(base_dir + 'N_Lines_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of both datasets to verify the \"Lines\" assignment\n",
        "print(\"First few rows of train/test data with 'Lines' assigned:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data with 'Lines' assigned:\")\n",
        "print(unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qBmKgOFOskq",
        "outputId": "1c6acb4f-fe5f-4874-e26a-b4a9d7d1a60e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of train/test data with 'Lines' assigned:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2018-08-01           1  Training     19              7          27   \n",
            "1  2018-08-02           2  Training     31             11           1   \n",
            "2  2018-08-03           3  Training     15             19          21   \n",
            "3  2018-08-04           4  Training     31             35          18   \n",
            "4  2018-08-05           5         0      0              0           0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0              23                32           27            17  ...   \n",
            "1               9                33           21             6  ...   \n",
            "2              12                35           23            20  ...   \n",
            "3              35                23           29            26  ...   \n",
            "4               0                 0            0             0  ...   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  Prediction1  \\\n",
            "0            13              34            32          23           19   \n",
            "1            19              14            33           9           31   \n",
            "2            31               3            35          12           15   \n",
            "3            15               9            23          35           31   \n",
            "4            31              21            29          16            0   \n",
            "\n",
            "   Line_Prev_Entry  Line_PE_Num_1  Line_PE_Num_2  Line_PE_Num_3  Line_PE_Num_4  \n",
            "0                5              5             14             23             32  \n",
            "1                9              9             18             27             36  \n",
            "2                3              3             12             21             30  \n",
            "3                8              8             17             26             35  \n",
            "4                0              0              0              0              0  \n",
            "\n",
            "[5 rows x 44 columns]\n",
            "\n",
            "First few rows of unseen data with 'Lines' assigned:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2023-08-01        1673    Unseen     13             27          25   \n",
            "1  2023-08-02        1674    Unseen     21             33          12   \n",
            "2  2023-08-03        1675    Unseen     15             27           3   \n",
            "3  2023-08-04        1676    Unseen     13             20          11   \n",
            "4  2023-08-05        1677    Unseen     12             29          14   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0               5                 7            6            26  ...   \n",
            "1              18                26           22            22  ...   \n",
            "2              28                 7           17            15  ...   \n",
            "3               2                 2            2            15  ...   \n",
            "4              12                22           17            21  ...   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  Prediction1  \\\n",
            "0            25               9             7           5            0   \n",
            "1            13              20            26          18            0   \n",
            "2            21              31             7          28            0   \n",
            "3            15               5             2           2            0   \n",
            "4            13              28            22          12            0   \n",
            "\n",
            "   Line_Prev_Entry  Line_PE_Num_1  Line_PE_Num_2  Line_PE_Num_3  Line_PE_Num_4  \n",
            "0                5              5             14             23             32  \n",
            "1                9              9             18             27             36  \n",
            "2                1              1             10             19             28  \n",
            "3                2              2             11             20             29  \n",
            "4                3              3             12             21             30  \n",
            "\n",
            "[5 rows x 44 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Cell 4.2: # Introducing \"Special Groups\" as a new feature in both datasets\n",
        "\n",
        "# Load the most recent CSVs\n",
        "#train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/M_Lines_Train_Test_Data.csv')\n",
        "#unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/N_Lines_Unseen_Data.csv')\n",
        "\n",
        "# Define the mapping for \"Special Groups\"\n",
        "#special_groups_mapping = {\n",
        "#    2: 1, 15: 1, 16: 1, 24: 1, 31: 1,  # \"Ladies\"\n",
        "#    4: 2, 5: 2, 12: 2, 29: 2, 34: 2,  # \"Men\"\n",
        "#    11: 3, 17: 3, 26: 3,  # \"Birds\"\n",
        "#    7: 4, 9: 4, 19: 4, 20: 4, 22: 4, 30: 4, 36: 4,  # \"Domestic Animals\"\n",
        "#    8: 5, 10: 5, 13: 5, 25: 5,  # \"Wild Animals\"\n",
        "#    18: 6, 28: 6, 32: 6,  # \"Ocean\"\n",
        "#    1: 7, 27: 7, 33: 7, 35: 7,  # \"Snakes & Insects\"\n",
        "#    3: 8, 6: 8, 14: 8, 21: 8, 23: 8  # \"Home\"\n",
        "#}\n",
        "\n",
        "# Function to assign \"Special Groups\" based on the mapping\n",
        "#def assign_special_groups(data, column_name, special_groups_mapping):\n",
        "#    data[f'Special_Groups_{column_name}'] = data[column_name].map(special_groups_mapping).fillna(0).astype(int)\n",
        "\n",
        "# List of columns to assign \"Special Groups\"\n",
        "#columns_to_assign_special_groups = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "\n",
        "# Assign \"Special Groups\" for specified columns in train/test data\n",
        "#for column in columns_to_assign_special_groups:\n",
        "#    assign_special_groups(train_test_data, column, special_groups_mapping)\n",
        "\n",
        "# Assign \"Special Groups\" for specified columns in unseen data\n",
        "#for column in columns_to_assign_special_groups:\n",
        "#    assign_special_groups(unseen_data, column, special_groups_mapping)\n",
        "\n",
        "# Save the updated datasets\n",
        "#train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/O_Special_Groups_Train_Test_Data.csv', index=False)\n",
        "#unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/P_Special_Groups_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of both datasets to verify the \"Special Groups\" assignment\n",
        "#print(\"First few rows of train/test data with 'Special Groups' assigned:\")\n",
        "#print(train_test_data.head())\n",
        "\n",
        "#print(\"\\nFirst few rows of unseen data with 'Special Groups' assigned:\")\n",
        "#print(unseen_data.head())\n"
      ],
      "metadata": {
        "id": "U8TauDfPOtKG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.3: Introducing \"Spirits\" as a new feature in both datasets\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define the directory for file paths\n",
        "base_dir = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/'\n",
        "\n",
        "# Load the most recent CSVs\n",
        "train_test_data = pd.read_csv(base_dir + 'M_Lines_Train_Test_Data.csv')\n",
        "unseen_data = pd.read_csv(base_dir + 'N_Lines_Unseen_Data.csv')\n",
        "\n",
        "# Define a mapping dictionary for \"Spirits\" pairs\n",
        "spirits_mapping = {\n",
        "    1: 5,\n",
        "    2: 24,\n",
        "    3: 19,\n",
        "    4: 35,\n",
        "    5: 1,\n",
        "    6: 15,\n",
        "    7: 13,\n",
        "    8: 29,\n",
        "    9: 33,\n",
        "    10: 28,\n",
        "    11: 36,\n",
        "    12: 32,\n",
        "    13: 7,\n",
        "    14: 25,\n",
        "    15: 6,\n",
        "    16: 17,\n",
        "    17: 16,\n",
        "    18: 30,\n",
        "    19: 3,\n",
        "    20: 22,\n",
        "    21: 23,\n",
        "    22: 20,\n",
        "    23: 21,\n",
        "    24: 2,\n",
        "    25: 14,\n",
        "    26: 27,\n",
        "    27: 26,\n",
        "    28: 10,\n",
        "    29: 8,\n",
        "    30: 18,\n",
        "    31: 34,\n",
        "    32: 12,\n",
        "    33: 9,\n",
        "    34: 31,\n",
        "    35: 4,\n",
        "    36: 11\n",
        "}\n",
        "\n",
        "# Function to map \"DR1_Prev_Entry\" to its spirit pair\n",
        "def map_to_spirit(x, spirits_dict):\n",
        "    # Return the corresponding spirit number or None if not found\n",
        "    return spirits_dict.get(x)\n",
        "\n",
        "# Create the 'Spirit_PE_Num' column\n",
        "train_test_data['Spirit_PE_Num'] = train_test_data['DR1_Prev_Entry'].apply(lambda x: map_to_spirit(x, spirits_mapping))\n",
        "unseen_data['Spirit_PE_Num'] = unseen_data['DR1_Prev_Entry'].apply(lambda x: map_to_spirit(x, spirits_mapping))\n",
        "\n",
        "# Replace NaNs with 0 and convert to int\n",
        "train_test_data['Spirit_PE_Num'] = train_test_data['Spirit_PE_Num'].fillna(0).astype(int)\n",
        "unseen_data['Spirit_PE_Num'] = unseen_data['Spirit_PE_Num'].fillna(0).astype(int)\n",
        "\n",
        "# Save the updated datasets with 'Spirits' as new features\n",
        "train_test_data.to_csv(base_dir + 'O_Spirits_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv(base_dir + 'P_Spirits_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of both datasets to verify the \"Spirits\" assignment\n",
        "print(\"First few rows of train/test data with 'Spirits' assigned:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data with 'Spirits' assigned:\")\n",
        "print(unseen_data.head())\n"
      ],
      "metadata": {
        "id": "_8T-Y4tK20PV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ad75de-76be-4e24-eba1-9a17bbb5c482"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of train/test data with 'Spirits' assigned:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2018-08-01           1  Training     19              7          27   \n",
            "1  2018-08-02           2  Training     31             11           1   \n",
            "2  2018-08-03           3  Training     15             19          21   \n",
            "3  2018-08-04           4  Training     31             35          18   \n",
            "4  2018-08-05           5         0      0              0           0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0              23                32           27            17  ...   \n",
            "1               9                33           21             6  ...   \n",
            "2              12                35           23            20  ...   \n",
            "3              35                23           29            26  ...   \n",
            "4               0                 0            0             0  ...   \n",
            "\n",
            "   Prev_Afternoon  Prev_Evening  Prev_Night  Prediction1  Line_Prev_Entry  \\\n",
            "0              34            32          23           19                5   \n",
            "1              14            33           9           31                9   \n",
            "2               3            35          12           15                3   \n",
            "3               9            23          35           31                8   \n",
            "4              21            29          16            0                0   \n",
            "\n",
            "   Line_PE_Num_1  Line_PE_Num_2  Line_PE_Num_3  Line_PE_Num_4  Spirit_PE_Num  \n",
            "0              5             14             23             32             21  \n",
            "1              9             18             27             36             33  \n",
            "2              3             12             21             30             32  \n",
            "3              8             17             26             35              4  \n",
            "4              0              0              0              0              0  \n",
            "\n",
            "[5 rows x 45 columns]\n",
            "\n",
            "First few rows of unseen data with 'Spirits' assigned:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2023-08-01        1673    Unseen     13             27          25   \n",
            "1  2023-08-02        1674    Unseen     21             33          12   \n",
            "2  2023-08-03        1675    Unseen     15             27           3   \n",
            "3  2023-08-04        1676    Unseen     13             20          11   \n",
            "4  2023-08-05        1677    Unseen     12             29          14   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0               5                 7            6            26  ...   \n",
            "1              18                26           22            22  ...   \n",
            "2              28                 7           17            15  ...   \n",
            "3               2                 2            2            15  ...   \n",
            "4              12                22           17            21  ...   \n",
            "\n",
            "   Prev_Afternoon  Prev_Evening  Prev_Night  Prediction1  Line_Prev_Entry  \\\n",
            "0               9             7           5            0                5   \n",
            "1              20            26          18            0                9   \n",
            "2              31             7          28            0                1   \n",
            "3               5             2           2            0                2   \n",
            "4              28            22          12            0                3   \n",
            "\n",
            "   Line_PE_Num_1  Line_PE_Num_2  Line_PE_Num_3  Line_PE_Num_4  Spirit_PE_Num  \n",
            "0              5             14             23             32              1  \n",
            "1              9             18             27             36             30  \n",
            "2              1             10             19             28             10  \n",
            "3              2             11             20             29             24  \n",
            "4              3             12             21             30             32  \n",
            "\n",
            "[5 rows x 45 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.4: Introducing \"Rakes\" as a new feature in both datasets\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define the directory for file paths\n",
        "base_dir = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/'\n",
        "\n",
        "# Load the most recent CSVs\n",
        "train_test_data = pd.read_csv(base_dir + 'O_Spirits_Train_Test_Data.csv')\n",
        "unseen_data = pd.read_csv(base_dir + 'P_Spirits_Unseen_Data.csv')\n",
        "\n",
        "# Define a mapping dictionary for \"Rakes\" numbers\n",
        "rakes_mapping = {\n",
        "    1: [7, 12, 15, 36],\n",
        "    2: [4, 14, 16, 23],\n",
        "    3: [19, 22, 34, 35],\n",
        "    4: [7, 11, 14, 32],\n",
        "    5: [20, 23, 31, 33],\n",
        "    6: [14, 24, 30, 32],\n",
        "    7: [4, 11, 24, 29],\n",
        "    8: [12, 14, 33, 36],\n",
        "    9: [7, 11, 24, 32],\n",
        "    10: [7, 12, 15, 36],\n",
        "    11: [4, 7, 17, 22],\n",
        "    12: [1, 10, 28, 35],\n",
        "    13: [10, 25, 28, 29],\n",
        "    14: [16, 23, 31, 33],\n",
        "    15: [5, 6, 23, 36],\n",
        "    16: [14, 31, 35, 36],\n",
        "    17: [11, 16, 26, 29],\n",
        "    18: [5, 7, 28, 33],\n",
        "    19: [10, 27, 32, 36],\n",
        "    20: [4, 14, 24, 30],\n",
        "    21: [16, 22, 24, 29],\n",
        "    22: [11, 30, 32, 34],\n",
        "    23: [12, 14, 16, 20],\n",
        "    24: [2, 6, 12, 21],\n",
        "    25: [1, 3, 13, 18],\n",
        "    26: [1, 2, 11, 17],\n",
        "    27: [14, 16, 19, 35],\n",
        "    28: [12, 13, 18, 33],\n",
        "    29: [7, 13, 16, 28],\n",
        "    30: [6, 8, 20, 22],\n",
        "    31: [5, 14, 16, 36],\n",
        "    32: [4, 6, 28, 36],\n",
        "    33: [5, 10, 14, 20],\n",
        "    34: [1, 12, 20, 22],\n",
        "    35: [3, 12, 14, 16],\n",
        "    36: [1, 8, 16, 32],\n",
        "}\n",
        "\n",
        "# Function to assign \"Rakes\" based on the 'DR1_Prev_Entry' value\n",
        "def assign_rakes(data, column_name, rakes_dict):\n",
        "    # Create new columns for Rakes numbers\n",
        "    for i in range(1, 5):\n",
        "        data[f'Rake_PE_Num_{i}'] = 0\n",
        "\n",
        "    # Populate Rakes numbers\n",
        "    for index, row in data.iterrows():\n",
        "        rakes_numbers = rakes_dict.get(row[column_name], [0, 0, 0, 0])\n",
        "        for i, rake_num in enumerate(rakes_numbers, start=1):\n",
        "            data.at[index, f'Rake_PE_Num_{i}'] = rake_num\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply 'assign_rakes' function to create new Rakes columns\n",
        "train_test_data = assign_rakes(train_test_data, 'DR1_Prev_Entry', rakes_mapping)\n",
        "unseen_data = assign_rakes(unseen_data, 'DR1_Prev_Entry', rakes_mapping)\n",
        "\n",
        "# Save the updated datasets with 'Rakes' as new features\n",
        "train_test_data.to_csv(base_dir + 'Q_Rakes_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv(base_dir + 'R_Rakes_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of both datasets to verify the \"Rakes\" assignment\n",
        "print(\"First few rows of train/test data with 'Rakes' assigned:\")\n",
        "print(train_test_data[['DR1_Prev_Entry', 'Rake_PE_Num_1', 'Rake_PE_Num_2', 'Rake_PE_Num_3', 'Rake_PE_Num_4']].head())\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data with 'Rakes' assigned:\")\n",
        "print(unseen_data[['DR1_Prev_Entry', 'Rake_PE_Num_1', 'Rake_PE_Num_2', 'Rake_PE_Num_3', 'Rake_PE_Num_4']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNf2x1Y8IVe5",
        "outputId": "3aa68712-a986-47a7-a1e7-c594b1e97d84"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of train/test data with 'Rakes' assigned:\n",
            "   DR1_Prev_Entry  Rake_PE_Num_1  Rake_PE_Num_2  Rake_PE_Num_3  Rake_PE_Num_4\n",
            "0              23             12             14             16             20\n",
            "1               9              7             11             24             32\n",
            "2              12              1             10             28             35\n",
            "3              35              3             12             14             16\n",
            "4               0              0              0              0              0\n",
            "\n",
            "First few rows of unseen data with 'Rakes' assigned:\n",
            "   DR1_Prev_Entry  Rake_PE_Num_1  Rake_PE_Num_2  Rake_PE_Num_3  Rake_PE_Num_4\n",
            "0               5             20             23             31             33\n",
            "1              18              5              7             28             33\n",
            "2              28             12             13             18             33\n",
            "3               2              4             14             16             23\n",
            "4              12              1             10             28             35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5.1: Final checks and verifications.\n",
        "\n",
        "# Check for NaN values in train/test data\n",
        "print(\"NaN check for train/test data:\")\n",
        "print(train_test_data.isnull().sum())\n",
        "\n",
        "# Check data types in train/test data\n",
        "print(\"\\nData types in train/test data:\")\n",
        "print(train_test_data.dtypes)\n",
        "\n",
        "# Check for NaN values in unseen data\n",
        "print(\"\\nNaN check for unseen data:\")\n",
        "print(unseen_data.isnull().sum())\n",
        "\n",
        "# Check data types in unseen data\n",
        "print(\"\\nData types in unseen data:\")\n",
        "print(unseen_data.dtypes)\n"
      ],
      "metadata": {
        "id": "FPuNXxZPG2Rf",
        "outputId": "8a399f0b-15e4-4f91-842c-87a20d90c41d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN check for train/test data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "Prev_Morning        0\n",
            "Prev_Afternoon      0\n",
            "Prev_Evening        0\n",
            "Prev_Night          0\n",
            "Prediction1         0\n",
            "Line_Prev_Entry     0\n",
            "Line_PE_Num_1       0\n",
            "Line_PE_Num_2       0\n",
            "Line_PE_Num_3       0\n",
            "Line_PE_Num_4       0\n",
            "Spirit_PE_Num       0\n",
            "Rake_PE_Num_1       0\n",
            "Rake_PE_Num_2       0\n",
            "Rake_PE_Num_3       0\n",
            "Rake_PE_Num_4       0\n",
            "dtype: int64\n",
            "\n",
            "Data types in train/test data:\n",
            "Date                object\n",
            "Row Number           int64\n",
            "Data_Type           object\n",
            "Draw1                int64\n",
            "DR1_Prev_Week        int64\n",
            "DR1_2Weeks           int64\n",
            "DR1_Prev_Entry       int64\n",
            "DR1_Prev_Entry-2     int64\n",
            "DR1_Mov_Avg          int64\n",
            "DR1_Vert_Avg         int64\n",
            "Draw2                int64\n",
            "DR2_Prev_Week        int64\n",
            "DR2_2Weeks           int64\n",
            "DR2_Prev_Entry       int64\n",
            "DR2_Prev_Entry-2     int64\n",
            "DR2_Mov_Avg          int64\n",
            "DR2_Vert_Avg         int64\n",
            "Draw3                int64\n",
            "DR3_Prev_Week        int64\n",
            "DR3_2Weeks           int64\n",
            "DR3_Prev_Entry       int64\n",
            "DR3_Prev_Entry-2     int64\n",
            "DR3_Mov_Avg          int64\n",
            "DR3_Vert_Avg         int64\n",
            "Draw4                int64\n",
            "DR4_Prev_Week        int64\n",
            "DR4_2Weeks           int64\n",
            "DR4_Prev_Entry       int64\n",
            "DR4_Prev_Entry-2     int64\n",
            "DR4_Mov_Avg          int64\n",
            "DR4_Vert_Avg         int64\n",
            "Year                 int64\n",
            "Month                int64\n",
            "Day                  int64\n",
            "Prev_Morning         int64\n",
            "Prev_Afternoon       int64\n",
            "Prev_Evening         int64\n",
            "Prev_Night           int64\n",
            "Prediction1          int64\n",
            "Line_Prev_Entry      int64\n",
            "Line_PE_Num_1        int64\n",
            "Line_PE_Num_2        int64\n",
            "Line_PE_Num_3        int64\n",
            "Line_PE_Num_4        int64\n",
            "Spirit_PE_Num        int64\n",
            "Rake_PE_Num_1        int64\n",
            "Rake_PE_Num_2        int64\n",
            "Rake_PE_Num_3        int64\n",
            "Rake_PE_Num_4        int64\n",
            "dtype: object\n",
            "\n",
            "NaN check for unseen data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "Prev_Morning        0\n",
            "Prev_Afternoon      0\n",
            "Prev_Evening        0\n",
            "Prev_Night          0\n",
            "Prediction1         0\n",
            "Line_Prev_Entry     0\n",
            "Line_PE_Num_1       0\n",
            "Line_PE_Num_2       0\n",
            "Line_PE_Num_3       0\n",
            "Line_PE_Num_4       0\n",
            "Spirit_PE_Num       0\n",
            "Rake_PE_Num_1       0\n",
            "Rake_PE_Num_2       0\n",
            "Rake_PE_Num_3       0\n",
            "Rake_PE_Num_4       0\n",
            "dtype: int64\n",
            "\n",
            "Data types in unseen data:\n",
            "Date                object\n",
            "Row Number           int64\n",
            "Data_Type           object\n",
            "Draw1                int64\n",
            "DR1_Prev_Week        int64\n",
            "DR1_2Weeks           int64\n",
            "DR1_Prev_Entry       int64\n",
            "DR1_Prev_Entry-2     int64\n",
            "DR1_Mov_Avg          int64\n",
            "DR1_Vert_Avg         int64\n",
            "Draw2                int64\n",
            "DR2_Prev_Week        int64\n",
            "DR2_2Weeks           int64\n",
            "DR2_Prev_Entry       int64\n",
            "DR2_Prev_Entry-2     int64\n",
            "DR2_Mov_Avg          int64\n",
            "DR2_Vert_Avg         int64\n",
            "Draw3                int64\n",
            "DR3_Prev_Week        int64\n",
            "DR3_2Weeks           int64\n",
            "DR3_Prev_Entry       int64\n",
            "DR3_Prev_Entry-2     int64\n",
            "DR3_Mov_Avg          int64\n",
            "DR3_Vert_Avg         int64\n",
            "Draw4                int64\n",
            "DR4_Prev_Week        int64\n",
            "DR4_2Weeks           int64\n",
            "DR4_Prev_Entry       int64\n",
            "DR4_Prev_Entry-2     int64\n",
            "DR4_Mov_Avg          int64\n",
            "DR4_Vert_Avg         int64\n",
            "Year                 int64\n",
            "Month                int64\n",
            "Day                  int64\n",
            "Prev_Morning         int64\n",
            "Prev_Afternoon       int64\n",
            "Prev_Evening         int64\n",
            "Prev_Night           int64\n",
            "Prediction1          int64\n",
            "Line_Prev_Entry      int64\n",
            "Line_PE_Num_1        int64\n",
            "Line_PE_Num_2        int64\n",
            "Line_PE_Num_3        int64\n",
            "Line_PE_Num_4        int64\n",
            "Spirit_PE_Num        int64\n",
            "Rake_PE_Num_1        int64\n",
            "Rake_PE_Num_2        int64\n",
            "Rake_PE_Num_3        int64\n",
            "Rake_PE_Num_4        int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the first copy to the first directory\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/S_Final_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/T_Final_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Save the second copy to the second directory AS INITIAL DATASETS FOR DRAW 1 PREDICTIVE SCRIPT\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Draw1_Predictive_Model/A_Initial_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Draw1_Predictive_Model/B_Initial_Unseen_Data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "lixNbXei4ghR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# :::::**THE END** *Thank You*:::::"
      ],
      "metadata": {
        "id": "c7irQ4xrLOIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Last Revision***\n",
        "***04/02/24***\n",
        "11:24pm"
      ],
      "metadata": {
        "id": "PRJWR0NLS1Ui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Revision***\n",
        "27/3/24\n",
        "*Updated Unseen Results up to 30/11/23*"
      ],
      "metadata": {
        "id": "jauzzY0jdZzZ"
      }
    }
  ]
}