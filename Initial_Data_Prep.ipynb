{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOInRETnsPqCI6DGyul9u3p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvinfranklyndavis/Draw1_Predictive_Model/blob/main/Initial_Data_Prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1.1: Package Installation and Library Import\n",
        "\n",
        "# Check for existing libraries\n",
        "!pip show pandas numpy\n",
        "\n",
        "# Install or upgrade required packages\n",
        "!pip install -U --upgrade-strategy eager pip\n",
        "!pip install -U --upgrade-strategy eager pandas==<desired_version> numpy==<desired_version>\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Set up logging to save logs in a file\n",
        "log_file = 'project.log'\n",
        "logging.basicConfig(filename=log_file, level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Set up virtual environment (optional but recommended)\n",
        "# You can create a virtual environment with: !python -m venv myenv\n",
        "# And activate it with: source myenv/bin/activate (Linux/macOS) or myenv\\Scripts\\activate (Windows)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plnc-ffhAUCk",
        "outputId": "a7e28d2a-081b-42e5-8507-e545d2e2c8d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pandas\n",
            "Version: 1.5.3\n",
            "Summary: Powerful data structures for data analysis, time series, and statistics\n",
            "Home-page: https://pandas.pydata.org\n",
            "Author: The Pandas Development Team\n",
            "Author-email: pandas-dev@python.org\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, python-dateutil, pytz\n",
            "Required-by: altair, arviz, bigframes, bokeh, bqplot, cmdstanpy, cufflinks, datascience, db-dtypes, dopamine-rl, fastai, geemap, geopandas, google-colab, gspread-dataframe, holoviews, ibis-framework, lida, mizani, mlxtend, pandas-datareader, pandas-gbq, panel, pins, plotnine, prophet, pymc, seaborn, sklearn-pandas, statsmodels, vega-datasets, xarray, yfinance\n",
            "---\n",
            "Name: numpy\n",
            "Version: 1.23.5\n",
            "Summary: NumPy is the fundamental package for array computing with Python.\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: \n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: albumentations, altair, arviz, astropy, autograd, blis, bokeh, bqplot, chex, cmdstanpy, contourpy, cufflinks, cupy-cuda12x, cvxpy, datascience, db-dtypes, dopamine-rl, ecos, flax, folium, geemap, gensim, gym, h5py, holoviews, hyperopt, ibis-framework, imageio, imbalanced-learn, imgaug, jax, jaxlib, librosa, lida, lightgbm, matplotlib, matplotlib-venn, missingno, mizani, ml-dtypes, mlxtend, moviepy, music21, nibabel, numba, numexpr, opencv-contrib-python, opencv-python, opencv-python-headless, opt-einsum, optax, orbax-checkpoint, osqp, pandas, pandas-gbq, patsy, plotnine, prophet, pyarrow, pycocotools, pyerfa, pymc, pytensor, python-louvain, PyWavelets, qdldl, qudida, scikit-image, scikit-learn, scipy, scs, seaborn, shapely, sklearn-pandas, soxr, spacy, stanio, statsmodels, tables, tensorboard, tensorflow, tensorflow-datasets, tensorflow-hub, tensorflow-probability, tensorstore, thinc, tifffile, torchtext, torchvision, transformers, wordcloud, xarray, xarray-einstats, xgboost, yellowbrick, yfinance\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.2\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `pip install -U --upgrade-strategy eager pandas==<desired_version> numpy==<desired_version>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.2: Data Loading from Google Drive Training / Testing  and Unseen datasets\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the directory for datasets in Google Drive\n",
        "drive_dataset_directory = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/'\n",
        "\n",
        "# Define the paths to the CSV files\n",
        "csv_filename_train_test = 'A_Initial_Train_Test_Data.csv'\n",
        "csv_filename_unseen = 'B_Initial_Unseen_Data.csv'\n",
        "\n",
        "drive_csv_path_train_test = os.path.join(drive_dataset_directory, csv_filename_train_test)\n",
        "drive_csv_path_unseen = os.path.join(drive_dataset_directory, csv_filename_unseen)\n",
        "\n",
        "# Check and load the datasets\n",
        "def load_dataset(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        print(\"File found. Proceeding to load the dataset.\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"File not found. Check the file path or the Google Drive mount.\")\n",
        "        return None\n",
        "\n",
        "# Load training/testing data\n",
        "train_test_data = load_dataset(drive_csv_path_train_test)\n",
        "\n",
        "# Load unseen data\n",
        "unseen_data = load_dataset(drive_csv_path_unseen)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of training/testing data:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data:\")\n",
        "print(unseen_data.head())\n"
      ],
      "metadata": {
        "id": "fP_Q74gUBGQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "992d10d8-c912-4a01-b79d-498ca5173641"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of training/testing data:\n",
            "       Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  01-08-18           1  Training   19.0            7.0        27.0   \n",
            "1  02-08-18           2  Training   31.0           11.0         1.0   \n",
            "2  03-08-18           3  Training   15.0           19.0        21.0   \n",
            "3  04-08-18           4  Training   31.0           35.0        18.0   \n",
            "4  05-08-18           5       NaN    NaN            NaN         NaN   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0            23.0              32.0         27.5          17.0  ...   \n",
            "1             9.0              33.0         21.0           6.0  ...   \n",
            "2            12.0              35.0         23.5          20.0  ...   \n",
            "3            35.0              23.0         29.0          26.5  ...   \n",
            "4             NaN               NaN          NaN           NaN  ...   \n",
            "\n",
            "   DR3_Prev_Entry-2  DR3_Mov_Avg  DR3_Vert_Avg  Draw4  DR4_Prev_Week  \\\n",
            "0              19.0         16.5          15.0    9.0            2.0   \n",
            "1              31.0         17.0          17.0   12.0           35.0   \n",
            "2              15.0         12.0          10.0   35.0           11.0   \n",
            "3              31.0         26.0          23.5   16.0           13.0   \n",
            "4               NaN          NaN           NaN    NaN            NaN   \n",
            "\n",
            "   DR4_2Weeks  DR4_Prev_Entry  DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  \n",
            "0        24.0            33.0              14.0         23.5          13.0  \n",
            "1        26.0            35.0               3.0         19.0          30.5  \n",
            "2        29.0            23.0               9.0         16.0          20.0  \n",
            "3        17.0            29.0              21.0         25.0          15.0  \n",
            "4         NaN             NaN               NaN          NaN           NaN  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "First few rows of unseen data:\n",
            "       Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  1/8/2023        1410    Unseen   13.0           27.0        25.0   \n",
            "1  2/8/2023        1411    Unseen   21.0           33.0        12.0   \n",
            "2  3/8/2023        1412    Unseen   15.0           27.0         3.0   \n",
            "3  4/8/2023        1413    Unseen   13.0           20.0        11.0   \n",
            "4  5/8/2023        1414    Unseen   12.0           29.0        14.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0             5.0               7.0          6.0          26.0  ...   \n",
            "1            18.0              26.0         22.0          22.5  ...   \n",
            "2            28.0               7.0         17.5          15.0  ...   \n",
            "3             2.0               2.0          2.0          15.5  ...   \n",
            "4            12.0              22.0         17.0          21.5  ...   \n",
            "\n",
            "   DR3_Prev_Entry-2  DR3_Mov_Avg  DR3_Vert_Avg  Draw4  DR4_Prev_Week  \\\n",
            "0              13.0         16.5          25.0   18.0           26.0   \n",
            "1              21.0         26.0           6.0   28.0            8.0   \n",
            "2              15.0         10.0          18.0    2.0           30.0   \n",
            "3              13.0         20.5          26.0   12.0            2.0   \n",
            "4              12.0         23.5          18.5   11.0            3.0   \n",
            "\n",
            "   DR4_2Weeks  DR4_Prev_Entry  DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  \n",
            "0         3.0            26.0              20.0         23.0          14.5  \n",
            "1         5.0             7.0              31.0         19.0           6.5  \n",
            "2         6.0             2.0               5.0          3.5          18.0  \n",
            "3         7.0            22.0              28.0         25.0           4.5  \n",
            "4        18.0            31.0              35.0         33.0          10.5  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.3: Surveillance Check for NaNs within both datasets\n",
        "\n",
        "# Check for NaN values in training/testing data\n",
        "print(\"NaN check for training/testing data:\")\n",
        "print(train_test_data.isna().sum())\n",
        "\n",
        "# Check for NaN values in unseen data\n",
        "print(\"\\nNaN check for unseen data:\")\n",
        "print(unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2THl1IOP57A7",
        "outputId": "efc0599a-a1d1-4719-b6bf-2e8985af7a3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN check for training/testing data:\n",
            "Date                  0\n",
            "Row Number            0\n",
            "Data_Type           239\n",
            "Draw1               239\n",
            "DR1_Prev_Week       239\n",
            "DR1_2Weeks          239\n",
            "DR1_Prev_Entry      239\n",
            "DR1_Prev_Entry-2    239\n",
            "DR1_Mov_Avg         239\n",
            "DR1_Vert_Avg        239\n",
            "Draw2               239\n",
            "DR2_Prev_Week       239\n",
            "DR2_2Weeks          239\n",
            "DR2_Prev_Entry      239\n",
            "DR2_Prev_Entry-2    239\n",
            "DR2_Mov_Avg         239\n",
            "DR2_Vert_Avg        239\n",
            "Draw3               239\n",
            "DR3_Prev_Week       239\n",
            "DR3_2Weeks          239\n",
            "DR3_Prev_Entry      239\n",
            "DR3_Prev_Entry-2    239\n",
            "DR3_Mov_Avg         239\n",
            "DR3_Vert_Avg        239\n",
            "Draw4               239\n",
            "DR4_Prev_Week       239\n",
            "DR4_2Weeks          239\n",
            "DR4_Prev_Entry      239\n",
            "DR4_Prev_Entry-2    239\n",
            "DR4_Mov_Avg         239\n",
            "DR4_Vert_Avg        239\n",
            "dtype: int64\n",
            "\n",
            "NaN check for unseen data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           4\n",
            "Draw1               4\n",
            "DR1_Prev_Week       4\n",
            "DR1_2Weeks          4\n",
            "DR1_Prev_Entry      4\n",
            "DR1_Prev_Entry-2    4\n",
            "DR1_Mov_Avg         4\n",
            "DR1_Vert_Avg        4\n",
            "Draw2               4\n",
            "DR2_Prev_Week       4\n",
            "DR2_2Weeks          4\n",
            "DR2_Prev_Entry      4\n",
            "DR2_Prev_Entry-2    4\n",
            "DR2_Mov_Avg         4\n",
            "DR2_Vert_Avg        4\n",
            "Draw3               4\n",
            "DR3_Prev_Week       4\n",
            "DR3_2Weeks          4\n",
            "DR3_Prev_Entry      4\n",
            "DR3_Prev_Entry-2    4\n",
            "DR3_Mov_Avg         4\n",
            "DR3_Vert_Avg        4\n",
            "Draw4               4\n",
            "DR4_Prev_Week       4\n",
            "DR4_2Weeks          4\n",
            "DR4_Prev_Entry      4\n",
            "DR4_Prev_Entry-2    4\n",
            "DR4_Mov_Avg         4\n",
            "DR4_Vert_Avg        4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.1: NaN handling and new CSV saving for Training / Testing  and Unseen datasets\n",
        "\n",
        "\n",
        "# Impute NaN values with zeros in training/testing data\n",
        "train_test_data = train_test_data.fillna(0)\n",
        "\n",
        "# Impute NaN values with zeros in unseen data\n",
        "unseen_data = unseen_data.fillna(0)\n",
        "\n",
        "# Define new CSV file names\n",
        "new_csv_filename_train_test = 'C_NaN_Handled_Train_Test_Data.csv'\n",
        "new_csv_filename_unseen = 'D_NaN_Handled_Unseen_Data.csv'\n",
        "\n",
        "# Define the paths for saving the new CSV files\n",
        "new_csv_path_train_test = os.path.join(drive_dataset_directory, new_csv_filename_train_test)\n",
        "new_csv_path_unseen = os.path.join(drive_dataset_directory, new_csv_filename_unseen)\n",
        "\n",
        "# Save the preprocessed training/testing data as a new CSV file\n",
        "train_test_data.to_csv(new_csv_path_train_test, index=False)\n",
        "\n",
        "# Save the preprocessed unseen data as a new CSV file\n",
        "unseen_data.to_csv(new_csv_path_unseen, index=False)\n",
        "\n",
        "# Print a message to confirm that the preprocessing and saving is complete\n",
        "print(\"Preprocessing and saving of datasets is complete.\")\n",
        "\n",
        "# Check for NaN values in the preprocessed training/testing data\n",
        "print(\"\\nNaN check for preprocessed training/testing data:\")\n",
        "print(train_test_data.isna().sum())\n",
        "\n",
        "# Check for NaN values in the preprocessed unseen data\n",
        "print(\"\\nNaN check for preprocessed unseen data:\")\n",
        "print(unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7QU7JyA8B8b",
        "outputId": "00a5a591-a724-48ae-d126-5cf3f3abb14f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing and saving of datasets is complete.\n",
            "\n",
            "NaN check for preprocessed training/testing data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "dtype: int64\n",
            "\n",
            "NaN check for preprocessed unseen data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.2: Extract Y/M/D from Date and new CSV saving for Training / Testing  and Unseen datasets\n",
        "\n",
        "# Load the NaN-handled training/testing data\n",
        "nan_handled_train_test_data = load_dataset(new_csv_path_train_test)\n",
        "\n",
        "# Load the NaN-handled unseen data\n",
        "nan_handled_unseen_data = load_dataset(new_csv_path_unseen)\n",
        "\n",
        "# Check and load the datasets\n",
        "def load_dataset(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        print(\"File found. Proceeding to load the dataset.\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"File not found. Check the file path.\")\n",
        "        return None\n",
        "\n",
        "# Function to extract 'Year', 'Month', and 'Day' from the 'Date' column\n",
        "def extract_date_features(data):\n",
        "    if 'Date' in data.columns:\n",
        "        print(\"Converting 'Date' to datetime and extracting Year, Month, and Day...\")\n",
        "        date_formats = ['%d-%m-%y', '%d/%m/%Y']\n",
        "        for date_format in date_formats:\n",
        "            try:\n",
        "                data['Date'] = pd.to_datetime(data['Date'], format=date_format)\n",
        "                data['Year'] = data['Date'].dt.year.fillna(0).astype(int)\n",
        "                data['Month'] = data['Date'].dt.month.fillna(0).astype(int)\n",
        "                data['Day'] = data['Date'].dt.day.fillna(0).astype(int)\n",
        "                print(\"After extracting Year, Month, and Day:\", data.columns)\n",
        "                break  # Break the loop if successful date conversion\n",
        "            except ValueError:\n",
        "                print(f\"Failed to convert 'Date' with format: {date_format}\")\n",
        "    else:\n",
        "        print(\"'Date' column not found in the dataset.\")\n",
        "\n",
        "# Extract 'Year', 'Month', and 'Day' from the 'Date' column in training/testing data\n",
        "extract_date_features(nan_handled_train_test_data)\n",
        "\n",
        "# Extract 'Year', 'Month', and 'Day' from the 'Date' column in unseen data\n",
        "extract_date_features(nan_handled_unseen_data)\n",
        "\n",
        "# Define new CSV file names\n",
        "new_csv_filename_train_test_date = 'E_Date_Extracted_Train_Test_Data.csv'\n",
        "new_csv_filename_unseen_date = 'F_Date_Extracted_Unseen_Data.csv'\n",
        "\n",
        "# Define the paths for saving the new CSV files\n",
        "new_csv_path_train_test_date = os.path.join(drive_dataset_directory, new_csv_filename_train_test_date)\n",
        "new_csv_path_unseen_date = os.path.join(drive_dataset_directory, new_csv_filename_unseen_date)\n",
        "\n",
        "# Save the datasets with extracted date features as new CSV files\n",
        "nan_handled_train_test_data.to_csv(new_csv_path_train_test_date, index=False)\n",
        "nan_handled_unseen_data.to_csv(new_csv_path_unseen_date, index=False)\n",
        "\n",
        "# Print a message to confirm that the date extraction and saving is complete\n",
        "print(\"Date extraction and saving of datasets is complete.\")\n",
        "\n",
        "# Check for NaN values in the datasets with extracted date features\n",
        "print(\"\\nNaN check for training/testing data with extracted date features:\")\n",
        "print(nan_handled_train_test_data.isna().sum())\n",
        "\n",
        "print(\"\\nNaN check for unseen data with extracted date features:\")\n",
        "print(nan_handled_unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEbg8-qg8NiZ",
        "outputId": "0f2bdccf-990e-46c7-e3a1-a3d9a62d61f4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "Converting 'Date' to datetime and extracting Year, Month, and Day...\n",
            "After extracting Year, Month, and Day: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg', 'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "Converting 'Date' to datetime and extracting Year, Month, and Day...\n",
            "Failed to convert 'Date' with format: %d-%m-%y\n",
            "After extracting Year, Month, and Day: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg', 'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "Date extraction and saving of datasets is complete.\n",
            "\n",
            "NaN check for training/testing data with extracted date features:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "dtype: int64\n",
            "\n",
            "NaN check for unseen data with extracted date features:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.3: Create shifted columns for previous day's data\n",
        "\n",
        "# Function to create shifted columns for previous day's data\n",
        "def create_shifted_columns(data):\n",
        "    data['Prev_Morning'] = data['Draw1'].shift(1)\n",
        "    data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
        "    data['Prev_Evening'] = data['Draw3'].shift(1)\n",
        "    data['Prev_Night'] = data['Draw4'].shift(1)\n",
        "    data[['Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night']] = data[['Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night']].fillna(0).astype(int)\n",
        "\n",
        "# Load the date extracted training/testing data\n",
        "date_extracted_train_test_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/E_Date_Extracted_Train_Test_Data.csv')\n",
        "\n",
        "# Apply the function to create shifted columns\n",
        "create_shifted_columns(date_extracted_train_test_data)\n",
        "\n",
        "# Save the updated training/testing data with shifted columns\n",
        "date_extracted_train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/G_Shifted_Train_Test_Data.csv', index=False)\n",
        "\n",
        "# Load the date extracted unseen data\n",
        "date_extracted_unseen_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/F_Date_Extracted_Unseen_Data.csv')\n",
        "\n",
        "# Apply the function to create shifted columns\n",
        "create_shifted_columns(date_extracted_unseen_data)\n",
        "\n",
        "# Save the updated unseen data with shifted columns\n",
        "date_extracted_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/H_Shifted_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of date extracted training/testing data:\")\n",
        "print(date_extracted_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of date extracted unseen data:\")\n",
        "print(date_extracted_unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YbHzP7wBUY1",
        "outputId": "10856183-ae92-4800-cefb-78e77c7f82d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of date extracted training/testing data:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2018-08-01           1  Training   19.0            7.0        27.0   \n",
            "1  2018-08-02           2  Training   31.0           11.0         1.0   \n",
            "2  2018-08-03           3  Training   15.0           19.0        21.0   \n",
            "3  2018-08-04           4  Training   31.0           35.0        18.0   \n",
            "4  2018-08-05           5         0    0.0            0.0         0.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0            23.0              32.0         27.5          17.0  ...   \n",
            "1             9.0              33.0         21.0           6.0  ...   \n",
            "2            12.0              35.0         23.5          20.0  ...   \n",
            "3            35.0              23.0         29.0          26.5  ...   \n",
            "4             0.0               0.0          0.0           0.0  ...   \n",
            "\n",
            "   DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  \\\n",
            "0              14.0         23.5          13.0  2018      8    1   \n",
            "1               3.0         19.0          30.5  2018      8    2   \n",
            "2               9.0         16.0          20.0  2018      8    3   \n",
            "3              21.0         25.0          15.0  2018      8    4   \n",
            "4               0.0          0.0           0.0  2018      8    5   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  \n",
            "0             0               0             0           0  \n",
            "1            19              14            33           9  \n",
            "2            31               3            35          12  \n",
            "3            15               9            23          35  \n",
            "4            31              21            29          16  \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "\n",
            "First few rows of date extracted unseen data:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2023-08-01        1410    Unseen   13.0           27.0        25.0   \n",
            "1  2023-08-02        1411    Unseen   21.0           33.0        12.0   \n",
            "2  2023-08-03        1412    Unseen   15.0           27.0         3.0   \n",
            "3  2023-08-04        1413    Unseen   13.0           20.0        11.0   \n",
            "4  2023-08-05        1414    Unseen   12.0           29.0        14.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0             5.0               7.0          6.0          26.0  ...   \n",
            "1            18.0              26.0         22.0          22.5  ...   \n",
            "2            28.0               7.0         17.5          15.0  ...   \n",
            "3             2.0               2.0          2.0          15.5  ...   \n",
            "4            12.0              22.0         17.0          21.5  ...   \n",
            "\n",
            "   DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  \\\n",
            "0              20.0         23.0          14.5  2023      8    1   \n",
            "1              31.0         19.0           6.5  2023      8    2   \n",
            "2               5.0          3.5          18.0  2023      8    3   \n",
            "3              28.0         25.0           4.5  2023      8    4   \n",
            "4              35.0         33.0          10.5  2023      8    5   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  \n",
            "0             0               0             0           0  \n",
            "1            13              20            26          18  \n",
            "2            21              31             7          28  \n",
            "3            15               5             2           2  \n",
            "4            13              28            22          12  \n",
            "\n",
            "[5 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.4: Handle NaN values for previous day's data\n",
        "\n",
        "# Load the shifted training/testing data\n",
        "shifted_train_test_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/G_Shifted_Train_Test_Data.csv')\n",
        "\n",
        "# Manually set values for the first row of training/testing set\n",
        "shifted_train_test_data.at[0, 'Prev_Morning'] = 13\n",
        "shifted_train_test_data.at[0, 'Prev_Afternoon'] = 34\n",
        "shifted_train_test_data.at[0, 'Prev_Evening'] = 32\n",
        "shifted_train_test_data.at[0, 'Prev_Night'] = 23\n",
        "\n",
        "# Save the updated training/testing data\n",
        "shifted_train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/I_Handled_Shifted_Train_Test_Data.csv', index=False)\n",
        "\n",
        "# Load the shifted unseen data\n",
        "shifted_unseen_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/H_Shifted_Unseen_Data.csv')\n",
        "\n",
        "# Manually set values for the first row of unseen set\n",
        "shifted_unseen_data.at[0, 'Prev_Morning'] = 25\n",
        "shifted_unseen_data.at[0, 'Prev_Afternoon'] = 9\n",
        "shifted_unseen_data.at[0, 'Prev_Evening'] = 7\n",
        "shifted_unseen_data.at[0, 'Prev_Night'] = 5\n",
        "\n",
        "# Save the updated unseen data\n",
        "shifted_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/J_Handled_Shifted_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of handled shifted training/testing data:\")\n",
        "print(shifted_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of handled shifted unseen data:\")\n",
        "print(shifted_unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8U-4sqFGQXj",
        "outputId": "62873510-3280-4ea3-8443-99dbfa4db493"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of handled shifted training/testing data:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2018-08-01           1  Training   19.0            7.0        27.0   \n",
            "1  2018-08-02           2  Training   31.0           11.0         1.0   \n",
            "2  2018-08-03           3  Training   15.0           19.0        21.0   \n",
            "3  2018-08-04           4  Training   31.0           35.0        18.0   \n",
            "4  2018-08-05           5         0    0.0            0.0         0.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0            23.0              32.0         27.5          17.0  ...   \n",
            "1             9.0              33.0         21.0           6.0  ...   \n",
            "2            12.0              35.0         23.5          20.0  ...   \n",
            "3            35.0              23.0         29.0          26.5  ...   \n",
            "4             0.0               0.0          0.0           0.0  ...   \n",
            "\n",
            "   DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  \\\n",
            "0              14.0         23.5          13.0  2018      8    1   \n",
            "1               3.0         19.0          30.5  2018      8    2   \n",
            "2               9.0         16.0          20.0  2018      8    3   \n",
            "3              21.0         25.0          15.0  2018      8    4   \n",
            "4               0.0          0.0           0.0  2018      8    5   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  \n",
            "0            13              34            32          23  \n",
            "1            19              14            33           9  \n",
            "2            31               3            35          12  \n",
            "3            15               9            23          35  \n",
            "4            31              21            29          16  \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "\n",
            "First few rows of handled shifted unseen data:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2023-08-01        1410    Unseen   13.0           27.0        25.0   \n",
            "1  2023-08-02        1411    Unseen   21.0           33.0        12.0   \n",
            "2  2023-08-03        1412    Unseen   15.0           27.0         3.0   \n",
            "3  2023-08-04        1413    Unseen   13.0           20.0        11.0   \n",
            "4  2023-08-05        1414    Unseen   12.0           29.0        14.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0             5.0               7.0          6.0          26.0  ...   \n",
            "1            18.0              26.0         22.0          22.5  ...   \n",
            "2            28.0               7.0         17.5          15.0  ...   \n",
            "3             2.0               2.0          2.0          15.5  ...   \n",
            "4            12.0              22.0         17.0          21.5  ...   \n",
            "\n",
            "   DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  \\\n",
            "0              20.0         23.0          14.5  2023      8    1   \n",
            "1              31.0         19.0           6.5  2023      8    2   \n",
            "2               5.0          3.5          18.0  2023      8    3   \n",
            "3              28.0         25.0           4.5  2023      8    4   \n",
            "4              35.0         33.0          10.5  2023      8    5   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  \n",
            "0            25               9             7           5  \n",
            "1            13              20            26          18  \n",
            "2            21              31             7          28  \n",
            "3            15               5             2           2  \n",
            "4            13              28            22          12  \n",
            "\n",
            "[5 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.1: # Initialize TARGET VARIABLE 'Prediction1' column\n",
        "\n",
        "# Load the handled shifted training/testing data\n",
        "handled_shifted_train_test_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/I_Handled_Shifted_Train_Test_Data.csv')\n",
        "\n",
        "# Set 'Prediction1' column equal to 'Draw1' for training/testing data\n",
        "handled_shifted_train_test_data['Prediction1'] = handled_shifted_train_test_data['Draw1']\n",
        "\n",
        "# Save the updated training/testing data\n",
        "handled_shifted_train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/K_Handled_Prediction1_Train_Test_Data.csv', index=False)\n",
        "\n",
        "# Load the handled shifted unseen data\n",
        "handled_shifted_unseen_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/J_Handled_Shifted_Unseen_Data.csv')\n",
        "\n",
        "# Initialize 'Prediction1' column with zero (0) for the unseen data\n",
        "handled_shifted_unseen_data['Prediction1'] = 0\n",
        "\n",
        "# Save the updated unseen data\n",
        "handled_shifted_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/L_Handled_Prediction1_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of handled Prediction1 training/testing data:\")\n",
        "print(handled_shifted_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of handled Prediction1 unseen data:\")\n",
        "print(handled_shifted_unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flDRfm_bLNeU",
        "outputId": "1f26a580-41a8-4da6-a5e9-6112688a63dc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of handled Prediction1 training/testing data:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2018-08-01           1  Training   19.0            7.0        27.0   \n",
            "1  2018-08-02           2  Training   31.0           11.0         1.0   \n",
            "2  2018-08-03           3  Training   15.0           19.0        21.0   \n",
            "3  2018-08-04           4  Training   31.0           35.0        18.0   \n",
            "4  2018-08-05           5         0    0.0            0.0         0.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0            23.0              32.0         27.5          17.0  ...   \n",
            "1             9.0              33.0         21.0           6.0  ...   \n",
            "2            12.0              35.0         23.5          20.0  ...   \n",
            "3            35.0              23.0         29.0          26.5  ...   \n",
            "4             0.0               0.0          0.0           0.0  ...   \n",
            "\n",
            "   DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  \\\n",
            "0         23.5          13.0  2018      8    1            13              34   \n",
            "1         19.0          30.5  2018      8    2            19              14   \n",
            "2         16.0          20.0  2018      8    3            31               3   \n",
            "3         25.0          15.0  2018      8    4            15               9   \n",
            "4          0.0           0.0  2018      8    5            31              21   \n",
            "\n",
            "   Prev_Evening  Prev_Night  Prediction1  \n",
            "0            32          23         19.0  \n",
            "1            33           9         31.0  \n",
            "2            35          12         15.0  \n",
            "3            23          35         31.0  \n",
            "4            29          16          0.0  \n",
            "\n",
            "[5 rows x 39 columns]\n",
            "\n",
            "First few rows of handled Prediction1 unseen data:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2023-08-01        1410    Unseen   13.0           27.0        25.0   \n",
            "1  2023-08-02        1411    Unseen   21.0           33.0        12.0   \n",
            "2  2023-08-03        1412    Unseen   15.0           27.0         3.0   \n",
            "3  2023-08-04        1413    Unseen   13.0           20.0        11.0   \n",
            "4  2023-08-05        1414    Unseen   12.0           29.0        14.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0             5.0               7.0          6.0          26.0  ...   \n",
            "1            18.0              26.0         22.0          22.5  ...   \n",
            "2            28.0               7.0         17.5          15.0  ...   \n",
            "3             2.0               2.0          2.0          15.5  ...   \n",
            "4            12.0              22.0         17.0          21.5  ...   \n",
            "\n",
            "   DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  \\\n",
            "0         23.0          14.5  2023      8    1            25               9   \n",
            "1         19.0           6.5  2023      8    2            13              20   \n",
            "2          3.5          18.0  2023      8    3            21              31   \n",
            "3         25.0           4.5  2023      8    4            15               5   \n",
            "4         33.0          10.5  2023      8    5            13              28   \n",
            "\n",
            "   Prev_Evening  Prev_Night  Prediction1  \n",
            "0             7           5            0  \n",
            "1            26          18            0  \n",
            "2             7          28            0  \n",
            "3             2           2            0  \n",
            "4            22          12            0  \n",
            "\n",
            "[5 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.2: Converting the columns to integer in both datasets (excluding 'Date')\n",
        "\n",
        "# Load the most recent CSVs\n",
        "train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/K_Handled_Prediction1_Train_Test_Data.csv')\n",
        "unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/L_Handled_Prediction1_Unseen_Data.csv')\n",
        "\n",
        "# List of columns to convert to integer (excluding 'Data_Type' and 'Date')\n",
        "columns_to_convert_train_test = [col for col in train_test_data.columns if col not in ['Data_Type', 'Date']]\n",
        "columns_to_convert_unseen = [col for col in unseen_data.columns if col not in ['Data_Type', 'Date']]\n",
        "\n",
        "# Convert columns to integer\n",
        "train_test_data[columns_to_convert_train_test] = train_test_data[columns_to_convert_train_test].astype(int)\n",
        "unseen_data[columns_to_convert_unseen] = unseen_data[columns_to_convert_unseen].astype(int)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/K_Handled_Prediction1_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/L_Handled_Prediction1_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the data types of the columns after conversion\n",
        "print(\"Data types of columns in train/test data after conversion:\")\n",
        "print(train_test_data.dtypes)\n",
        "\n",
        "print(\"\\nData types of columns in unseen data after conversion:\")\n",
        "print(unseen_data.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adGQ6YMGOsYv",
        "outputId": "a1d646cb-4ef4-4966-ca47-a2167f365b71"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types of columns in train/test data after conversion:\n",
            "Date                object\n",
            "Row Number           int64\n",
            "Data_Type           object\n",
            "Draw1                int64\n",
            "DR1_Prev_Week        int64\n",
            "DR1_2Weeks           int64\n",
            "DR1_Prev_Entry       int64\n",
            "DR1_Prev_Entry-2     int64\n",
            "DR1_Mov_Avg          int64\n",
            "DR1_Vert_Avg         int64\n",
            "Draw2                int64\n",
            "DR2_Prev_Week        int64\n",
            "DR2_2Weeks           int64\n",
            "DR2_Prev_Entry       int64\n",
            "DR2_Prev_Entry-2     int64\n",
            "DR2_Mov_Avg          int64\n",
            "DR2_Vert_Avg         int64\n",
            "Draw3                int64\n",
            "DR3_Prev_Week        int64\n",
            "DR3_2Weeks           int64\n",
            "DR3_Prev_Entry       int64\n",
            "DR3_Prev_Entry-2     int64\n",
            "DR3_Mov_Avg          int64\n",
            "DR3_Vert_Avg         int64\n",
            "Draw4                int64\n",
            "DR4_Prev_Week        int64\n",
            "DR4_2Weeks           int64\n",
            "DR4_Prev_Entry       int64\n",
            "DR4_Prev_Entry-2     int64\n",
            "DR4_Mov_Avg          int64\n",
            "DR4_Vert_Avg         int64\n",
            "Year                 int64\n",
            "Month                int64\n",
            "Day                  int64\n",
            "Prev_Morning         int64\n",
            "Prev_Afternoon       int64\n",
            "Prev_Evening         int64\n",
            "Prev_Night           int64\n",
            "Prediction1          int64\n",
            "dtype: object\n",
            "\n",
            "Data types of columns in unseen data after conversion:\n",
            "Date                object\n",
            "Row Number           int64\n",
            "Data_Type           object\n",
            "Draw1                int64\n",
            "DR1_Prev_Week        int64\n",
            "DR1_2Weeks           int64\n",
            "DR1_Prev_Entry       int64\n",
            "DR1_Prev_Entry-2     int64\n",
            "DR1_Mov_Avg          int64\n",
            "DR1_Vert_Avg         int64\n",
            "Draw2                int64\n",
            "DR2_Prev_Week        int64\n",
            "DR2_2Weeks           int64\n",
            "DR2_Prev_Entry       int64\n",
            "DR2_Prev_Entry-2     int64\n",
            "DR2_Mov_Avg          int64\n",
            "DR2_Vert_Avg         int64\n",
            "Draw3                int64\n",
            "DR3_Prev_Week        int64\n",
            "DR3_2Weeks           int64\n",
            "DR3_Prev_Entry       int64\n",
            "DR3_Prev_Entry-2     int64\n",
            "DR3_Mov_Avg          int64\n",
            "DR3_Vert_Avg         int64\n",
            "Draw4                int64\n",
            "DR4_Prev_Week        int64\n",
            "DR4_2Weeks           int64\n",
            "DR4_Prev_Entry       int64\n",
            "DR4_Prev_Entry-2     int64\n",
            "DR4_Mov_Avg          int64\n",
            "DR4_Vert_Avg         int64\n",
            "Year                 int64\n",
            "Month                int64\n",
            "Day                  int64\n",
            "Prev_Morning         int64\n",
            "Prev_Afternoon       int64\n",
            "Prev_Evening         int64\n",
            "Prev_Night           int64\n",
            "Prediction1          int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.1: # Introducing \"Lines\" as a new feature in both datasets\n",
        "\n",
        "# Load the most recent CSVs\n",
        "train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/K_Handled_Prediction1_Train_Test_Data.csv')\n",
        "unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/L_Handled_Prediction1_Unseen_Data.csv')\n",
        "\n",
        "# Function to assign \"Lines\" based on the sum of digits\n",
        "def assign_lines(data, column_name):\n",
        "    def get_lines(x):\n",
        "        try:\n",
        "            # Calculate the sum of digits\n",
        "            sum_of_digits = sum(map(int, str(x)))\n",
        "            # Ensure the sum is between 1 and 9\n",
        "            while sum_of_digits > 9:\n",
        "                sum_of_digits = sum(map(int, str(sum_of_digits)))\n",
        "            return sum_of_digits\n",
        "        except (ValueError, TypeError):\n",
        "            return None  # Handle non-convertible values by returning None\n",
        "\n",
        "    data[f'Lines_{column_name}'] = data[column_name].apply(get_lines)\n",
        "\n",
        "# List of columns to assign \"Lines\"\n",
        "columns_to_assign_lines = ['DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "\n",
        "# Assign \"Lines\" to columns in train/test data\n",
        "for column in columns_to_assign_lines:\n",
        "    assign_lines(train_test_data, column)\n",
        "\n",
        "# Assign \"Lines\" to columns in unseen data\n",
        "for column in columns_to_assign_lines:\n",
        "    assign_lines(unseen_data, column)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/M_Lines_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/N_Lines_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of both datasets to verify the \"Lines\" assignment\n",
        "print(\"First few rows of train/test data with 'Lines' assigned:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data with 'Lines' assigned:\")\n",
        "print(unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qBmKgOFOskq",
        "outputId": "2bbbdac7-a13a-48d5-aebc-f78baea99b3c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of train/test data with 'Lines' assigned:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2018-08-01           1  Training     19              7          27   \n",
            "1  2018-08-02           2  Training     31             11           1   \n",
            "2  2018-08-03           3  Training     15             19          21   \n",
            "3  2018-08-04           4  Training     31             35          18   \n",
            "4  2018-08-05           5         0      0              0           0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  Year  \\\n",
            "0              23                32           27            17  ...  2018   \n",
            "1               9                33           21             6  ...  2018   \n",
            "2              12                35           23            20  ...  2018   \n",
            "3              35                23           29            26  ...  2018   \n",
            "4               0                 0            0             0  ...  2018   \n",
            "\n",
            "   Month  Day  Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  \\\n",
            "0      8    1            13              34            32          23   \n",
            "1      8    2            19              14            33           9   \n",
            "2      8    3            31               3            35          12   \n",
            "3      8    4            15               9            23          35   \n",
            "4      8    5            31              21            29          16   \n",
            "\n",
            "   Prediction1  Lines_DR1_Prev_Week  Lines_DR1_Prev_Entry  \n",
            "0           19                    7                     5  \n",
            "1           31                    2                     9  \n",
            "2           15                    1                     3  \n",
            "3           31                    8                     8  \n",
            "4            0                    0                     0  \n",
            "\n",
            "[5 rows x 41 columns]\n",
            "\n",
            "First few rows of unseen data with 'Lines' assigned:\n",
            "         Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  2023-08-01        1410    Unseen     13             27          25   \n",
            "1  2023-08-02        1411    Unseen     21             33          12   \n",
            "2  2023-08-03        1412    Unseen     15             27           3   \n",
            "3  2023-08-04        1413    Unseen     13             20          11   \n",
            "4  2023-08-05        1414    Unseen     12             29          14   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  Year  \\\n",
            "0               5                 7            6            26  ...  2023   \n",
            "1              18                26           22            22  ...  2023   \n",
            "2              28                 7           17            15  ...  2023   \n",
            "3               2                 2            2            15  ...  2023   \n",
            "4              12                22           17            21  ...  2023   \n",
            "\n",
            "   Month  Day  Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  \\\n",
            "0      8    1            25               9             7           5   \n",
            "1      8    2            13              20            26          18   \n",
            "2      8    3            21              31             7          28   \n",
            "3      8    4            15               5             2           2   \n",
            "4      8    5            13              28            22          12   \n",
            "\n",
            "   Prediction1  Lines_DR1_Prev_Week  Lines_DR1_Prev_Entry  \n",
            "0            0                    9                     5  \n",
            "1            0                    6                     9  \n",
            "2            0                    9                     1  \n",
            "3            0                    2                     2  \n",
            "4            0                    2                     3  \n",
            "\n",
            "[5 rows x 41 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.2.1: Adding Corresponding Features for 'Lines_DR1_Prev_Entry'\n",
        "import pandas as pd\n",
        "\n",
        "# Define the base directory for file paths\n",
        "base_dir = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/'\n",
        "\n",
        "# Function to load a dataset\n",
        "def load_dataset(filename):\n",
        "    full_path = f'{base_dir}{filename}'\n",
        "    return pd.read_csv(full_path)\n",
        "\n",
        "# Load datasets\n",
        "train_test_data = load_dataset('M_Lines_Train_Test_Data.csv')\n",
        "unseen_data = load_dataset('N_Lines_Unseen_Data.csv')\n",
        "\n",
        "# Directory of Lines 1 to 9 with corresponding numbers\n",
        "lines_directory = {\n",
        "    1: [1, 10, 19, 28],\n",
        "    2: [2, 11, 20, 29],\n",
        "    3: [3, 12, 21, 30],\n",
        "    4: [4, 13, 22, 31],\n",
        "    5: [5, 14, 23, 32],\n",
        "    6: [6, 15, 24, 33],\n",
        "    7: [7, 16, 25, 34],\n",
        "    8: [8, 17, 26, 35],\n",
        "    9: [9, 18, 27, 36]\n",
        "}\n",
        "\n",
        "# Function to add corresponding numbers for 'Lines_DR1_Prev_Entry' in the dataset\n",
        "def add_line_numbers_entry(data, line_column):\n",
        "    for line, numbers in lines_directory.items():\n",
        "        # Create a column for the line itself, indicating the line of the previous entry\n",
        "        data[f'{line_column}_Line_{line}'] = data[line_column].apply(lambda x: 1 if x in numbers else 0)\n",
        "\n",
        "        # For each number in the line, create a column that will have a 1 if the line_column is the current line\n",
        "        for num in numbers:\n",
        "            # Create a column for each number to indicate it is part of the line subset of interest\n",
        "            data[f'Line_{line}_Num_{num}'] = data[f'{line_column}_Line_{line}']\n",
        "\n",
        "# Apply this function to both your training and unseen datasets\n",
        "add_line_numbers_entry(train_test_data, 'Lines_DR1_Prev_Entry')\n",
        "add_line_numbers_entry(unseen_data, 'Lines_DR1_Prev_Entry')\n",
        "\n",
        "# Save the updated datasets\n",
        "train_test_data.to_csv(base_dir + 'O_Lines_Enhanced_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv(base_dir + 'P_Lines_Enhanced_Unseen_Data.csv', index=False)\n",
        "\n",
        "print(\"Enhancement with 'Lines_DR1_Prev_Entry' numbers is complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl7b5Enfmfyb",
        "outputId": "c9fcbe88-2483-4f0f-c70c-7abcbc61ad3b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhancement with 'Lines_DR1_Prev_Entry' numbers is complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.2.2: Adding Corresponding Features for 'Lines_DR1_Prev_Week' (Commented Out for Later Use)\n",
        "#import pandas as pd\n",
        "\n",
        "# Define the base directory for file paths\n",
        "#base_dir = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/'\n",
        "\n",
        "# Function to load a dataset\n",
        "#def load_dataset(filename):\n",
        "#    full_path = f'{base_dir}{filename}'\n",
        "#    return pd.read_csv(full_path)\n",
        "\n",
        "# Load datasets\n",
        "#train_test_data = load_dataset('M_Lines_Train_Test_Data.csv')\n",
        "#unseen_data = load_dataset('N_Lines_Unseen_Data.csv')\n",
        "\n",
        "# Directory of Lines 1 to 9 with corresponding numbers\n",
        "#lines_directory = {\n",
        "#    1: [1, 10, 19, 28],\n",
        "#    2: [2, 11, 20, 29],\n",
        "#    3: [3, 12, 21, 30],\n",
        "#    4: [4, 13, 22, 31],\n",
        "#    5: [5, 14, 23, 32],\n",
        "#    6: [6, 15, 24, 33],\n",
        "#    7: [7, 16, 25, 34],\n",
        "#    8: [8, 17, 26, 35],\n",
        "#    9: [9, 18, 27, 36]\n",
        "#}\n",
        "\n",
        "# Rename function to reflect its purpose for 'DR1_Prev_Week'\n",
        "#def add_line_numbers_week(data, line_column):\n",
        "#    for line, numbers in lines_directory.items():\n",
        "#        # Create a column for the line itself, indicating the line of the previous entry\n",
        "#        data[f'{line_column}_Line_{line}'] = data[line_column].apply(lambda x: 1 if x in numbers else 0)\n",
        "\n",
        "        # For each number in the line, create a column that will have a 1 if the line_column is the current line\n",
        "#        for num in numbers:\n",
        "            # Create a column for each number to indicate it is part of the line subset of interest\n",
        "#            data[f'Line_{line}_Num_{num}'] = data[f'{line_column}_Line_{line}']\n",
        "\n",
        "# Comment out the function application for future use\n",
        "# add_line_numbers_week(train_test_data, 'Lines_DR1_Prev_Week')\n",
        "# add_line_numbers_week(unseen_data, 'Lines_DR1_Prev_Week')\n",
        "\n",
        "# Save the updated datasets\n",
        "#train_test_data.to_csv(base_dir + 'O_Lines_Enhanced_Train_Test_Data.csv', index=False)\n",
        "#unseen_data.to_csv(base_dir + 'P_Lines_Enhanced_Unseen_Data.csv', index=False)\n",
        "\n",
        "#print(\"Enhancement with 'Lines_DR1_Prev_Week' numbers is complete.\")\n"
      ],
      "metadata": {
        "id": "JLmiJ0V2e_Gs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cell 4.2: # Introducing \"Special Groups\" as a new feature in both datasets\n",
        "\n",
        "# Load the most recent CSVs\n",
        "#train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/M_Lines_Train_Test_Data.csv')\n",
        "#unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/N_Lines_Unseen_Data.csv')\n",
        "\n",
        "# Define the mapping for \"Special Groups\"\n",
        "#special_groups_mapping = {\n",
        "#    2: 1, 15: 1, 16: 1, 24: 1, 31: 1,  # \"Ladies\"\n",
        "#    4: 2, 5: 2, 12: 2, 29: 2, 34: 2,  # \"Men\"\n",
        "#    11: 3, 17: 3, 26: 3,  # \"Birds\"\n",
        "#    7: 4, 9: 4, 19: 4, 20: 4, 22: 4, 30: 4, 36: 4,  # \"Domestic Animals\"\n",
        "#    8: 5, 10: 5, 13: 5, 25: 5,  # \"Wild Animals\"\n",
        "#    18: 6, 28: 6, 32: 6,  # \"Ocean\"\n",
        "#    1: 7, 27: 7, 33: 7, 35: 7,  # \"Snakes & Insects\"\n",
        "#    3: 8, 6: 8, 14: 8, 21: 8, 23: 8  # \"Home\"\n",
        "#}\n",
        "\n",
        "# Function to assign \"Special Groups\" based on the mapping\n",
        "#def assign_special_groups(data, column_name, special_groups_mapping):\n",
        "#    data[f'Special_Groups_{column_name}'] = data[column_name].map(special_groups_mapping).fillna(0).astype(int)\n",
        "\n",
        "# List of columns to assign \"Special Groups\"\n",
        "#columns_to_assign_special_groups = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "\n",
        "# Assign \"Special Groups\" for specified columns in train/test data\n",
        "#for column in columns_to_assign_special_groups:\n",
        "#    assign_special_groups(train_test_data, column, special_groups_mapping)\n",
        "\n",
        "# Assign \"Special Groups\" for specified columns in unseen data\n",
        "#for column in columns_to_assign_special_groups:\n",
        "#    assign_special_groups(unseen_data, column, special_groups_mapping)\n",
        "\n",
        "# Save the updated datasets\n",
        "#train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/O_Special_Groups_Train_Test_Data.csv', index=False)\n",
        "#unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/P_Special_Groups_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of both datasets to verify the \"Special Groups\" assignment\n",
        "#print(\"First few rows of train/test data with 'Special Groups' assigned:\")\n",
        "#print(train_test_data.head())\n",
        "\n",
        "#print(\"\\nFirst few rows of unseen data with 'Special Groups' assigned:\")\n",
        "#print(unseen_data.head())\n"
      ],
      "metadata": {
        "id": "U8TauDfPOtKG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.3: # Introducing \"Spirits\" as a new feature in both datasets\n",
        "\n",
        "#import pandas as pd\n",
        "\n",
        "# Load the most recent CSVs\n",
        "#train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/O_Special_Groups_Train_Test_Data.csv')\n",
        "#unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/P_Special_Groups_Unseen_Data.csv')\n",
        "\n",
        "# Define a mapping dictionary for \"Spirits\" pairs\n",
        "#spirits_mapping = {\n",
        "#    1: 5,\n",
        "#    2: 24,\n",
        "#    3: 19,\n",
        "#    4: 35,\n",
        "#    5: 1,\n",
        "#    6: 15,\n",
        "#    7: 13,\n",
        "#    8: 29,\n",
        "#    9: 33,\n",
        "#    10: 28,\n",
        "#    11: 36,\n",
        "#    12: 32,\n",
        "#    13: 7,\n",
        "#    14: 25,\n",
        "#    15: 6,\n",
        "#    16: 17,\n",
        "#    17: 16,\n",
        "#    18: 30,\n",
        "#    19: 3,\n",
        "#    20: 22,\n",
        "#    21: 23,\n",
        "#    22: 20,\n",
        "#    23: 21,\n",
        "#    24: 2,\n",
        "#    25: 14,\n",
        "#    26: 27,\n",
        "#    27: 26,\n",
        "#    28: 10,\n",
        "#    29: 8,\n",
        "#    30: 18,\n",
        "#    31: 34,\n",
        "#    32: 12,\n",
        "#    33: 9,\n",
        "#    34: 31,\n",
        "#    35: 4,\n",
        "#    36: 11\n",
        "#}\n",
        "\n",
        "# Function to assign \"Spirits\" based on the mapping\n",
        "#def assign_spirits(data, column_name, spirits_mapping):\n",
        "#    data[f'Spirits_{column_name}'] = data[column_name].map(spirits_mapping).fillna(0).astype(int)\n",
        "\n",
        "# List of columns to assign \"Spirits\"\n",
        "#columns_to_assign_spirits = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "\n",
        "# Assign \"Spirits\" for specified columns in train/test data\n",
        "#for column in columns_to_assign_spirits:\n",
        "#    assign_spirits(train_test_data, column, spirits_mapping)\n",
        "\n",
        "# Assign \"Spirits\" for specified columns in unseen data\n",
        "#for column in columns_to_assign_spirits:\n",
        "#    assign_spirits(unseen_data, column, spirits_mapping)\n",
        "\n",
        "# Save the updated datasets\n",
        "#train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/Q_Spirits_Train_Test_Data.csv', index=False)\n",
        "#unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/R_Spirits_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of both datasets to verify the \"Spirits\" assignment\n",
        "#print(\"First few rows of train/test data with 'Spirits' assigned:\")\n",
        "#print(train_test_data.head())\n",
        "\n",
        "#print(\"\\nFirst few rows of unseen data with 'Spirits' assigned:\")\n",
        "#print(unseen_data.head())\n"
      ],
      "metadata": {
        "id": "_8T-Y4tK20PV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.4: # Introducing \"Rakes\" as a new feature in both datasets\n",
        "\n",
        "#import pandas as pd\n",
        "\n",
        "# Define a mapping dictionary for \"Rakes\" associations with lists as values\n",
        "#rakes_mapping = {\n",
        "#    1: ['36 First and Last', '7 Hog and Knife'],\n",
        "#    2: ['16 Old Jamette', '24 Old Fowl'],\n",
        "#    3: ['34 Three Blind Mice', '22 Three Blind Mice2', '35 Carriage On Road', '19 Horse and Carriage'],\n",
        "#    4: ['32 Dead Wood', '21 Death Announcement', '14 Dead Money', '26 Crowd from dead', '7 Sunset Drive', '11 Sunset Drive2'],\n",
        "#    5: ['31 Parson Man, Parson Wife'],\n",
        "#    6: ['25 Back and Belly', '32 Wood in Belly', '14 Bag of Money'],\n",
        "#    7: ['21 Hog Mouth'],\n",
        "#    8: ['3 Tiger In Cage', '33 Lion In Net', '7 Tiger Hunting', '14 Blood Money'],\n",
        "#    9: ['32 Bull Pistle', '11 Sept 11th'],\n",
        "#    10: ['32 Monkey Shrimps', '27 Monkey On Vine'],\n",
        "#    11: ['17 Black and White'],\n",
        "#    12: ['10 King Kong', '9 Clear or dirty water', '1 King and I'],\n",
        "#    13: ['10 Girl Child, Boy Child'],\n",
        "#    14: ['6 Money In Pocket', '23 Money In Bank', '33 Big Money, Small Money'],\n",
        "#    15: ['20 Sick like a Dog'],\n",
        "#    16: ['23 Jamette In Hotel', '35 Jamette Wining'],\n",
        "#    17: ['29 Young Drunk'],\n",
        "#    18: ['29 Rock D Boat', '28 Fish In the Boat'],\n",
        "#    19: ['35 Horse on Track', '32 Horse Wood', '36 Horse and Ass'],\n",
        "#    20: ['5 Worm On Fog', '24 Dog Food', '14 Dog Money', '30 Dog and Cat'],\n",
        "#    21: ['19 Straight from the Horse’s Mouth'],\n",
        "#    22: ['24 Rat Looking For Goods', '30 Tom and Jerry', '32 Rat Wood'],\n",
        "#    23: ['31 House Wife'],\n",
        "#    24: ['21 Food In Mouth'],\n",
        "#    25: ['13 Hard Back, Soft Back'],\n",
        "#    26: ['15 Fowl Sickness'],\n",
        "#    27: ['35 Little Snake, Big Snake', '19 Horse Whip', '14 Coil of Money'],\n",
        "#    28: ['36 Fish in Sea', '12 King Fish', '6 Fish Guts', '33 Fish in Net'],\n",
        "#    29: ['6 Rum Belly', '13 Drunk and Spread Out', '1 Rum Bottle', '16 Drunk like Jamette'],\n",
        "#    30: ['35 Golden Cobra', '6 Gold Sack', '6 Cat in Bag'],\n",
        "#    31: ['16 Big & Small Jamette', '5 Parson Man and Wife'],\n",
        "#    32: ['1 Bottle & Spoon'],\n",
        "#    33: ['9 Cow eating Grass', '5 Spider-man', '10 Spider Monkey'],\n",
        "#    34: ['1 Cemetery & Lights'],\n",
        "#    35: ['12 King Cobra'],\n",
        "#    36: ['18 Bridge & Water']\n",
        "#}\n",
        "\n",
        "# Save the mapping dictionary\n",
        "#import pickle\n",
        "\n",
        "#with open('rakes_mapping.pkl', 'wb') as f:\n",
        "#    pickle.dump(rakes_mapping, f)"
      ],
      "metadata": {
        "id": "dMFBQpu76ONH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.5: Applying \"Rakes\" Binary Function\n",
        "\n",
        "#import pandas as pd\n",
        "#import pickle\n",
        "\n",
        "# Load the most recent CSVs\n",
        "#train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/Q_Spirits_Train_Test_Data.csv')\n",
        "#unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/R_Spirits_Unseen_Data.csv')\n",
        "\n",
        "# Load the \"Rakes\" mapping dictionary\n",
        "#with open('rakes_mapping.pkl', 'rb') as f:\n",
        "#    rakes_mapping = pickle.load(f)\n",
        "\n",
        "# List of columns to assign \"Rakes\"\n",
        "#columns_to_assign_rakes = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "\n",
        "# Create binary columns for \"Rakes\" associations\n",
        "#def create_binary_columns(data, column_names, rakes_mapping):\n",
        "#    for column_name in column_names:\n",
        "#        for number, rakes_list in rakes_mapping.items():\n",
        "#            for rake in rakes_list:\n",
        "#                binary_column_name = f'Rakes_{column_name}_{number}_{rake}'\n",
        "#                data[binary_column_name] = (data[column_name] == number) & (data['Rakes'] == rake)\n",
        "\n",
        "# Create a column 'Rakes' to hold the associated Rake for each row\n",
        "#for column_name in columns_to_assign_rakes:\n",
        "#    train_test_data['Rakes'] = \"\"\n",
        "#    unseen_data['Rakes'] = \"\"\n",
        "#    for number, rakes_list in rakes_mapping.items():\n",
        "#        for rake in rakes_list:\n",
        "#            train_test_data.loc[train_test_data[column_name] == number, 'Rakes'] = rake\n",
        "#            unseen_data.loc[unseen_data[column_name] == number, 'Rakes'] = rake\n",
        "\n",
        "# Create binary columns for \"Rakes\" associations in train/test data\n",
        "#create_binary_columns(train_test_data, columns_to_assign_rakes, rakes_mapping)\n",
        "\n",
        "# Create binary columns for \"Rakes\" associations in unseen data\n",
        "#create_binary_columns(unseen_data, columns_to_assign_rakes, rakes_mapping)\n",
        "\n",
        "# Save the updated datasets\n",
        "#train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/S_Rakes_Train_Test_Data.csv', index=False)\n",
        "#unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/T_Rakes_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of both datasets to verify the binary columns\n",
        "#print(\"First few rows of train/test data with binary 'Rakes' columns:\")\n",
        "#print(train_test_data.head())\n",
        "\n",
        "#print(\"\\nFirst few rows of unseen data with binary 'Rakes' columns:\")\n",
        "#print(unseen_data.head())\n"
      ],
      "metadata": {
        "id": "-5Qw4O3PgH6X"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5.1: # Changing Data_Type column from categorical to numerical\n",
        "\n",
        "#import pandas as pd\n",
        "\n",
        "# Load the most recent CSVs\n",
        "#train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/S_Rakes_Train_Test_Data.csv')\n",
        "#unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/T_Rakes_Unseen_Data.csv')\n",
        "\n",
        "# Map 'Data_Type' to numerical values, including 0 in the mapping\n",
        "#data_type_mapping = {'Training': 1, 'Testing': 2, 'Unseen': 3}\n",
        "#train_test_data['Data_Type'] = train_test_data['Data_Type'].map(data_type_mapping)\n",
        "#unseen_data['Data_Type'] = train_test_data['Data_Type'].map(data_type_mapping)\n",
        "\n",
        "# Replace any remaining NaNs with 0 in the 'Data_Type' column\n",
        "#train_test_data['Data_Type'].fillna(0, inplace=True)\n",
        "#unseen_data['Data_Type'].fillna(0, inplace=True)\n",
        "\n",
        "# Convert the 'Data_Type' column to integers\n",
        "#train_test_data['Data_Type'] = train_test_data['Data_Type'].astype(int)\n",
        "#unseen_data['Data_Type'] = train_test_data['Data_Type'].astype(int)\n",
        "\n",
        "# Save the updated datasets\n",
        "#train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/U_Encoded_Train_Test_Data.csv', index=False)\n",
        "#unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/V_Encoded_Unseen_Data.csv', index=False)\n",
        "\n",
        "#print(\"First few rows of training/testing data:\")\n",
        "#print(train_test_data.head())\n",
        "\n",
        "#print(\"First few rows of unseen data:\")\n",
        "#print(unseen_data.head())\n"
      ],
      "metadata": {
        "id": "wwYJCfNV4fxG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for NaN values in train/test data\n",
        "print(\"NaN check for train/test data:\")\n",
        "print(train_test_data.isnull().sum())\n",
        "\n",
        "# Check data types in train/test data\n",
        "print(\"\\nData types in train/test data:\")\n",
        "print(train_test_data.dtypes)\n",
        "\n",
        "# Check for NaN values in unseen data\n",
        "print(\"\\nNaN check for unseen data:\")\n",
        "print(unseen_data.isnull().sum())\n",
        "\n",
        "# Check data types in unseen data\n",
        "print(\"\\nData types in unseen data:\")\n",
        "print(unseen_data.dtypes)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/U_Encoded_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/V_Encoded_Unseen_Data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "FPuNXxZPG2Rf",
        "outputId": "8fb1d0fe-1d83-4ce3-add9-90e3c36ac8d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN check for train/test data:\n",
            "Date                           0\n",
            "Row Number                     0\n",
            "Data_Type                      0\n",
            "Draw1                          0\n",
            "DR1_Prev_Week                  0\n",
            "                              ..\n",
            "Lines_DR1_Prev_Entry_Line_9    0\n",
            "Line_9_Num_9                   0\n",
            "Line_9_Num_18                  0\n",
            "Line_9_Num_27                  0\n",
            "Line_9_Num_36                  0\n",
            "Length: 86, dtype: int64\n",
            "\n",
            "Data types in train/test data:\n",
            "Date                           object\n",
            "Row Number                      int64\n",
            "Data_Type                      object\n",
            "Draw1                           int64\n",
            "DR1_Prev_Week                   int64\n",
            "                                ...  \n",
            "Lines_DR1_Prev_Entry_Line_9     int64\n",
            "Line_9_Num_9                    int64\n",
            "Line_9_Num_18                   int64\n",
            "Line_9_Num_27                   int64\n",
            "Line_9_Num_36                   int64\n",
            "Length: 86, dtype: object\n",
            "\n",
            "NaN check for unseen data:\n",
            "Date                           0\n",
            "Row Number                     0\n",
            "Data_Type                      0\n",
            "Draw1                          0\n",
            "DR1_Prev_Week                  0\n",
            "                              ..\n",
            "Lines_DR1_Prev_Entry_Line_9    0\n",
            "Line_9_Num_9                   0\n",
            "Line_9_Num_18                  0\n",
            "Line_9_Num_27                  0\n",
            "Line_9_Num_36                  0\n",
            "Length: 86, dtype: int64\n",
            "\n",
            "Data types in unseen data:\n",
            "Date                           object\n",
            "Row Number                      int64\n",
            "Data_Type                      object\n",
            "Draw1                           int64\n",
            "DR1_Prev_Week                   int64\n",
            "                                ...  \n",
            "Lines_DR1_Prev_Entry_Line_9     int64\n",
            "Line_9_Num_9                    int64\n",
            "Line_9_Num_18                   int64\n",
            "Line_9_Num_27                   int64\n",
            "Line_9_Num_36                   int64\n",
            "Length: 86, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the first copy to the first directory\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/W_Final_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Initial_Data_Prep/X_Final_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Save the second copy to the second directory AS INITIAL DATASETS FOR DRAW 1 PREDICTIVE SCRIPT\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Draw1_Predictive_Model/A_Initial_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model/Draw1_Predictive_Model/B_Initial_Unseen_Data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "lixNbXei4ghR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ":::::**THE END** *Thank You*:::::"
      ],
      "metadata": {
        "id": "c7irQ4xrLOIB"
      }
    }
  ]
}