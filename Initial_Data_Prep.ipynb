{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONNwZL4byZiufTtswt11tm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvinfranklyndavis/Project2023_v3/blob/main/Initial_Data_Prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1.1: Package Installation and Library Import\n",
        "\n",
        "# Check for existing libraries\n",
        "!pip show pandas numpy\n",
        "\n",
        "# Install or upgrade required packages\n",
        "!pip install -U --upgrade-strategy eager pip\n",
        "!pip install -U --upgrade-strategy eager pandas==<desired_version> numpy==<desired_version>\n",
        "\n",
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Set up logging to save logs in a file\n",
        "log_file = 'project.log'\n",
        "logging.basicConfig(filename=log_file, level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Set up virtual environment (optional but recommended)\n",
        "# You can create a virtual environment with: !python -m venv myenv\n",
        "# And activate it with: source myenv/bin/activate (Linux/macOS) or myenv\\Scripts\\activate (Windows)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plnc-ffhAUCk",
        "outputId": "2a9aac36-e521-496c-9886-e982c5bf9fa0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: pandas\n",
            "Version: 1.5.3\n",
            "Summary: Powerful data structures for data analysis, time series, and statistics\n",
            "Home-page: https://pandas.pydata.org\n",
            "Author: The Pandas Development Team\n",
            "Author-email: pandas-dev@python.org\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, python-dateutil, pytz\n",
            "Required-by: altair, arviz, bigframes, bokeh, bqplot, cmdstanpy, cufflinks, datascience, db-dtypes, dopamine-rl, fastai, geemap, geopandas, google-colab, gspread-dataframe, holoviews, ibis-framework, lida, mizani, mlxtend, pandas-datareader, pandas-gbq, panel, pins, plotnine, prophet, pymc, seaborn, sklearn-pandas, statsmodels, vega-datasets, xarray, yfinance\n",
            "---\n",
            "Name: numpy\n",
            "Version: 1.23.5\n",
            "Summary: NumPy is the fundamental package for array computing with Python.\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: \n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: albumentations, altair, arviz, astropy, autograd, blis, bokeh, bqplot, chex, cmdstanpy, contourpy, cufflinks, cupy-cuda12x, cvxpy, datascience, db-dtypes, dopamine-rl, ecos, flax, folium, geemap, gensim, gym, h5py, holoviews, hyperopt, ibis-framework, imageio, imbalanced-learn, imgaug, jax, jaxlib, librosa, lida, lightgbm, matplotlib, matplotlib-venn, missingno, mizani, ml-dtypes, mlxtend, moviepy, music21, nibabel, numba, numexpr, opencv-contrib-python, opencv-python, opencv-python-headless, opt-einsum, optax, orbax-checkpoint, osqp, pandas, pandas-gbq, patsy, plotnine, prophet, pyarrow, pycocotools, pyerfa, pymc, pytensor, python-louvain, PyWavelets, qdldl, qudida, scikit-image, scikit-learn, scipy, scs, seaborn, shapely, sklearn-pandas, soxr, spacy, stanio, statsmodels, tables, tensorboard, tensorflow, tensorflow-datasets, tensorflow-hub, tensorflow-probability, tensorstore, thinc, tifffile, torchtext, torchvision, transformers, wordcloud, xarray, xarray-einstats, xgboost, yellowbrick, yfinance\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.2\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `pip install -U --upgrade-strategy eager pandas==<desired_version> numpy==<desired_version>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.2: Data Loading from Google Drive Training / Testing  and Unseen datasets\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the directory for datasets in Google Drive\n",
        "drive_dataset_directory = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/'\n",
        "\n",
        "# Define the paths to the CSV files\n",
        "csv_filename_train_test = 'A_Initial_Train_Test_Data.csv'\n",
        "csv_filename_unseen = 'B_Initial_Unseen_Data.csv'\n",
        "\n",
        "drive_csv_path_train_test = os.path.join(drive_dataset_directory, csv_filename_train_test)\n",
        "drive_csv_path_unseen = os.path.join(drive_dataset_directory, csv_filename_unseen)\n",
        "\n",
        "# Check and load the datasets\n",
        "def load_dataset(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        print(\"File found. Proceeding to load the dataset.\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"File not found. Check the file path or the Google Drive mount.\")\n",
        "        return None\n",
        "\n",
        "# Load training/testing data\n",
        "train_test_data = load_dataset(drive_csv_path_train_test)\n",
        "\n",
        "# Load unseen data\n",
        "unseen_data = load_dataset(drive_csv_path_unseen)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of training/testing data:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data:\")\n",
        "print(unseen_data.head())\n"
      ],
      "metadata": {
        "id": "fP_Q74gUBGQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "635595ad-1089-4921-c9fa-ad3781833325"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of training/testing data:\n",
            "       Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  01-08-18           1  Training   19.0            7.0        27.0   \n",
            "1  02-08-18           2  Training   31.0           11.0         1.0   \n",
            "2  03-08-18           3  Training   15.0           19.0        21.0   \n",
            "3  04-08-18           4  Training   31.0           35.0        18.0   \n",
            "4  05-08-18           5       NaN    NaN            NaN         NaN   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0            23.0              32.0         27.5          17.0  ...   \n",
            "1             9.0              33.0         21.0           6.0  ...   \n",
            "2            12.0              35.0         23.5          20.0  ...   \n",
            "3            35.0              23.0         29.0          26.5  ...   \n",
            "4             NaN               NaN          NaN           NaN  ...   \n",
            "\n",
            "   DR3_Prev_Entry-2  DR3_Mov_Avg  DR3_Vert_Avg  Draw4  DR4_Prev_Week  \\\n",
            "0              19.0         16.5          15.0    9.0            2.0   \n",
            "1              31.0         17.0          17.0   12.0           35.0   \n",
            "2              15.0         12.0          10.0   35.0           11.0   \n",
            "3              31.0         26.0          23.5   16.0           13.0   \n",
            "4               NaN          NaN           NaN    NaN            NaN   \n",
            "\n",
            "   DR4_2Weeks  DR4_Prev_Entry  DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  \n",
            "0        24.0            33.0              14.0         23.5          13.0  \n",
            "1        26.0            35.0               3.0         19.0          30.5  \n",
            "2        29.0            23.0               9.0         16.0          20.0  \n",
            "3        17.0            29.0              21.0         25.0          15.0  \n",
            "4         NaN             NaN               NaN          NaN           NaN  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "First few rows of unseen data:\n",
            "       Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  1/8/2023        1410    Unseen   13.0           27.0        25.0   \n",
            "1  2/8/2023        1411    Unseen   21.0           33.0        12.0   \n",
            "2  3/8/2023        1412    Unseen   15.0           27.0         3.0   \n",
            "3  4/8/2023        1413    Unseen   13.0           20.0        11.0   \n",
            "4  5/8/2023        1414    Unseen   12.0           29.0        14.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0             5.0               7.0          6.0          26.0  ...   \n",
            "1            18.0              26.0         22.0          22.5  ...   \n",
            "2            28.0               7.0         17.5          15.0  ...   \n",
            "3             2.0               2.0          2.0          15.5  ...   \n",
            "4            12.0              22.0         17.0          21.5  ...   \n",
            "\n",
            "   DR3_Prev_Entry-2  DR3_Mov_Avg  DR3_Vert_Avg  Draw4  DR4_Prev_Week  \\\n",
            "0              13.0         16.5          25.0   18.0           26.0   \n",
            "1              21.0         26.0           6.0   28.0            8.0   \n",
            "2              15.0         10.0          18.0    2.0           30.0   \n",
            "3              13.0         20.5          26.0   12.0            2.0   \n",
            "4              12.0         23.5          18.5   11.0            3.0   \n",
            "\n",
            "   DR4_2Weeks  DR4_Prev_Entry  DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  \n",
            "0         3.0            26.0              20.0         23.0          14.5  \n",
            "1         5.0             7.0              31.0         19.0           6.5  \n",
            "2         6.0             2.0               5.0          3.5          18.0  \n",
            "3         7.0            22.0              28.0         25.0           4.5  \n",
            "4        18.0            31.0              35.0         33.0          10.5  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.3: Surveillance Check for NaNs within both datasets\n",
        "\n",
        "# Check for NaN values in training/testing data\n",
        "print(\"NaN check for training/testing data:\")\n",
        "print(train_test_data.isna().sum())\n",
        "\n",
        "# Check for NaN values in unseen data\n",
        "print(\"\\nNaN check for unseen data:\")\n",
        "print(unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2THl1IOP57A7",
        "outputId": "de454c4a-8dc0-4bb8-8130-0017fb7f97b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN check for training/testing data:\n",
            "Date                  0\n",
            "Row Number            0\n",
            "Data_Type           239\n",
            "Draw1               239\n",
            "DR1_Prev_Week       239\n",
            "DR1_2Weeks          239\n",
            "DR1_Prev_Entry      239\n",
            "DR1_Prev_Entry-2    239\n",
            "DR1_Mov_Avg         239\n",
            "DR1_Vert_Avg        239\n",
            "Draw2               239\n",
            "DR2_Prev_Week       239\n",
            "DR2_2Weeks          239\n",
            "DR2_Prev_Entry      239\n",
            "DR2_Prev_Entry-2    239\n",
            "DR2_Mov_Avg         239\n",
            "DR2_Vert_Avg        239\n",
            "Draw3               239\n",
            "DR3_Prev_Week       239\n",
            "DR3_2Weeks          239\n",
            "DR3_Prev_Entry      239\n",
            "DR3_Prev_Entry-2    239\n",
            "DR3_Mov_Avg         239\n",
            "DR3_Vert_Avg        239\n",
            "Draw4               239\n",
            "DR4_Prev_Week       239\n",
            "DR4_2Weeks          239\n",
            "DR4_Prev_Entry      239\n",
            "DR4_Prev_Entry-2    239\n",
            "DR4_Mov_Avg         239\n",
            "DR4_Vert_Avg        239\n",
            "dtype: int64\n",
            "\n",
            "NaN check for unseen data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           4\n",
            "Draw1               4\n",
            "DR1_Prev_Week       4\n",
            "DR1_2Weeks          4\n",
            "DR1_Prev_Entry      4\n",
            "DR1_Prev_Entry-2    4\n",
            "DR1_Mov_Avg         4\n",
            "DR1_Vert_Avg        4\n",
            "Draw2               4\n",
            "DR2_Prev_Week       4\n",
            "DR2_2Weeks          4\n",
            "DR2_Prev_Entry      4\n",
            "DR2_Prev_Entry-2    4\n",
            "DR2_Mov_Avg         4\n",
            "DR2_Vert_Avg        4\n",
            "Draw3               4\n",
            "DR3_Prev_Week       4\n",
            "DR3_2Weeks          4\n",
            "DR3_Prev_Entry      4\n",
            "DR3_Prev_Entry-2    4\n",
            "DR3_Mov_Avg         4\n",
            "DR3_Vert_Avg        4\n",
            "Draw4               4\n",
            "DR4_Prev_Week       4\n",
            "DR4_2Weeks          4\n",
            "DR4_Prev_Entry      4\n",
            "DR4_Prev_Entry-2    4\n",
            "DR4_Mov_Avg         4\n",
            "DR4_Vert_Avg        4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.1: NaN handling and new CSV saving for Training / Testing  and Unseen datasets\n",
        "\n",
        "\n",
        "# Impute NaN values with zeros in training/testing data\n",
        "train_test_data = train_test_data.fillna(0)\n",
        "\n",
        "# Impute NaN values with zeros in unseen data\n",
        "unseen_data = unseen_data.fillna(0)\n",
        "\n",
        "# Define new CSV file names\n",
        "new_csv_filename_train_test = 'C_NaN_Handled_Train_Test_Data.csv'\n",
        "new_csv_filename_unseen = 'D_NaN_Handled_Unseen_Data.csv'\n",
        "\n",
        "# Define the paths for saving the new CSV files\n",
        "new_csv_path_train_test = os.path.join(drive_dataset_directory, new_csv_filename_train_test)\n",
        "new_csv_path_unseen = os.path.join(drive_dataset_directory, new_csv_filename_unseen)\n",
        "\n",
        "# Save the preprocessed training/testing data as a new CSV file\n",
        "train_test_data.to_csv(new_csv_path_train_test, index=False)\n",
        "\n",
        "# Save the preprocessed unseen data as a new CSV file\n",
        "unseen_data.to_csv(new_csv_path_unseen, index=False)\n",
        "\n",
        "# Print a message to confirm that the preprocessing and saving is complete\n",
        "print(\"Preprocessing and saving of datasets is complete.\")\n",
        "\n",
        "# Check for NaN values in the preprocessed training/testing data\n",
        "print(\"\\nNaN check for preprocessed training/testing data:\")\n",
        "print(train_test_data.isna().sum())\n",
        "\n",
        "# Check for NaN values in the preprocessed unseen data\n",
        "print(\"\\nNaN check for preprocessed unseen data:\")\n",
        "print(unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7QU7JyA8B8b",
        "outputId": "85ae29c3-a5c9-4e41-83d5-8dc7c0377b04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing and saving of datasets is complete.\n",
            "\n",
            "NaN check for preprocessed training/testing data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "dtype: int64\n",
            "\n",
            "NaN check for preprocessed unseen data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.2: Extract Y/M/D from Date and new CSV saving for Training / Testing  and Unseen datasets\n",
        "\n",
        "# Load the NaN-handled training/testing data\n",
        "nan_handled_train_test_data = load_dataset(new_csv_path_train_test)\n",
        "\n",
        "# Load the NaN-handled unseen data\n",
        "nan_handled_unseen_data = load_dataset(new_csv_path_unseen)\n",
        "\n",
        "# Check and load the datasets\n",
        "def load_dataset(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        print(\"File found. Proceeding to load the dataset.\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"File not found. Check the file path.\")\n",
        "        return None\n",
        "\n",
        "# Function to extract 'Year', 'Month', and 'Day' from the 'Date' column\n",
        "def extract_date_features(data):\n",
        "    if 'Date' in data.columns:\n",
        "        print(\"Converting 'Date' to datetime and extracting Year, Month, and Day...\")\n",
        "        date_formats = ['%d-%m-%y', '%d/%m/%Y']\n",
        "        for date_format in date_formats:\n",
        "            try:\n",
        "                data['Date'] = pd.to_datetime(data['Date'], format=date_format)\n",
        "                data['Year'] = data['Date'].dt.year.fillna(0).astype(int)\n",
        "                data['Month'] = data['Date'].dt.month.fillna(0).astype(int)\n",
        "                data['Day'] = data['Date'].dt.day.fillna(0).astype(int)\n",
        "                data.drop(columns=['Date'], inplace=True)\n",
        "                print(\"After extracting Year, Month, and Day:\", data.columns)\n",
        "                break  # Break the loop if successful date conversion\n",
        "            except ValueError:\n",
        "                print(f\"Failed to convert 'Date' with format: {date_format}\")\n",
        "    else:\n",
        "        print(\"'Date' column not found in the dataset.\")\n",
        "\n",
        "# Extract 'Year', 'Month', and 'Day' from the 'Date' column in training/testing data\n",
        "extract_date_features(nan_handled_train_test_data)\n",
        "\n",
        "# Extract 'Year', 'Month', and 'Day' from the 'Date' column in unseen data\n",
        "extract_date_features(nan_handled_unseen_data)\n",
        "\n",
        "# Define new CSV file names\n",
        "new_csv_filename_train_test_date = 'E_Date_Extracted_Train_Test_Data.csv'\n",
        "new_csv_filename_unseen_date = 'F_Date_Extracted_Unseen_Data.csv'\n",
        "\n",
        "# Define the paths for saving the new CSV files\n",
        "new_csv_path_train_test_date = os.path.join(drive_dataset_directory, new_csv_filename_train_test_date)\n",
        "new_csv_path_unseen_date = os.path.join(drive_dataset_directory, new_csv_filename_unseen_date)\n",
        "\n",
        "# Save the datasets with extracted date features as new CSV files\n",
        "nan_handled_train_test_data.to_csv(new_csv_path_train_test_date, index=False)\n",
        "nan_handled_unseen_data.to_csv(new_csv_path_unseen_date, index=False)\n",
        "\n",
        "# Print a message to confirm that the date extraction and saving is complete\n",
        "print(\"Date extraction and saving of datasets is complete.\")\n",
        "\n",
        "# Check for NaN values in the datasets with extracted date features\n",
        "print(\"\\nNaN check for training/testing data with extracted date features:\")\n",
        "print(nan_handled_train_test_data.isna().sum())\n",
        "\n",
        "print(\"\\nNaN check for unseen data with extracted date features:\")\n",
        "print(nan_handled_unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEbg8-qg8NiZ",
        "outputId": "afda2952-a30d-413d-f588-77457b6e10f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "Converting 'Date' to datetime and extracting Year, Month, and Day...\n",
            "After extracting Year, Month, and Day: Index(['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
            "       'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
            "       'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks', 'DR2_Prev_Entry',\n",
            "       'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg', 'Draw3',\n",
            "       'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry', 'DR3_Prev_Entry-2',\n",
            "       'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4', 'DR4_Prev_Week', 'DR4_2Weeks',\n",
            "       'DR4_Prev_Entry', 'DR4_Prev_Entry-2', 'DR4_Mov_Avg', 'DR4_Vert_Avg',\n",
            "       'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "Converting 'Date' to datetime and extracting Year, Month, and Day...\n",
            "Failed to convert 'Date' with format: %d-%m-%y\n",
            "After extracting Year, Month, and Day: Index(['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
            "       'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
            "       'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks', 'DR2_Prev_Entry',\n",
            "       'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg', 'Draw3',\n",
            "       'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry', 'DR3_Prev_Entry-2',\n",
            "       'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4', 'DR4_Prev_Week', 'DR4_2Weeks',\n",
            "       'DR4_Prev_Entry', 'DR4_Prev_Entry-2', 'DR4_Mov_Avg', 'DR4_Vert_Avg',\n",
            "       'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "Date extraction and saving of datasets is complete.\n",
            "\n",
            "NaN check for training/testing data with extracted date features:\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "dtype: int64\n",
            "\n",
            "NaN check for unseen data with extracted date features:\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Draw2               0\n",
            "DR2_Prev_Week       0\n",
            "DR2_2Weeks          0\n",
            "DR2_Prev_Entry      0\n",
            "DR2_Prev_Entry-2    0\n",
            "DR2_Mov_Avg         0\n",
            "DR2_Vert_Avg        0\n",
            "Draw3               0\n",
            "DR3_Prev_Week       0\n",
            "DR3_2Weeks          0\n",
            "DR3_Prev_Entry      0\n",
            "DR3_Prev_Entry-2    0\n",
            "DR3_Mov_Avg         0\n",
            "DR3_Vert_Avg        0\n",
            "Draw4               0\n",
            "DR4_Prev_Week       0\n",
            "DR4_2Weeks          0\n",
            "DR4_Prev_Entry      0\n",
            "DR4_Prev_Entry-2    0\n",
            "DR4_Mov_Avg         0\n",
            "DR4_Vert_Avg        0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.3: Create shifted columns for previous day's data\n",
        "\n",
        "# Function to create shifted columns for previous day's data\n",
        "def create_shifted_columns(data):\n",
        "    data['Prev_Morning'] = data['Draw1'].shift(1)\n",
        "    data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
        "    data['Prev_Evening'] = data['Draw3'].shift(1)\n",
        "    data['Prev_Night'] = data['Draw4'].shift(1)\n",
        "    data[['Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night']] = data[['Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night']].fillna(0).astype(int)\n",
        "\n",
        "# Load the date extracted training/testing data\n",
        "date_extracted_train_test_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/E_Date_Extracted_Train_Test_Data.csv')\n",
        "\n",
        "# Apply the function to create shifted columns\n",
        "create_shifted_columns(date_extracted_train_test_data)\n",
        "\n",
        "# Save the updated training/testing data with shifted columns\n",
        "date_extracted_train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/G_Shifted_Train_Test_Data.csv', index=False)\n",
        "\n",
        "# Load the date extracted unseen data\n",
        "date_extracted_unseen_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/F_Date_Extracted_Unseen_Data.csv')\n",
        "\n",
        "# Apply the function to create shifted columns\n",
        "create_shifted_columns(date_extracted_unseen_data)\n",
        "\n",
        "# Save the updated unseen data with shifted columns\n",
        "date_extracted_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/H_Shifted_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of date extracted training/testing data:\")\n",
        "print(date_extracted_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of date extracted unseen data:\")\n",
        "print(date_extracted_unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YbHzP7wBUY1",
        "outputId": "65a76328-cab4-4a50-c874-a6b706188bfd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of date extracted training/testing data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training   19.0            7.0        27.0            23.0   \n",
            "1           2  Training   31.0           11.0         1.0             9.0   \n",
            "2           3  Training   15.0           19.0        21.0            12.0   \n",
            "3           4  Training   31.0           35.0        18.0            35.0   \n",
            "4           5         0    0.0            0.0         0.0             0.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  DR4_Prev_Entry-2  \\\n",
            "0              32.0         27.5          17.0   14.0  ...              14.0   \n",
            "1              33.0         21.0           6.0    3.0  ...               3.0   \n",
            "2              35.0         23.5          20.0    9.0  ...               9.0   \n",
            "3              23.0         29.0          26.5   21.0  ...              21.0   \n",
            "4               0.0          0.0           0.0    0.0  ...               0.0   \n",
            "\n",
            "   DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  \\\n",
            "0         23.5          13.0  2018      8    1             0               0   \n",
            "1         19.0          30.5  2018      8    2            19              14   \n",
            "2         16.0          20.0  2018      8    3            31               3   \n",
            "3         25.0          15.0  2018      8    4            15               9   \n",
            "4          0.0           0.0  2018      8    5            31              21   \n",
            "\n",
            "   Prev_Evening  Prev_Night  \n",
            "0             0           0  \n",
            "1            33           9  \n",
            "2            35          12  \n",
            "3            23          35  \n",
            "4            29          16  \n",
            "\n",
            "[5 rows x 37 columns]\n",
            "\n",
            "First few rows of date extracted unseen data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0        1410    Unseen   13.0           27.0        25.0             5.0   \n",
            "1        1411    Unseen   21.0           33.0        12.0            18.0   \n",
            "2        1412    Unseen   15.0           27.0         3.0            28.0   \n",
            "3        1413    Unseen   13.0           20.0        11.0             2.0   \n",
            "4        1414    Unseen   12.0           29.0        14.0            12.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  DR4_Prev_Entry-2  \\\n",
            "0               7.0          6.0          26.0   20.0  ...              20.0   \n",
            "1              26.0         22.0          22.5   31.0  ...              31.0   \n",
            "2               7.0         17.5          15.0    5.0  ...               5.0   \n",
            "3               2.0          2.0          15.5   28.0  ...              28.0   \n",
            "4              22.0         17.0          21.5   35.0  ...              35.0   \n",
            "\n",
            "   DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  \\\n",
            "0         23.0          14.5  2023      8    1             0               0   \n",
            "1         19.0           6.5  2023      8    2            13              20   \n",
            "2          3.5          18.0  2023      8    3            21              31   \n",
            "3         25.0           4.5  2023      8    4            15               5   \n",
            "4         33.0          10.5  2023      8    5            13              28   \n",
            "\n",
            "   Prev_Evening  Prev_Night  \n",
            "0             0           0  \n",
            "1            26          18  \n",
            "2             7          28  \n",
            "3             2           2  \n",
            "4            22          12  \n",
            "\n",
            "[5 rows x 37 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.4: Handle NaN values for previous day's data\n",
        "\n",
        "# Load the shifted training/testing data\n",
        "shifted_train_test_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/G_Shifted_Train_Test_Data.csv')\n",
        "\n",
        "# Manually set values for the first row of training/testing set\n",
        "shifted_train_test_data.at[0, 'Prev_Morning'] = 13\n",
        "shifted_train_test_data.at[0, 'Prev_Afternoon'] = 34\n",
        "shifted_train_test_data.at[0, 'Prev_Evening'] = 32\n",
        "shifted_train_test_data.at[0, 'Prev_Night'] = 23\n",
        "\n",
        "# Save the updated training/testing data\n",
        "shifted_train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/I_Handled_Shifted_Train_Test_Data.csv', index=False)\n",
        "\n",
        "# Load the shifted unseen data\n",
        "shifted_unseen_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/H_Shifted_Unseen_Data.csv')\n",
        "\n",
        "# Manually set values for the first row of unseen set\n",
        "shifted_unseen_data.at[0, 'Prev_Morning'] = 25\n",
        "shifted_unseen_data.at[0, 'Prev_Afternoon'] = 9\n",
        "shifted_unseen_data.at[0, 'Prev_Evening'] = 7\n",
        "shifted_unseen_data.at[0, 'Prev_Night'] = 5\n",
        "\n",
        "# Save the updated unseen data\n",
        "shifted_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/J_Handled_Shifted_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of handled shifted training/testing data:\")\n",
        "print(shifted_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of handled shifted unseen data:\")\n",
        "print(shifted_unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8U-4sqFGQXj",
        "outputId": "b21ef1b8-05a1-4fa6-8a04-15f39be7df0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of handled shifted training/testing data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training   19.0            7.0        27.0            23.0   \n",
            "1           2  Training   31.0           11.0         1.0             9.0   \n",
            "2           3  Training   15.0           19.0        21.0            12.0   \n",
            "3           4  Training   31.0           35.0        18.0            35.0   \n",
            "4           5         0    0.0            0.0         0.0             0.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  DR4_Prev_Entry-2  \\\n",
            "0              32.0         27.5          17.0   14.0  ...              14.0   \n",
            "1              33.0         21.0           6.0    3.0  ...               3.0   \n",
            "2              35.0         23.5          20.0    9.0  ...               9.0   \n",
            "3              23.0         29.0          26.5   21.0  ...              21.0   \n",
            "4               0.0          0.0           0.0    0.0  ...               0.0   \n",
            "\n",
            "   DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  \\\n",
            "0         23.5          13.0  2018      8    1            13              34   \n",
            "1         19.0          30.5  2018      8    2            19              14   \n",
            "2         16.0          20.0  2018      8    3            31               3   \n",
            "3         25.0          15.0  2018      8    4            15               9   \n",
            "4          0.0           0.0  2018      8    5            31              21   \n",
            "\n",
            "   Prev_Evening  Prev_Night  \n",
            "0            32          23  \n",
            "1            33           9  \n",
            "2            35          12  \n",
            "3            23          35  \n",
            "4            29          16  \n",
            "\n",
            "[5 rows x 37 columns]\n",
            "\n",
            "First few rows of handled shifted unseen data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0        1410    Unseen   13.0           27.0        25.0             5.0   \n",
            "1        1411    Unseen   21.0           33.0        12.0            18.0   \n",
            "2        1412    Unseen   15.0           27.0         3.0            28.0   \n",
            "3        1413    Unseen   13.0           20.0        11.0             2.0   \n",
            "4        1414    Unseen   12.0           29.0        14.0            12.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  DR4_Prev_Entry-2  \\\n",
            "0               7.0          6.0          26.0   20.0  ...              20.0   \n",
            "1              26.0         22.0          22.5   31.0  ...              31.0   \n",
            "2               7.0         17.5          15.0    5.0  ...               5.0   \n",
            "3               2.0          2.0          15.5   28.0  ...              28.0   \n",
            "4              22.0         17.0          21.5   35.0  ...              35.0   \n",
            "\n",
            "   DR4_Mov_Avg  DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  \\\n",
            "0         23.0          14.5  2023      8    1            25               9   \n",
            "1         19.0           6.5  2023      8    2            13              20   \n",
            "2          3.5          18.0  2023      8    3            21              31   \n",
            "3         25.0           4.5  2023      8    4            15               5   \n",
            "4         33.0          10.5  2023      8    5            13              28   \n",
            "\n",
            "   Prev_Evening  Prev_Night  \n",
            "0             7           5  \n",
            "1            26          18  \n",
            "2             7          28  \n",
            "3             2           2  \n",
            "4            22          12  \n",
            "\n",
            "[5 rows x 37 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.1: # Initialize TARGET VARIABLE 'Prediction1' column\n",
        "\n",
        "# Load the handled shifted training/testing data\n",
        "handled_shifted_train_test_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/I_Handled_Shifted_Train_Test_Data.csv')\n",
        "\n",
        "# Set 'Prediction1' column equal to 'Draw1' for training/testing data\n",
        "handled_shifted_train_test_data['Prediction1'] = handled_shifted_train_test_data['Draw1']\n",
        "\n",
        "# Save the updated training/testing data\n",
        "handled_shifted_train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/K_Handled_Prediction1_Train_Test_Data.csv', index=False)\n",
        "\n",
        "# Load the handled shifted unseen data\n",
        "handled_shifted_unseen_data = load_dataset('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/J_Handled_Shifted_Unseen_Data.csv')\n",
        "\n",
        "# Initialize 'Prediction1' column with NaN values for the unseen data\n",
        "handled_shifted_unseen_data['Prediction1'] = np.nan\n",
        "\n",
        "# Save the updated unseen data\n",
        "handled_shifted_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/L_Handled_Prediction1_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Print the first few rows of both datasets for inspection\n",
        "print(\"First few rows of handled Prediction1 training/testing data:\")\n",
        "print(handled_shifted_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of handled Prediction1 unseen data:\")\n",
        "print(handled_shifted_unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flDRfm_bLNeU",
        "outputId": "754ea405-1d53-4792-fd7d-b970eb02103c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "File found. Proceeding to load the dataset.\n",
            "First few rows of handled Prediction1 training/testing data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training   19.0            7.0        27.0            23.0   \n",
            "1           2  Training   31.0           11.0         1.0             9.0   \n",
            "2           3  Training   15.0           19.0        21.0            12.0   \n",
            "3           4  Training   31.0           35.0        18.0            35.0   \n",
            "4           5         0    0.0            0.0         0.0             0.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  DR4_Mov_Avg  \\\n",
            "0              32.0         27.5          17.0   14.0  ...         23.5   \n",
            "1              33.0         21.0           6.0    3.0  ...         19.0   \n",
            "2              35.0         23.5          20.0    9.0  ...         16.0   \n",
            "3              23.0         29.0          26.5   21.0  ...         25.0   \n",
            "4               0.0          0.0           0.0    0.0  ...          0.0   \n",
            "\n",
            "   DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  Prev_Evening  \\\n",
            "0          13.0  2018      8    1            13              34            32   \n",
            "1          30.5  2018      8    2            19              14            33   \n",
            "2          20.0  2018      8    3            31               3            35   \n",
            "3          15.0  2018      8    4            15               9            23   \n",
            "4           0.0  2018      8    5            31              21            29   \n",
            "\n",
            "   Prev_Night  Prediction1  \n",
            "0          23         19.0  \n",
            "1           9         31.0  \n",
            "2          12         15.0  \n",
            "3          35         31.0  \n",
            "4          16          0.0  \n",
            "\n",
            "[5 rows x 38 columns]\n",
            "\n",
            "First few rows of handled Prediction1 unseen data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0        1410    Unseen   13.0           27.0        25.0             5.0   \n",
            "1        1411    Unseen   21.0           33.0        12.0            18.0   \n",
            "2        1412    Unseen   15.0           27.0         3.0            28.0   \n",
            "3        1413    Unseen   13.0           20.0        11.0             2.0   \n",
            "4        1414    Unseen   12.0           29.0        14.0            12.0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  DR4_Mov_Avg  \\\n",
            "0               7.0          6.0          26.0   20.0  ...         23.0   \n",
            "1              26.0         22.0          22.5   31.0  ...         19.0   \n",
            "2               7.0         17.5          15.0    5.0  ...          3.5   \n",
            "3               2.0          2.0          15.5   28.0  ...         25.0   \n",
            "4              22.0         17.0          21.5   35.0  ...         33.0   \n",
            "\n",
            "   DR4_Vert_Avg  Year  Month  Day  Prev_Morning  Prev_Afternoon  Prev_Evening  \\\n",
            "0          14.5  2023      8    1            25               9             7   \n",
            "1           6.5  2023      8    2            13              20            26   \n",
            "2          18.0  2023      8    3            21              31             7   \n",
            "3           4.5  2023      8    4            15               5             2   \n",
            "4          10.5  2023      8    5            13              28            22   \n",
            "\n",
            "   Prev_Night  Prediction1  \n",
            "0           5          NaN  \n",
            "1          18          NaN  \n",
            "2          28          NaN  \n",
            "3           2          NaN  \n",
            "4          12          NaN  \n",
            "\n",
            "[5 rows x 38 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.2: # Converting the columns to integer in both datasets\n",
        "\n",
        "# Load the most recent CSVs\n",
        "train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/K_Handled_Prediction1_Train_Test_Data.csv')\n",
        "unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/L_Handled_Prediction1_Unseen_Data.csv')\n",
        "\n",
        "# List of columns to convert to integer (excluding 'Data_Type' and 'Prediction1' in unseen data)\n",
        "columns_to_convert_train_test = [col for col in train_test_data.columns if col != 'Data_Type']\n",
        "columns_to_convert_unseen = [col for col in unseen_data.columns if col != 'Data_Type' and col != 'Prediction1']\n",
        "\n",
        "# Convert columns to integer\n",
        "train_test_data[columns_to_convert_train_test] = train_test_data[columns_to_convert_train_test].astype(int)\n",
        "unseen_data[columns_to_convert_unseen] = unseen_data[columns_to_convert_unseen].astype(int)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/K_Handled_Prediction1_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/L_Handled_Prediction1_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the data types of the columns after conversion\n",
        "print(\"Data types of columns in train/test data after conversion:\")\n",
        "print(train_test_data.dtypes)\n",
        "\n",
        "print(\"\\nData types of columns in unseen data after conversion:\")\n",
        "print(unseen_data.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adGQ6YMGOsYv",
        "outputId": "3d254c2b-4c6e-4851-c8ed-a4420afdd04b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types of columns in train/test data after conversion:\n",
            "Row Number           int64\n",
            "Data_Type           object\n",
            "Draw1                int64\n",
            "DR1_Prev_Week        int64\n",
            "DR1_2Weeks           int64\n",
            "DR1_Prev_Entry       int64\n",
            "DR1_Prev_Entry-2     int64\n",
            "DR1_Mov_Avg          int64\n",
            "DR1_Vert_Avg         int64\n",
            "Draw2                int64\n",
            "DR2_Prev_Week        int64\n",
            "DR2_2Weeks           int64\n",
            "DR2_Prev_Entry       int64\n",
            "DR2_Prev_Entry-2     int64\n",
            "DR2_Mov_Avg          int64\n",
            "DR2_Vert_Avg         int64\n",
            "Draw3                int64\n",
            "DR3_Prev_Week        int64\n",
            "DR3_2Weeks           int64\n",
            "DR3_Prev_Entry       int64\n",
            "DR3_Prev_Entry-2     int64\n",
            "DR3_Mov_Avg          int64\n",
            "DR3_Vert_Avg         int64\n",
            "Draw4                int64\n",
            "DR4_Prev_Week        int64\n",
            "DR4_2Weeks           int64\n",
            "DR4_Prev_Entry       int64\n",
            "DR4_Prev_Entry-2     int64\n",
            "DR4_Mov_Avg          int64\n",
            "DR4_Vert_Avg         int64\n",
            "Year                 int64\n",
            "Month                int64\n",
            "Day                  int64\n",
            "Prev_Morning         int64\n",
            "Prev_Afternoon       int64\n",
            "Prev_Evening         int64\n",
            "Prev_Night           int64\n",
            "Prediction1          int64\n",
            "dtype: object\n",
            "\n",
            "Data types of columns in unseen data after conversion:\n",
            "Row Number            int64\n",
            "Data_Type            object\n",
            "Draw1                 int64\n",
            "DR1_Prev_Week         int64\n",
            "DR1_2Weeks            int64\n",
            "DR1_Prev_Entry        int64\n",
            "DR1_Prev_Entry-2      int64\n",
            "DR1_Mov_Avg           int64\n",
            "DR1_Vert_Avg          int64\n",
            "Draw2                 int64\n",
            "DR2_Prev_Week         int64\n",
            "DR2_2Weeks            int64\n",
            "DR2_Prev_Entry        int64\n",
            "DR2_Prev_Entry-2      int64\n",
            "DR2_Mov_Avg           int64\n",
            "DR2_Vert_Avg          int64\n",
            "Draw3                 int64\n",
            "DR3_Prev_Week         int64\n",
            "DR3_2Weeks            int64\n",
            "DR3_Prev_Entry        int64\n",
            "DR3_Prev_Entry-2      int64\n",
            "DR3_Mov_Avg           int64\n",
            "DR3_Vert_Avg          int64\n",
            "Draw4                 int64\n",
            "DR4_Prev_Week         int64\n",
            "DR4_2Weeks            int64\n",
            "DR4_Prev_Entry        int64\n",
            "DR4_Prev_Entry-2      int64\n",
            "DR4_Mov_Avg           int64\n",
            "DR4_Vert_Avg          int64\n",
            "Year                  int64\n",
            "Month                 int64\n",
            "Day                   int64\n",
            "Prev_Morning          int64\n",
            "Prev_Afternoon        int64\n",
            "Prev_Evening          int64\n",
            "Prev_Night            int64\n",
            "Prediction1         float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.1: # Introducing \"Lines\" as a new feature in both datasets\n",
        "\n",
        "# Load the most recent CSVs\n",
        "train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/K_Handled_Prediction1_Train_Test_Data.csv')\n",
        "unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/L_Handled_Prediction1_Unseen_Data.csv')\n",
        "\n",
        "# Function to assign \"Lines\" based on the sum of digits\n",
        "def assign_lines(data, column_name):\n",
        "    def get_lines(x):\n",
        "        try:\n",
        "            # Calculate the sum of digits\n",
        "            sum_of_digits = sum(map(int, str(x)))\n",
        "            # Ensure the sum is between 1 and 9\n",
        "            while sum_of_digits > 9:\n",
        "                sum_of_digits = sum(map(int, str(sum_of_digits)))\n",
        "            return sum_of_digits\n",
        "        except (ValueError, TypeError):\n",
        "            return None  # Handle non-convertible values by returning None\n",
        "\n",
        "    data[f'Lines_{column_name}'] = data[column_name].apply(get_lines)\n",
        "\n",
        "# List of columns to assign \"Lines\"\n",
        "columns_to_assign_lines = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "\n",
        "# Assign \"Lines\" to columns in train/test data\n",
        "for column in columns_to_assign_lines:\n",
        "    assign_lines(train_test_data, column)\n",
        "\n",
        "# Assign \"Lines\" to columns in unseen data\n",
        "for column in columns_to_assign_lines:\n",
        "    assign_lines(unseen_data, column)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/M_Lines_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/N_Lines_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of both datasets to verify the \"Lines\" assignment\n",
        "print(\"First few rows of train/test data with 'Lines' assigned:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data with 'Lines' assigned:\")\n",
        "print(unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qBmKgOFOskq",
        "outputId": "ee051bc5-8256-46ea-d692-54fdcd7bebec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of train/test data with 'Lines' assigned:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training     19              7          27              23   \n",
            "1           2  Training     31             11           1               9   \n",
            "2           3  Training     15             19          21              12   \n",
            "3           4  Training     31             35          18              35   \n",
            "4           5         0      0              0           0               0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  Month  Day  \\\n",
            "0                32           27            17     14  ...      8    1   \n",
            "1                33           21             6      3  ...      8    2   \n",
            "2                35           23            20      9  ...      8    3   \n",
            "3                23           29            26     21  ...      8    4   \n",
            "4                 0            0             0      0  ...      8    5   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  Prediction1  \\\n",
            "0            13              34            32          23           19   \n",
            "1            19              14            33           9           31   \n",
            "2            31               3            35          12           15   \n",
            "3            15               9            23          35           31   \n",
            "4            31              21            29          16            0   \n",
            "\n",
            "   Lines_Draw1  Lines_DR1_Prev_Week  Lines_DR1_Prev_Entry  \n",
            "0            1                    7                     5  \n",
            "1            4                    2                     9  \n",
            "2            6                    1                     3  \n",
            "3            4                    8                     8  \n",
            "4            0                    0                     0  \n",
            "\n",
            "[5 rows x 41 columns]\n",
            "\n",
            "First few rows of unseen data with 'Lines' assigned:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0        1410    Unseen     13             27          25               5   \n",
            "1        1411    Unseen     21             33          12              18   \n",
            "2        1412    Unseen     15             27           3              28   \n",
            "3        1413    Unseen     13             20          11               2   \n",
            "4        1414    Unseen     12             29          14              12   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  Month  Day  \\\n",
            "0                 7            6            26     20  ...      8    1   \n",
            "1                26           22            22     31  ...      8    2   \n",
            "2                 7           17            15      5  ...      8    3   \n",
            "3                 2            2            15     28  ...      8    4   \n",
            "4                22           17            21     35  ...      8    5   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  Prev_Night  Prediction1  \\\n",
            "0            25               9             7           5          NaN   \n",
            "1            13              20            26          18          NaN   \n",
            "2            21              31             7          28          NaN   \n",
            "3            15               5             2           2          NaN   \n",
            "4            13              28            22          12          NaN   \n",
            "\n",
            "   Lines_Draw1  Lines_DR1_Prev_Week  Lines_DR1_Prev_Entry  \n",
            "0            4                    9                     5  \n",
            "1            3                    6                     9  \n",
            "2            6                    9                     1  \n",
            "3            4                    2                     2  \n",
            "4            3                    2                     3  \n",
            "\n",
            "[5 rows x 41 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.2: # Introducing \"Special Groups\" as a new feature in both datasets\n",
        "\n",
        "# Load the most recent CSVs\n",
        "train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/M_Lines_Train_Test_Data.csv')\n",
        "unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/N_Lines_Unseen_Data.csv')\n",
        "\n",
        "# Define the mapping for \"Special Groups\"\n",
        "special_groups_mapping = {\n",
        "    2: 1, 15: 1, 16: 1, 24: 1, 31: 1,  # \"Ladies\"\n",
        "    4: 2, 5: 2, 12: 2, 29: 2, 34: 2,  # \"Men\"\n",
        "    11: 3, 17: 3, 26: 3,  # \"Birds\"\n",
        "    7: 4, 9: 4, 19: 4, 20: 4, 22: 4, 30: 4, 36: 4,  # \"Domestic Animals\"\n",
        "    8: 5, 10: 5, 13: 5, 25: 5,  # \"Wild Animals\"\n",
        "    18: 6, 28: 6, 32: 6,  # \"Ocean\"\n",
        "    1: 7, 27: 7, 33: 7, 35: 7,  # \"Snakes & Insects\"\n",
        "    3: 8, 6: 8, 14: 8, 21: 8, 23: 8  # \"Home\"\n",
        "}\n",
        "\n",
        "# Function to assign \"Special Groups\" based on the mapping\n",
        "def assign_special_groups(data, column_name, special_groups_mapping):\n",
        "    data[f'Special_Groups_{column_name}'] = data[column_name].map(special_groups_mapping).fillna(0).astype(int)\n",
        "\n",
        "# List of columns to assign \"Special Groups\"\n",
        "columns_to_assign_special_groups = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "\n",
        "# Assign \"Special Groups\" for specified columns in train/test data\n",
        "for column in columns_to_assign_special_groups:\n",
        "    assign_special_groups(train_test_data, column, special_groups_mapping)\n",
        "\n",
        "# Assign \"Special Groups\" for specified columns in unseen data\n",
        "for column in columns_to_assign_special_groups:\n",
        "    assign_special_groups(unseen_data, column, special_groups_mapping)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/O_Special_Groups_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/P_Special_Groups_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of both datasets to verify the \"Special Groups\" assignment\n",
        "print(\"First few rows of train/test data with 'Special Groups' assigned:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data with 'Special Groups' assigned:\")\n",
        "print(unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8TauDfPOtKG",
        "outputId": "8236a238-62b3-44b4-87b5-b218daeb4551"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of train/test data with 'Special Groups' assigned:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training     19              7          27              23   \n",
            "1           2  Training     31             11           1               9   \n",
            "2           3  Training     15             19          21              12   \n",
            "3           4  Training     31             35          18              35   \n",
            "4           5         0      0              0           0               0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  Prev_Afternoon  \\\n",
            "0                32           27            17     14  ...              34   \n",
            "1                33           21             6      3  ...              14   \n",
            "2                35           23            20      9  ...               3   \n",
            "3                23           29            26     21  ...               9   \n",
            "4                 0            0             0      0  ...              21   \n",
            "\n",
            "   Prev_Evening  Prev_Night  Prediction1  Lines_Draw1  Lines_DR1_Prev_Week  \\\n",
            "0            32          23           19            1                    7   \n",
            "1            33           9           31            4                    2   \n",
            "2            35          12           15            6                    1   \n",
            "3            23          35           31            4                    8   \n",
            "4            29          16            0            0                    0   \n",
            "\n",
            "   Lines_DR1_Prev_Entry  Special_Groups_Draw1  Special_Groups_DR1_Prev_Week  \\\n",
            "0                     5                     4                             4   \n",
            "1                     9                     1                             3   \n",
            "2                     3                     1                             4   \n",
            "3                     8                     1                             7   \n",
            "4                     0                     0                             0   \n",
            "\n",
            "   Special_Groups_DR1_Prev_Entry  \n",
            "0                              8  \n",
            "1                              4  \n",
            "2                              2  \n",
            "3                              7  \n",
            "4                              0  \n",
            "\n",
            "[5 rows x 44 columns]\n",
            "\n",
            "First few rows of unseen data with 'Special Groups' assigned:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0        1410    Unseen     13             27          25               5   \n",
            "1        1411    Unseen     21             33          12              18   \n",
            "2        1412    Unseen     15             27           3              28   \n",
            "3        1413    Unseen     13             20          11               2   \n",
            "4        1414    Unseen     12             29          14              12   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  Prev_Afternoon  \\\n",
            "0                 7            6            26     20  ...               9   \n",
            "1                26           22            22     31  ...              20   \n",
            "2                 7           17            15      5  ...              31   \n",
            "3                 2            2            15     28  ...               5   \n",
            "4                22           17            21     35  ...              28   \n",
            "\n",
            "   Prev_Evening  Prev_Night  Prediction1  Lines_Draw1  Lines_DR1_Prev_Week  \\\n",
            "0             7           5          NaN            4                    9   \n",
            "1            26          18          NaN            3                    6   \n",
            "2             7          28          NaN            6                    9   \n",
            "3             2           2          NaN            4                    2   \n",
            "4            22          12          NaN            3                    2   \n",
            "\n",
            "   Lines_DR1_Prev_Entry  Special_Groups_Draw1  Special_Groups_DR1_Prev_Week  \\\n",
            "0                     5                     5                             7   \n",
            "1                     9                     8                             7   \n",
            "2                     1                     1                             7   \n",
            "3                     2                     5                             4   \n",
            "4                     3                     2                             2   \n",
            "\n",
            "   Special_Groups_DR1_Prev_Entry  \n",
            "0                              2  \n",
            "1                              6  \n",
            "2                              6  \n",
            "3                              1  \n",
            "4                              2  \n",
            "\n",
            "[5 rows x 44 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.3: # Introducing \"Spirits\" as a new feature in both datasets\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the most recent CSVs\n",
        "train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/O_Special_Groups_Train_Test_Data.csv')\n",
        "unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/P_Special_Groups_Unseen_Data.csv')\n",
        "\n",
        "# Define a mapping dictionary for \"Spirits\" pairs\n",
        "spirits_mapping = {\n",
        "    1: 5,\n",
        "    2: 24,\n",
        "    3: 19,\n",
        "    4: 35,\n",
        "    5: 1,\n",
        "    6: 15,\n",
        "    7: 13,\n",
        "    8: 29,\n",
        "    9: 33,\n",
        "    10: 28,\n",
        "    11: 36,\n",
        "    12: 32,\n",
        "    13: 7,\n",
        "    14: 25,\n",
        "    15: 6,\n",
        "    16: 17,\n",
        "    17: 16,\n",
        "    18: 30,\n",
        "    19: 3,\n",
        "    20: 22,\n",
        "    21: 23,\n",
        "    22: 20,\n",
        "    23: 21,\n",
        "    24: 2,\n",
        "    25: 14,\n",
        "    26: 27,\n",
        "    27: 26,\n",
        "    28: 10,\n",
        "    29: 8,\n",
        "    30: 18,\n",
        "    31: 34,\n",
        "    32: 12,\n",
        "    33: 9,\n",
        "    34: 31,\n",
        "    35: 4,\n",
        "    36: 11\n",
        "}\n",
        "\n",
        "# Function to assign \"Spirits\" based on the mapping\n",
        "def assign_spirits(data, column_name, spirits_mapping):\n",
        "    data[f'Spirits_{column_name}'] = data[column_name].map(spirits_mapping).fillna(0).astype(int)\n",
        "\n",
        "# List of columns to assign \"Spirits\"\n",
        "columns_to_assign_spirits = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "\n",
        "# Assign \"Spirits\" for specified columns in train/test data\n",
        "for column in columns_to_assign_spirits:\n",
        "    assign_spirits(train_test_data, column, spirits_mapping)\n",
        "\n",
        "# Assign \"Spirits\" for specified columns in unseen data\n",
        "for column in columns_to_assign_spirits:\n",
        "    assign_spirits(unseen_data, column, spirits_mapping)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/Q_Spirits_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/R_Spirits_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of both datasets to verify the \"Spirits\" assignment\n",
        "print(\"First few rows of train/test data with 'Spirits' assigned:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data with 'Spirits' assigned:\")\n",
        "print(unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8T-Y4tK20PV",
        "outputId": "39e949bf-108c-4ff1-cbcf-546d59b1e535"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of train/test data with 'Spirits' assigned:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training     19              7          27              23   \n",
            "1           2  Training     31             11           1               9   \n",
            "2           3  Training     15             19          21              12   \n",
            "3           4  Training     31             35          18              35   \n",
            "4           5         0      0              0           0               0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  Prediction1  \\\n",
            "0                32           27            17     14  ...           19   \n",
            "1                33           21             6      3  ...           31   \n",
            "2                35           23            20      9  ...           15   \n",
            "3                23           29            26     21  ...           31   \n",
            "4                 0            0             0      0  ...            0   \n",
            "\n",
            "   Lines_Draw1  Lines_DR1_Prev_Week  Lines_DR1_Prev_Entry  \\\n",
            "0            1                    7                     5   \n",
            "1            4                    2                     9   \n",
            "2            6                    1                     3   \n",
            "3            4                    8                     8   \n",
            "4            0                    0                     0   \n",
            "\n",
            "   Special_Groups_Draw1  Special_Groups_DR1_Prev_Week  \\\n",
            "0                     4                             4   \n",
            "1                     1                             3   \n",
            "2                     1                             4   \n",
            "3                     1                             7   \n",
            "4                     0                             0   \n",
            "\n",
            "   Special_Groups_DR1_Prev_Entry  Spirits_Draw1  Spirits_DR1_Prev_Week  \\\n",
            "0                              8              3                     13   \n",
            "1                              4             34                     36   \n",
            "2                              2              6                      3   \n",
            "3                              7             34                      4   \n",
            "4                              0              0                      0   \n",
            "\n",
            "   Spirits_DR1_Prev_Entry  \n",
            "0                      21  \n",
            "1                      33  \n",
            "2                      32  \n",
            "3                       4  \n",
            "4                       0  \n",
            "\n",
            "[5 rows x 47 columns]\n",
            "\n",
            "First few rows of unseen data with 'Spirits' assigned:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0        1410    Unseen     13             27          25               5   \n",
            "1        1411    Unseen     21             33          12              18   \n",
            "2        1412    Unseen     15             27           3              28   \n",
            "3        1413    Unseen     13             20          11               2   \n",
            "4        1414    Unseen     12             29          14              12   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  Prediction1  \\\n",
            "0                 7            6            26     20  ...          NaN   \n",
            "1                26           22            22     31  ...          NaN   \n",
            "2                 7           17            15      5  ...          NaN   \n",
            "3                 2            2            15     28  ...          NaN   \n",
            "4                22           17            21     35  ...          NaN   \n",
            "\n",
            "   Lines_Draw1  Lines_DR1_Prev_Week  Lines_DR1_Prev_Entry  \\\n",
            "0            4                    9                     5   \n",
            "1            3                    6                     9   \n",
            "2            6                    9                     1   \n",
            "3            4                    2                     2   \n",
            "4            3                    2                     3   \n",
            "\n",
            "   Special_Groups_Draw1  Special_Groups_DR1_Prev_Week  \\\n",
            "0                     5                             7   \n",
            "1                     8                             7   \n",
            "2                     1                             7   \n",
            "3                     5                             4   \n",
            "4                     2                             2   \n",
            "\n",
            "   Special_Groups_DR1_Prev_Entry  Spirits_Draw1  Spirits_DR1_Prev_Week  \\\n",
            "0                              2              7                     26   \n",
            "1                              6             23                      9   \n",
            "2                              6              6                     26   \n",
            "3                              1              7                     22   \n",
            "4                              2             32                      8   \n",
            "\n",
            "   Spirits_DR1_Prev_Entry  \n",
            "0                       1  \n",
            "1                      30  \n",
            "2                      10  \n",
            "3                      24  \n",
            "4                      32  \n",
            "\n",
            "[5 rows x 47 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.4: # Introducing \"Rakes\" as a new feature in both datasets\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the most recent CSVs\n",
        "train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/Q_Spirits_Train_Test_Data.csv')\n",
        "unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/R_Spirits_Unseen_Data.csv')\n",
        "\n",
        "# Define a mapping dictionary for \"Rakes\" associations\n",
        "rakes_mapping = {\n",
        "    1: '36 First and Last',\n",
        "    1: '7 Hog and Knife',\n",
        "    2: '16 Old Jamette',\n",
        "    2: '24 Old Fowl',\n",
        "    3: '34 22 Three Blind Mice',\n",
        "    3: '35 Carriage On Road',\n",
        "    3: '19 Horse and Carriage',\n",
        "    4: '32 Dead Wood',\n",
        "    4: '21 Death Announcement',\n",
        "    4: '14 Dead Money',\n",
        "    4: '26 Crowd from dead',\n",
        "    4: '7 11 Sunset Drive',\n",
        "    5: '31 Parson Man, Parson Wife',\n",
        "    6: '25 Back and Belly',\n",
        "    6: '32 Wood in Belly',\n",
        "    6: '14 Bag of Money',\n",
        "    7: '21 Hog Mouth',\n",
        "    8: '3 Tiger In Cage',\n",
        "    8: '33 Lion In Net',\n",
        "    8: '7 Tiger Hunting',\n",
        "    8: '14 Blood Money',\n",
        "    9: '32 Bull Pistle',\n",
        "    9: '11 Sept 11th',\n",
        "    10: '32 Monkey Shrimps',\n",
        "    10: '27 Monkey On Vine',\n",
        "    11: '17 Black and White',\n",
        "    12: '10 King Kong',\n",
        "    12: '9 Clear or dirty water',\n",
        "    12: '1 King and I',\n",
        "    13: '10 Girl Child, Boy Child',\n",
        "    14: '6 Money In Pocket',\n",
        "    14: '23 Money In Bank',\n",
        "    14: '33 Big Money, Small Money',\n",
        "    15: '20 Sick like a Dog',\n",
        "    16: '23 Jamette In Hotel',\n",
        "    16: '35 Jamette Wining',\n",
        "    17: '29 Young Drunk',\n",
        "    18: '29 Rock D Boat',\n",
        "    18: '28 Fish In the Boat',\n",
        "    19: '35 Horse on Track',\n",
        "    19: '32 Horse Wood',\n",
        "    19: '36 Horse and Ass',\n",
        "    20: '5 Worm On Fog',\n",
        "    20: '24 Dog Food',\n",
        "    20: '14 Dog Money',\n",
        "    20: '30 Dog and Cat',\n",
        "    21: '19 Straight from the Horse’s Mouth',\n",
        "    22: '24 Rat Looking For Goods',\n",
        "    22: '30 Tom and Jerry',\n",
        "    22: '32 Rat Wood',\n",
        "    23: '31 House Wife',\n",
        "    24: '21 Food In Mouth',\n",
        "    25: '13 Hard Back, Soft Back',\n",
        "    26: '15 Fowl Sickness',\n",
        "    27: '35 Little Snake, Big Snake',\n",
        "    27: '19 Horse Whip',\n",
        "    27: '14 Coil of Money',\n",
        "    28: '36 Fish in Sea',\n",
        "    28: '12 King Fish',\n",
        "    28: '6 Fish Guts',\n",
        "    28: '33 Fish in Net',\n",
        "    29: '6 Rum Belly',\n",
        "    29: '13 Drunk and Spread Out',\n",
        "    29: '1 Rum Bottle',\n",
        "    29: '16 Drunk like Jamette',\n",
        "    30: '35 Golden Cobra',\n",
        "    30: '6 Gold Sack',\n",
        "    30: '6 Cat in Bag',\n",
        "    31: '16 Big & Small Jamette',\n",
        "    31: '5 Parson Man and Wife',\n",
        "    32: '1 Bottle & Spoon',\n",
        "    33: '9 Cow eating Grass',\n",
        "    33: '5 Spider-man',\n",
        "    33: '10 Spider Monkey',\n",
        "    34: '1 Cemetery & Lights',\n",
        "    35: '12 King Cobra',\n",
        "    36: '18 Bridge & Water'\n",
        "}\n",
        "\n",
        "# Function to assign \"Rakes\" based on the mapping\n",
        "def assign_rakes(data, column_name, rakes_mapping):\n",
        "    data[f'Rakes_{column_name}'] = data[column_name].map(rakes_mapping).fillna('').astype(str)\n",
        "\n",
        "# List of columns to assign \"Rakes\"\n",
        "columns_to_assign_rakes = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "\n",
        "# Assign \"Rakes\" for specified columns in train/test data\n",
        "for column in columns_to_assign_rakes:\n",
        "    assign_rakes(train_test_data, column, rakes_mapping)\n",
        "\n",
        "# Assign \"Rakes\" for specified columns in unseen data\n",
        "for column in columns_to_assign_rakes:\n",
        "    assign_rakes(unseen_data, column, rakes_mapping)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/S_Rakes_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/T_Rakes_Unseen_Data.csv', index=False)\n",
        "\n",
        "# Display the first few rows of both datasets to verify the \"Rakes\" assignment\n",
        "print(\"First few rows of train/test data with 'Rakes' assigned:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data with 'Rakes' assigned:\")\n",
        "print(unseen_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMFBQpu76ONH",
        "outputId": "fcef96e3-636e-4222-8fe4-7c4329d42e2c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of train/test data with 'Rakes' assigned:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training     19              7          27              23   \n",
            "1           2  Training     31             11           1               9   \n",
            "2           3  Training     15             19          21              12   \n",
            "3           4  Training     31             35          18              35   \n",
            "4           5         0      0              0           0               0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  \\\n",
            "0                32           27            17     14  ...   \n",
            "1                33           21             6      3  ...   \n",
            "2                35           23            20      9  ...   \n",
            "3                23           29            26     21  ...   \n",
            "4                 0            0             0      0  ...   \n",
            "\n",
            "   Lines_DR1_Prev_Entry  Special_Groups_Draw1  Special_Groups_DR1_Prev_Week  \\\n",
            "0                     5                     4                             4   \n",
            "1                     9                     1                             3   \n",
            "2                     3                     1                             4   \n",
            "3                     8                     1                             7   \n",
            "4                     0                     0                             0   \n",
            "\n",
            "   Special_Groups_DR1_Prev_Entry  Spirits_Draw1  Spirits_DR1_Prev_Week  \\\n",
            "0                              8              3                     13   \n",
            "1                              4             34                     36   \n",
            "2                              2              6                      3   \n",
            "3                              7             34                      4   \n",
            "4                              0              0                      0   \n",
            "\n",
            "   Spirits_DR1_Prev_Entry            Rakes_Draw1  Rakes_DR1_Prev_Week  \\\n",
            "0                      21       36 Horse and Ass         21 Hog Mouth   \n",
            "1                      33  5 Parson Man and Wife   17 Black and White   \n",
            "2                      32     20 Sick like a Dog     36 Horse and Ass   \n",
            "3                       4  5 Parson Man and Wife        12 King Cobra   \n",
            "4                       0                                               \n",
            "\n",
            "   Rakes_DR1_Prev_Entry  \n",
            "0         31 House Wife  \n",
            "1          11 Sept 11th  \n",
            "2          1 King and I  \n",
            "3         12 King Cobra  \n",
            "4                        \n",
            "\n",
            "[5 rows x 50 columns]\n",
            "\n",
            "First few rows of unseen data with 'Rakes' assigned:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0        1410    Unseen     13             27          25               5   \n",
            "1        1411    Unseen     21             33          12              18   \n",
            "2        1412    Unseen     15             27           3              28   \n",
            "3        1413    Unseen     13             20          11               2   \n",
            "4        1414    Unseen     12             29          14              12   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  \\\n",
            "0                 7            6            26     20  ...   \n",
            "1                26           22            22     31  ...   \n",
            "2                 7           17            15      5  ...   \n",
            "3                 2            2            15     28  ...   \n",
            "4                22           17            21     35  ...   \n",
            "\n",
            "   Lines_DR1_Prev_Entry  Special_Groups_Draw1  Special_Groups_DR1_Prev_Week  \\\n",
            "0                     5                     5                             7   \n",
            "1                     9                     8                             7   \n",
            "2                     1                     1                             7   \n",
            "3                     2                     5                             4   \n",
            "4                     3                     2                             2   \n",
            "\n",
            "   Special_Groups_DR1_Prev_Entry  Spirits_Draw1  Spirits_DR1_Prev_Week  \\\n",
            "0                              2              7                     26   \n",
            "1                              6             23                      9   \n",
            "2                              6              6                     26   \n",
            "3                              1              7                     22   \n",
            "4                              2             32                      8   \n",
            "\n",
            "   Spirits_DR1_Prev_Entry                         Rakes_Draw1  \\\n",
            "0                       1            10 Girl Child, Boy Child   \n",
            "1                      30  19 Straight from the Horse’s Mouth   \n",
            "2                      10                  20 Sick like a Dog   \n",
            "3                      24            10 Girl Child, Boy Child   \n",
            "4                      32                        1 King and I   \n",
            "\n",
            "     Rakes_DR1_Prev_Week        Rakes_DR1_Prev_Entry  \n",
            "0       14 Coil of Money  31 Parson Man, Parson Wife  \n",
            "1       10 Spider Monkey         28 Fish In the Boat  \n",
            "2       14 Coil of Money              33 Fish in Net  \n",
            "3         30 Dog and Cat                 24 Old Fowl  \n",
            "4  16 Drunk like Jamette                1 King and I  \n",
            "\n",
            "[5 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5.1: # Changing Data_Type column from categorical to numerical\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the most recent CSVs\n",
        "train_test_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/S_Rakes_Train_Test_Data.csv')\n",
        "unseen_data = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/T_Rakes_Unseen_Data.csv')\n",
        "\n",
        "# Map 'Data_Type' to numerical values, including 0 in the mapping\n",
        "data_type_mapping = {'Training': 1, 'Testing': 2, 'Unseen': 3}\n",
        "train_test_data['Data_Type'] = train_test_data['Data_Type'].map(data_type_mapping)\n",
        "unseen_data['Data_Type'] = train_test_data['Data_Type'].map(data_type_mapping)\n",
        "\n",
        "# Replace any remaining NaNs with 0 in the 'Data_Type' column\n",
        "train_test_data['Data_Type'].fillna(0, inplace=True)\n",
        "unseen_data['Data_Type'].fillna(0, inplace=True)\n",
        "\n",
        "# Convert the 'Data_Type' column to integers\n",
        "train_test_data['Data_Type'] = train_test_data['Data_Type'].astype(int)\n",
        "unseen_data['Data_Type'] = train_test_data['Data_Type'].astype(int)\n",
        "\n",
        "# Save the updated datasets\n",
        "train_test_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/U_Encoded_Train_Test_Data.csv', index=False)\n",
        "unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/V_Encoded_Unseen_Data.csv', index=False)\n",
        "\n",
        "print(\"First few rows of training/testing data:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "print(\"First few rows of unseen data:\")\n",
        "print(unseen_data.head())\n"
      ],
      "metadata": {
        "id": "wwYJCfNV4fxG",
        "outputId": "85dbaedb-4998-4afa-f2b8-cc0aa76eb1a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of training/testing data:\n",
            "   Row Number  Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1          1     19              7          27              23   \n",
            "1           2          1     31             11           1               9   \n",
            "2           3          1     15             19          21              12   \n",
            "3           4          1     31             35          18              35   \n",
            "4           5          0      0              0           0               0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  \\\n",
            "0                32           27            17     14  ...   \n",
            "1                33           21             6      3  ...   \n",
            "2                35           23            20      9  ...   \n",
            "3                23           29            26     21  ...   \n",
            "4                 0            0             0      0  ...   \n",
            "\n",
            "   Lines_DR1_Prev_Entry  Special_Groups_Draw1  Special_Groups_DR1_Prev_Week  \\\n",
            "0                     5                     4                             4   \n",
            "1                     9                     1                             3   \n",
            "2                     3                     1                             4   \n",
            "3                     8                     1                             7   \n",
            "4                     0                     0                             0   \n",
            "\n",
            "   Special_Groups_DR1_Prev_Entry  Spirits_Draw1  Spirits_DR1_Prev_Week  \\\n",
            "0                              8              3                     13   \n",
            "1                              4             34                     36   \n",
            "2                              2              6                      3   \n",
            "3                              7             34                      4   \n",
            "4                              0              0                      0   \n",
            "\n",
            "   Spirits_DR1_Prev_Entry            Rakes_Draw1  Rakes_DR1_Prev_Week  \\\n",
            "0                      21       36 Horse and Ass         21 Hog Mouth   \n",
            "1                      33  5 Parson Man and Wife   17 Black and White   \n",
            "2                      32     20 Sick like a Dog     36 Horse and Ass   \n",
            "3                       4  5 Parson Man and Wife        12 King Cobra   \n",
            "4                       0                    NaN                  NaN   \n",
            "\n",
            "   Rakes_DR1_Prev_Entry  \n",
            "0         31 House Wife  \n",
            "1          11 Sept 11th  \n",
            "2          1 King and I  \n",
            "3         12 King Cobra  \n",
            "4                   NaN  \n",
            "\n",
            "[5 rows x 50 columns]\n",
            "First few rows of unseen data:\n",
            "   Row Number  Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0        1410          1     13             27          25               5   \n",
            "1        1411          1     21             33          12              18   \n",
            "2        1412          1     15             27           3              28   \n",
            "3        1413          1     13             20          11               2   \n",
            "4        1414          0     12             29          14              12   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Draw2  ...  \\\n",
            "0                 7            6            26     20  ...   \n",
            "1                26           22            22     31  ...   \n",
            "2                 7           17            15      5  ...   \n",
            "3                 2            2            15     28  ...   \n",
            "4                22           17            21     35  ...   \n",
            "\n",
            "   Lines_DR1_Prev_Entry  Special_Groups_Draw1  Special_Groups_DR1_Prev_Week  \\\n",
            "0                     5                     5                             7   \n",
            "1                     9                     8                             7   \n",
            "2                     1                     1                             7   \n",
            "3                     2                     5                             4   \n",
            "4                     3                     2                             2   \n",
            "\n",
            "   Special_Groups_DR1_Prev_Entry  Spirits_Draw1  Spirits_DR1_Prev_Week  \\\n",
            "0                              2              7                     26   \n",
            "1                              6             23                      9   \n",
            "2                              6              6                     26   \n",
            "3                              1              7                     22   \n",
            "4                              2             32                      8   \n",
            "\n",
            "   Spirits_DR1_Prev_Entry                         Rakes_Draw1  \\\n",
            "0                       1            10 Girl Child, Boy Child   \n",
            "1                      30  19 Straight from the Horse’s Mouth   \n",
            "2                      10                  20 Sick like a Dog   \n",
            "3                      24            10 Girl Child, Boy Child   \n",
            "4                      32                        1 King and I   \n",
            "\n",
            "     Rakes_DR1_Prev_Week        Rakes_DR1_Prev_Entry  \n",
            "0       14 Coil of Money  31 Parson Man, Parson Wife  \n",
            "1       10 Spider Monkey         28 Fish In the Boat  \n",
            "2       14 Coil of Money              33 Fish in Net  \n",
            "3         30 Dog and Cat                 24 Old Fowl  \n",
            "4  16 Drunk like Jamette                1 King and I  \n",
            "\n",
            "[5 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FPuNXxZPG2Rf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lixNbXei4ghR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ":::::**bold text** *italicized text*"
      ],
      "metadata": {
        "id": "c7irQ4xrLOIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MYjrY8s4Dz5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################\n",
        "# Cell 1.3: Preprocessing Training/Testing Data\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Function to preprocess training/testing data\n",
        "def preprocess_train_test_data(data):\n",
        "    print(\"Initial data columns:\", data.columns)\n",
        "\n",
        "    # Remove rows where 'Draw1' is NaN\n",
        "    data = data.dropna(subset=['Draw1'])\n",
        "\n",
        "    # Convert 'Date' to datetime with the correct format\n",
        "    if 'Date' in data.columns:\n",
        "        print(\"Converting 'Date' to datetime...\")\n",
        "        data['Date'] = pd.to_datetime(data['Date'], format='%d-%m-%y')  # Specify the correct format here\n",
        "        data['Year'] = data['Date'].dt.year\n",
        "        data['Month'] = data['Date'].dt.month\n",
        "        data['Day'] = data['Date'].dt.day\n",
        "        print(\"After extracting Year, Month, Day:\", data.columns)\n",
        "        data.drop(columns=['Date'], inplace=True)\n",
        "        print(\"After dropping 'Date':\", data.columns)\n",
        "    else:\n",
        "        print(\"Date column not found in the given dataset.\")\n",
        "\n",
        "    # Initialize TARGET VARIABLE 'Prediction1' column with 'Draw1' values\n",
        "    data['Prediction1'] = data['Draw1']\n",
        "\n",
        "    # Create shifted columns for previous day's data\n",
        "    data['Prev_Morning'] = data['Draw1'].shift(1)\n",
        "    data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
        "    data['Prev_Evening'] = data['Draw3'].shift(1)\n",
        "    data['Prev_Night'] = data['Draw4'].shift(1)\n",
        "\n",
        "    # Handle NaN values\n",
        "    data['Prev_Morning'].fillna(13, inplace=True)\n",
        "    data['Prev_Afternoon'].fillna(34, inplace=True)\n",
        "    data['Prev_Evening'].fillna(32, inplace=True)\n",
        "    data['Prev_Night'].fillna(23, inplace=True)\n",
        "\n",
        "    # Select relevant columns, including 'Prediction1'\n",
        "    selected_columns = ['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
        "    'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night', 'Prediction1', 'Year', 'Month', 'Day']\n",
        "    data = data[selected_columns]\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply preprocessing to the training/testing dataset\n",
        "train_test_data = preprocess_train_test_data(train_test_data)\n",
        "\n",
        "# Save the preprocessed model training/testing data directly to your Google Drive folder\n",
        "save_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/C_Preprocessed_Train_Test_Data.csv'\n",
        "train_test_data.to_csv(save_path, index=False)\n",
        "\n",
        "# Display the first few rows of the preprocessed data for verification\n",
        "print(\"First few rows of preprocessed training/testing data:\")\n",
        "print(train_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aARJ03VjGuJY",
        "outputId": "caeaef41-ba0e-44b8-bfc8-980324b1cda1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial data columns: Index(['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
            "       'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
            "       'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks', 'DR2_Prev_Entry',\n",
            "       'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg', 'Draw3',\n",
            "       'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry', 'DR3_Prev_Entry-2',\n",
            "       'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4', 'DR4_Prev_Week', 'DR4_2Weeks',\n",
            "       'DR4_Prev_Entry', 'DR4_Prev_Entry-2', 'DR4_Mov_Avg', 'DR4_Vert_Avg',\n",
            "       'Year', 'Month', 'Day', 'Prev_Morning', 'Prev_Afternoon',\n",
            "       'Prev_Evening', 'Prev_Night', 'Prediction1', 'Lines_Draw1',\n",
            "       'Lines_DR1_Prev_Week', 'Lines_DR1_Prev_Entry', 'Special_Groups_Draw1',\n",
            "       'Special_Groups_DR1_Prev_Week', 'Special_Groups_DR1_Prev_Entry',\n",
            "       'Spirits_Draw1', 'Spirits_DR1_Prev_Week', 'Spirits_DR1_Prev_Entry',\n",
            "       'Rakes_Draw1', 'Rakes_DR1_Prev_Week', 'Rakes_DR1_Prev_Entry'],\n",
            "      dtype='object')\n",
            "Date column not found in the given dataset.\n",
            "First few rows of preprocessed training/testing data:\n",
            "   Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  DR1_Prev_Entry  \\\n",
            "0           1  Training     19              7          27              23   \n",
            "1           2  Training     31             11           1               9   \n",
            "2           3  Training     15             19          21              12   \n",
            "3           4  Training     31             35          18              35   \n",
            "4           5         0      0              0           0               0   \n",
            "\n",
            "   DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  Prev_Morning  Prev_Afternoon  \\\n",
            "0                32           27            17          13.0            34.0   \n",
            "1                33           21             6          19.0            14.0   \n",
            "2                35           23            20          31.0             3.0   \n",
            "3                23           29            26          15.0             9.0   \n",
            "4                 0            0             0          31.0            21.0   \n",
            "\n",
            "   Prev_Evening  Prev_Night  Prediction1  Year  Month  Day  \n",
            "0          32.0        23.0           19  2018      8    1  \n",
            "1          33.0         9.0           31  2018      8    2  \n",
            "2          35.0        12.0           15  2018      8    3  \n",
            "3          23.0        35.0           31  2018      8    4  \n",
            "4          29.0        16.0            0  2018      8    5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.4: Preprocessing Model Unseen Data\n",
        "\n",
        "# Define the path to the CSV file for model unseen data\n",
        "csv_filename_unseen = 'B_Initial_Unseen_Data.csv'\n",
        "drive_csv_path_unseen = os.path.join(drive_dataset_directory, csv_filename_unseen)\n",
        "\n",
        "# Load the model unseen data\n",
        "model_unseen_data = load_dataset(drive_csv_path_unseen)\n",
        "\n",
        "# Function to preprocess unseen data\n",
        "def preprocess_unseen_data(data):\n",
        "    print(\"Initial data columns:\", data.columns)\n",
        "\n",
        "    # Remove rows where 'Draw1' is NaN\n",
        "    data = data.dropna(subset=['Draw1'])\n",
        "\n",
        "    # Define possible date formats\n",
        "    date_formats = ['%d-%m-%y', '%d/%m/%Y']\n",
        "\n",
        "    # Try to convert 'Date' to datetime with different formats\n",
        "    for date_format in date_formats:\n",
        "        try:\n",
        "            if 'Date' in data.columns:\n",
        "                print(\"Converting 'Date' to datetime...\")\n",
        "                data['Date'] = pd.to_datetime(data['Date'], format=date_format)\n",
        "                data['Year'] = data['Date'].dt.year\n",
        "                data['Month'] = data['Date'].dt.month\n",
        "                data['Day'] = data['Date'].dt.day\n",
        "                print(\"After extracting Year, Month, Day:\", data.columns)\n",
        "                data.drop(columns=['Date'], inplace=True)\n",
        "                print(\"After dropping 'Date':\", data.columns)\n",
        "\n",
        "            # Initialize TARGET VARIABLE 'Prediction1' column with NaN values\n",
        "            data['Prediction1'] = np.nan\n",
        "\n",
        "            # Create shifted columns for previous day's data\n",
        "            data['Prev_Morning'] = data['Draw1'].shift(1)\n",
        "            data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
        "            data['Prev_Evening'] = data['Draw3'].shift(1)\n",
        "            data['Prev_Night'] = data['Draw4'].shift(1)\n",
        "\n",
        "            # Handle NaN values\n",
        "            data['Prev_Morning'].fillna(25, inplace=True)\n",
        "            data['Prev_Afternoon'].fillna(9, inplace=True)\n",
        "            data['Prev_Evening'].fillna(7, inplace=True)\n",
        "            data['Prev_Night'].fillna(5, inplace=True)\n",
        "\n",
        "            # Select relevant columns, including 'Prediction1'\n",
        "            selected_columns = ['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
        "            'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night', 'Prediction1', 'Year', 'Month', 'Day']\n",
        "            data = data[selected_columns]\n",
        "\n",
        "            # Save the preprocessed model unseen data directly to your Google Drive folder\n",
        "            save_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/D_Preprocessed_Unseen_Data.csv'\n",
        "            model_unseen_data.to_csv(save_path, index=False)\n",
        "\n",
        "            # Display the first few rows of the preprocessed data for verification\n",
        "            print(\"First few rows of preprocessed model unseen data:\")\n",
        "            print(model_unseen_data.head())\n",
        "\n",
        "\n",
        "            break  # Break the loop if successful date conversion\n",
        "\n",
        "        except ValueError:\n",
        "            print(\"Failed to convert 'Date' with format:\", date_format)\n",
        "\n",
        "# Apply preprocessing to the model unseen data\n",
        "preprocess_unseen_data(model_unseen_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhcW-7C8XvpW",
        "outputId": "3125fe96-7ec6-4f03-d036-1549fcc29113"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File found. Proceeding to load the dataset.\n",
            "Initial data columns: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg'],\n",
            "      dtype='object')\n",
            "Converting 'Date' to datetime...\n",
            "Failed to convert 'Date' with format: %d-%m-%y\n",
            "Converting 'Date' to datetime...\n",
            "After extracting Year, Month, Day: Index(['Date', 'Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week',\n",
            "       'DR1_2Weeks', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg',\n",
            "       'DR1_Vert_Avg', 'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks',\n",
            "       'DR2_Prev_Entry', 'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg',\n",
            "       'Draw3', 'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry',\n",
            "       'DR3_Prev_Entry-2', 'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4',\n",
            "       'DR4_Prev_Week', 'DR4_2Weeks', 'DR4_Prev_Entry', 'DR4_Prev_Entry-2',\n",
            "       'DR4_Mov_Avg', 'DR4_Vert_Avg', 'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n",
            "After dropping 'Date': Index(['Row Number', 'Data_Type', 'Draw1', 'DR1_Prev_Week', 'DR1_2Weeks',\n",
            "       'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
            "       'Draw2', 'DR2_Prev_Week', 'DR2_2Weeks', 'DR2_Prev_Entry',\n",
            "       'DR2_Prev_Entry-2', 'DR2_Mov_Avg', 'DR2_Vert_Avg', 'Draw3',\n",
            "       'DR3_Prev_Week', 'DR3_2Weeks', 'DR3_Prev_Entry', 'DR3_Prev_Entry-2',\n",
            "       'DR3_Mov_Avg', 'DR3_Vert_Avg', 'Draw4', 'DR4_Prev_Week', 'DR4_2Weeks',\n",
            "       'DR4_Prev_Entry', 'DR4_Prev_Entry-2', 'DR4_Mov_Avg', 'DR4_Vert_Avg',\n",
            "       'Year', 'Month', 'Day'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-f7e2b7ad31b0>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Date'] = pd.to_datetime(data['Date'], format=date_format)\n",
            "<ipython-input-15-f7e2b7ad31b0>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Year'] = data['Date'].dt.year\n",
            "<ipython-input-15-f7e2b7ad31b0>:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Month'] = data['Date'].dt.month\n",
            "<ipython-input-15-f7e2b7ad31b0>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Day'] = data['Date'].dt.day\n",
            "<ipython-input-15-f7e2b7ad31b0>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.drop(columns=['Date'], inplace=True)\n",
            "<ipython-input-15-f7e2b7ad31b0>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prediction1'] = np.nan\n",
            "<ipython-input-15-f7e2b7ad31b0>:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Morning'] = data['Draw1'].shift(1)\n",
            "<ipython-input-15-f7e2b7ad31b0>:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Afternoon'] = data['Draw2'].shift(1)\n",
            "<ipython-input-15-f7e2b7ad31b0>:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Evening'] = data['Draw3'].shift(1)\n",
            "<ipython-input-15-f7e2b7ad31b0>:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Night'] = data['Draw4'].shift(1)\n",
            "<ipython-input-15-f7e2b7ad31b0>:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Morning'].fillna(25, inplace=True)\n",
            "<ipython-input-15-f7e2b7ad31b0>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Afternoon'].fillna(9, inplace=True)\n",
            "<ipython-input-15-f7e2b7ad31b0>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Evening'].fillna(7, inplace=True)\n",
            "<ipython-input-15-f7e2b7ad31b0>:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Prev_Night'].fillna(5, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of preprocessed model unseen data:\n",
            "       Date  Row Number Data_Type  Draw1  DR1_Prev_Week  DR1_2Weeks  \\\n",
            "0  1/8/2023        1410    Unseen   13.0           27.0        25.0   \n",
            "1  2/8/2023        1411    Unseen   21.0           33.0        12.0   \n",
            "2  3/8/2023        1412    Unseen   15.0           27.0         3.0   \n",
            "3  4/8/2023        1413    Unseen   13.0           20.0        11.0   \n",
            "4  5/8/2023        1414    Unseen   12.0           29.0        14.0   \n",
            "\n",
            "   DR1_Prev_Entry  DR1_Prev_Entry-2  DR1_Mov_Avg  DR1_Vert_Avg  ...  \\\n",
            "0             5.0               7.0          6.0          26.0  ...   \n",
            "1            18.0              26.0         22.0          22.5  ...   \n",
            "2            28.0               7.0         17.5          15.0  ...   \n",
            "3             2.0               2.0          2.0          15.5  ...   \n",
            "4            12.0              22.0         17.0          21.5  ...   \n",
            "\n",
            "   DR3_Prev_Entry-2  DR3_Mov_Avg  DR3_Vert_Avg  Draw4  DR4_Prev_Week  \\\n",
            "0              13.0         16.5          25.0   18.0           26.0   \n",
            "1              21.0         26.0           6.0   28.0            8.0   \n",
            "2              15.0         10.0          18.0    2.0           30.0   \n",
            "3              13.0         20.5          26.0   12.0            2.0   \n",
            "4              12.0         23.5          18.5   11.0            3.0   \n",
            "\n",
            "   DR4_2Weeks  DR4_Prev_Entry  DR4_Prev_Entry-2  DR4_Mov_Avg  DR4_Vert_Avg  \n",
            "0         3.0            26.0              20.0         23.0          14.5  \n",
            "1         5.0             7.0              31.0         19.0           6.5  \n",
            "2         6.0             2.0               5.0          3.5          18.0  \n",
            "3         7.0            22.0              28.0         25.0           4.5  \n",
            "4        18.0            31.0              35.0         33.0          10.5  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.5: Print and investigate presence of NaNs in Model Unseen Data\n",
        "\n",
        "# Check for NaN values in training/testing data\n",
        "print(\"NaN check for training/testing data:\")\n",
        "print(train_test_data.isna().sum())\n",
        "\n",
        "# Check for NaN values in model unseen data\n",
        "print(\"\\nNaN check for model unseen data:\")\n",
        "print(model_unseen_data.isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9PH8HbW1ToU",
        "outputId": "7570778c-7d9a-4672-eb34-fa32cc33da25"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN check for training/testing data:\n",
            "Row Number          0\n",
            "Data_Type           0\n",
            "Draw1               0\n",
            "DR1_Prev_Week       0\n",
            "DR1_2Weeks          0\n",
            "DR1_Prev_Entry      0\n",
            "DR1_Prev_Entry-2    0\n",
            "DR1_Mov_Avg         0\n",
            "DR1_Vert_Avg        0\n",
            "Prev_Morning        0\n",
            "Prev_Afternoon      0\n",
            "Prev_Evening        0\n",
            "Prev_Night          0\n",
            "Prediction1         0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "dtype: int64\n",
            "\n",
            "NaN check for model unseen data:\n",
            "Date                0\n",
            "Row Number          0\n",
            "Data_Type           4\n",
            "Draw1               4\n",
            "DR1_Prev_Week       4\n",
            "DR1_2Weeks          4\n",
            "DR1_Prev_Entry      4\n",
            "DR1_Prev_Entry-2    4\n",
            "DR1_Mov_Avg         4\n",
            "DR1_Vert_Avg        4\n",
            "Draw2               4\n",
            "DR2_Prev_Week       4\n",
            "DR2_2Weeks          4\n",
            "DR2_Prev_Entry      4\n",
            "DR2_Prev_Entry-2    4\n",
            "DR2_Mov_Avg         4\n",
            "DR2_Vert_Avg        4\n",
            "Draw3               4\n",
            "DR3_Prev_Week       4\n",
            "DR3_2Weeks          4\n",
            "DR3_Prev_Entry      4\n",
            "DR3_Prev_Entry-2    4\n",
            "DR3_Mov_Avg         4\n",
            "DR3_Vert_Avg        4\n",
            "Draw4               4\n",
            "DR4_Prev_Week       4\n",
            "DR4_2Weeks          4\n",
            "DR4_Prev_Entry      4\n",
            "DR4_Prev_Entry-2    4\n",
            "DR4_Mov_Avg         4\n",
            "DR4_Vert_Avg        4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.1: Creating \"LINES\" feature for Training/Testing and Unseen Datasets\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the path to the CSV file for preprocessed training/testing data\n",
        "preprocessed_train_test_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/C_Preprocessed_Train_Test_Data.csv'\n",
        "\n",
        "# Define the path to the CSV file for preprocessed model unseen data\n",
        "preprocessed_unseen_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/D_Preprocessed_Unseen_Data.csv'\n",
        "\n",
        "# Load preprocessed training/testing data\n",
        "preprocessed_train_test_data = pd.read_csv(preprocessed_train_test_data_path)\n",
        "\n",
        "# Load preprocessed unseen data\n",
        "preprocessed_unseen_data = pd.read_csv(preprocessed_unseen_data_path)\n",
        "\n",
        "# List of columns to convert to integers\n",
        "int_columns = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry', 'DR1_Prev_Entry-2', 'DR1_Mov_Avg', 'DR1_Vert_Avg',\n",
        "               'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night']\n",
        "\n",
        "# Convert specified columns to integers for both datasets\n",
        "preprocessed_train_test_data[int_columns] = preprocessed_train_test_data[int_columns].astype(int)\n",
        "preprocessed_unseen_data[int_columns] = preprocessed_unseen_data[int_columns].astype(int)\n",
        "\n",
        "# Function to assign \"Lines\" based on the sum of digits\n",
        "def assign_lines(data, column_name):\n",
        "    def get_lines(x):\n",
        "        try:\n",
        "            # Calculate the sum of digits\n",
        "            sum_of_digits = sum(map(int, str(x)))\n",
        "            # Ensure the sum is between 1 and 9\n",
        "            while sum_of_digits > 9:\n",
        "                sum_of_digits = sum(map(int, str(sum_of_digits)))\n",
        "            return sum_of_digits\n",
        "        except (ValueError, TypeError):\n",
        "            return None  # Handle non-convertible values by returning None\n",
        "\n",
        "    data[f'Lines_{column_name}'] = data[column_name].apply(get_lines)\n",
        "\n",
        "# Handle NaN values in the 'Prediction1' column for unseen data by filling them with 0\n",
        "preprocessed_unseen_data['Prediction1'].fillna(0, inplace=True)\n",
        "\n",
        "# Assign \"Lines\" for specified columns in both datasets\n",
        "columns_to_assign_lines = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "for column in columns_to_assign_lines:\n",
        "    assign_lines(preprocessed_train_test_data, column)\n",
        "    assign_lines(preprocessed_unseen_data, column)\n",
        "\n",
        "# Define file paths for the new CSVs with \"Lines\"\n",
        "lines_train_test_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/E_Lines_Train_Test_Data.csv'\n",
        "lines_unseen_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/F_Lines_Unseen_Data.csv'\n",
        "\n",
        "# Save the datasets with \"Lines\" to new CSVs\n",
        "preprocessed_train_test_data.to_csv(lines_train_test_data_path, index=False)\n",
        "preprocessed_unseen_data.to_csv(lines_unseen_data_path, index=False)\n",
        "\n",
        "# Display a sample of the processed data for verification\n",
        "print(\"Sample of preprocessed training/testing data with 'Lines_Draw1':\")\n",
        "print(preprocessed_train_test_data[['Row Number', 'Draw1', 'Lines_Draw1']].head())\n",
        "\n",
        "print(\"\\nSample of preprocessed unseen data with 'Lines_Draw1':\")\n",
        "print(preprocessed_unseen_data[['Row Number', 'Draw1', 'Lines_Draw1']].head())\n"
      ],
      "metadata": {
        "id": "zwgfUWQo0gEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "126706b6-689f-49d0-997e-c4852e8e398e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3e1ff875f4ab>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Convert specified columns to integers for both datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mpreprocessed_train_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessed_train_test_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mpreprocessed_unseen_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint_columns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessed_unseen_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Function to assign \"Lines\" based on the sum of digits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3813\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3815\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6068\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6070\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6072\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6132\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6133\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6135\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prev_Night'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.2: Loading Datasets for \"Special Groups\"\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define file paths for the preprocessed training/testing and unseen data\n",
        "preprocessed_train_test_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/C_Preprocessed_Train_Test_Data.csv'\n",
        "preprocessed_unseen_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/D_Preprocessed_Unseen_Data.csv'\n",
        "\n",
        "# Load preprocessed training/testing data\n",
        "preprocessed_train_test_data = pd.read_csv(preprocessed_train_test_data_path)\n",
        "\n",
        "# Load preprocessed unseen data\n",
        "preprocessed_unseen_data = pd.read_csv(preprocessed_unseen_data_path)\n",
        "\n",
        "# Display the first few rows of the loaded data to verify\n",
        "preprocessed_train_test_data.head()\n",
        "preprocessed_unseen_data.head()\n"
      ],
      "metadata": {
        "id": "feiR8iFN0hBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2.3: Creating \"Special Groups\" feature for Training/Testing and Unseen Datasets\n",
        "\n",
        "# Define the mapping for \"Special Groups\"\n",
        "special_groups_mapping = {\n",
        "    2: 1, 15: 1, 16: 1, 24: 1, 31: 1,  # \"Ladies\"\n",
        "    4: 2, 5: 2, 12: 2, 29: 2, 34: 2,  # \"Men\"\n",
        "    11: 3, 17: 3, 26: 3,  # \"Birds\"\n",
        "    7: 4, 9: 4, 19: 4, 20: 4, 22: 4, 30: 4, 36: 4,  # \"Domestic Animals\"\n",
        "    8: 5, 10: 5, 13: 5, 25: 5,  # \"Wild Animals\"\n",
        "    18: 6, 28: 6, 32: 6,  # \"Ocean\"\n",
        "    1: 7, 27: 7, 33: 7, 35: 7,  # \"Snakes & Insects\"\n",
        "    3: 8, 6: 8, 14: 8, 21: 8, 23: 8  # \"Home\"\n",
        "}\n",
        "\n",
        "# Function to assign \"Special Groups\" based on the mapping\n",
        "def assign_special_groups(data, column_name, special_groups_mapping):\n",
        "    data[f'Special_Groups_{column_name}'] = data[column_name].map(special_groups_mapping).fillna(0).astype(int)\n",
        "\n",
        "# Assign \"Special Groups\" for specified columns in both datasets\n",
        "columns_to_assign_special_groups = ['Draw1', 'DR1_Prev_Week', 'DR1_Prev_Entry']\n",
        "for column in columns_to_assign_special_groups:\n",
        "    assign_special_groups(train_test_data, column, special_groups_mapping)\n",
        "    assign_special_groups(unseen_data, column, special_groups_mapping)\n",
        "\n",
        "# Save the datasets with \"Special Groups\" to new CSVs\n",
        "special_groups_train_test_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/G_Special_Groups_Train_Test_Data.csv'\n",
        "special_groups_unseen_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Initial_Data_Prep/H_Special_Groups_Unseen_Data.csv'\n",
        "\n",
        "train_test_data.to_csv(special_groups_train_test_data_path, index=False)\n",
        "unseen_data.to_csv(special_groups_unseen_data_path, index=False)\n",
        "\n",
        "# Load the datasets with \"Special Groups\"\n",
        "special_groups_train_test_data = pd.read_csv(special_groups_train_test_data_path)\n",
        "special_groups_unseen_data = pd.read_csv(special_groups_unseen_data_path)\n",
        "\n",
        "# Display the first few rows of the datasets to investigate the issue\n",
        "print(\"First few rows of special_groups_train_test_data:\")\n",
        "print(special_groups_train_test_data.head())\n",
        "\n",
        "print(\"\\nFirst few rows of special_groups_unseen_data:\")\n",
        "print(special_groups_unseen_data.head())"
      ],
      "metadata": {
        "id": "TgHqp-uTnTyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2NiVstWrZE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eYAyxCevrZZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ES57Mh6gnVmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.3: Data Loading from Google Drive and Preprocessing Unseen Dataset\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the directory for datasets in Google Drive\n",
        "drive_dataset_directory = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/'\n",
        "\n",
        "# Define the path to the CSV file for unseen data\n",
        "csv_filename_unseen = 'Model_Unseen_Data.csv'\n",
        "drive_csv_path_unseen = os.path.join(drive_dataset_directory, csv_filename_unseen)\n",
        "\n",
        "# Check and load the dataset\n",
        "def load_dataset(file_path):\n",
        "    if os.path.isfile(file_path):\n",
        "        print(\"File found. Proceeding to load the dataset.\")\n",
        "        return pd.read_csv(file_path)\n",
        "    else:\n",
        "        print(\"File not found. Check the file path or the Google Drive mount.\")\n",
        "        return None\n",
        "\n",
        "unseen_data = load_dataset(drive_csv_path_unseen)\n",
        "\n",
        "# Function to preprocess unseen data\n",
        "def preprocess_unseen_data(data):\n",
        "    print(\"Initial data columns:\", data.columns)\n",
        "\n",
        "    # Convert 'Date' to datetime and extract 'Year', 'Month', and 'Day'\n",
        "    if 'Date' in data.columns:\n",
        "        print(\"Converting 'Date' to datetime...\")\n",
        "        data['Date'] = pd.to_datetime(data['Date'])\n",
        "        data['Year'] = data['Date'].dt.year\n",
        "        data['Month'] = data['Date'].dt.month\n",
        "        data['Day'] = data['Date'].dt.day\n",
        "        print(\"After extracting Year, Month, Day:\", data.columns)\n",
        "        data.drop(columns=['Date'], inplace=True)\n",
        "        print(\"After dropping 'Date':\", data.columns)\n",
        "    else:\n",
        "        print(\"Date column not found in the given dataset.\")\n",
        "\n",
        "    # Initialize 'Prediction1' column with NaNs for unseen data\n",
        "    data['Prediction1'] = np.nan\n",
        "\n",
        "    # Create shifted columns for previous day's data\n",
        "    data['Prev_Morning'] = data['Morning'].shift(1)\n",
        "    data['Prev_Afternoon'] = data['Afternoon'].shift(1)\n",
        "    data['Prev_Evening'] = data['Evening'].shift(1)\n",
        "\n",
        "    # Calculate moving averages excluding current row\n",
        "    initial_window_size = 3  # Increased by 1 to exclude the current row\n",
        "    columns_to_average = ['Morning', 'Afternoon', 'Evening', 'Night']\n",
        "    target_columns = ['Mov_Avg_Mor', 'Mov_Avg_Aft', 'Mov_Avg_Eve', 'Mov_Avg_Nig']\n",
        "\n",
        "    for col, target_col in zip(columns_to_average, target_columns):\n",
        "    # Roll over an additional row and then shift to exclude the current row\n",
        "        data[target_col] = data[col].rolling(window=initial_window_size, min_periods=1).mean().shift(1)\n",
        "    # Manually set the value for the first row\n",
        "    unseen_data.at[0, 'Mov_Avg_Mor'] = 6\n",
        "    unseen_data.at[1, 'Mov_Avg_Mor'] = 22\n",
        "    unseen_data.at[2, 'Mov_Avg_Mor'] = 17.5\n",
        "    unseen_data.at[3, 'Mov_Avg_Mor'] = 2\n",
        "    unseen_data.at[4, 'Mov_Avg_Mor'] = 17\n",
        "\n",
        "    # Calculate vertical averages excluding current row\n",
        "    vertical_target_columns = ['Vert_Avg_Mor', 'Vert_Avg_Aft', 'Vert_Avg_Eve', 'Vert_Avg_Nig']\n",
        "    for col, target_col in zip(columns_to_average, vertical_target_columns):\n",
        "        data[target_col] = data[col].rolling(window=3, min_periods=1).mean().shift(1)\n",
        "\n",
        "    # Handle NaN values\n",
        "    data['Prev_Morning'].fillna(25, inplace=True)\n",
        "    data['Prev_Afternoon'].fillna(9, inplace=True)\n",
        "    data['Prev_Evening'].fillna(7, inplace=True)\n",
        "\n",
        "    # Select relevant columns, including 'Prediction1'\n",
        "    selected_columns = ['Row Number', 'Data_Type', 'Year', 'Month', 'Day', 'Prev_Week', 'Prev_Entry', 'Mov_Avg_Mor', 'Vert_Avg_Mor', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prediction1']\n",
        "    data[selected_columns]\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply preprocessing to the unseen dataset\n",
        "unseen_data = preprocess_unseen_data(unseen_data)\n",
        "\n",
        "# Display the preprocessed unseen data\n",
        "print(\"First few rows of preprocessed unseen data:\")\n",
        "print(unseen_data.head())"
      ],
      "metadata": {
        "id": "WsY7Mvh7Jp1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.4: # Save the preprocessed training/testing dataset\n",
        "preprocessed_train_test_path = os.path.join(drive_dataset_directory, '1_preprocessed_train_test_data.csv')\n",
        "train_test_data.to_csv(preprocessed_train_test_path, index=False)\n",
        "print(\"Preprocessed training/testing data saved to Google Drive.\")\n",
        "\n",
        "# Display the first few rows of the preprocessed training/testing data\n",
        "print(\"First few rows of preprocessed training/testing data:\")\n",
        "print(train_test_data.head())\n",
        "\n",
        "# Check for NaN values in the entire dataset\n",
        "nan_counts = train_test_data.isnull().sum()\n",
        "print(\"Count of NaN values in training/testing data:\")\n",
        "print(nan_counts)\n",
        "\n",
        "# Save the preprocessed unseen dataset\n",
        "preprocessed_unseen_path = os.path.join(drive_dataset_directory, '2_preprocessed_unseen_data.csv')\n",
        "unseen_data.to_csv(preprocessed_unseen_path, index=False)\n",
        "print(\"Preprocessed unseen data saved to Google Drive.\")\n",
        "\n",
        "# Display the first few rows of the preprocessed unseen data\n",
        "print(\"First few rows of preprocessed unseen data:\")\n",
        "print(unseen_data.head())\n",
        "\n",
        "# Check for NaN values in the entire dataset\n",
        "nan_counts = unseen_data.isnull().sum()\n",
        "print(\"Count of NaN values in unseen data:\")\n",
        "print(nan_counts)\n"
      ],
      "metadata": {
        "id": "ncZjXqqlHgvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging\n",
        "import os\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define the directory for datasets in Google Drive\n",
        "drive_dataset_directory = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/'\n",
        "\n",
        "# Define the path to the preprocessed unseen data\n",
        "preprocessed_unseen_path = os.path.join(drive_dataset_directory, '2_preprocessed_unseen_data.csv')\n",
        "\n",
        "# Load the preprocessed unseen data\n",
        "unseen_data = pd.read_csv(preprocessed_unseen_path)\n",
        "logger.info(\"Preprocessed unseen data loaded successfully.\")\n",
        "\n",
        "# Define the provided data for imputation\n",
        "provided_data = [\n",
        "    {\n",
        "        'Row Number': 1410,\n",
        "        'Morning': 13,\n",
        "        'Prev_Week': 27,\n",
        "        '2WeeksM': 25,\n",
        "        'Prev_Entry': 5,\n",
        "        'Prev_Entry-2': 7,\n",
        "        'Mov_Avg_Mor': 6,\n",
        "        'Vert_Avg_Mor': 26,\n",
        "        'Afternoon': 20,\n",
        "        'Prev_Week': 7,\n",
        "        '2WeeksA': 34,\n",
        "        'Prev_Entry': 13,\n",
        "        'Prev_Entry-2': 5,\n",
        "        'Mov_Avg_Aft': 9,\n",
        "        'Vert_Avg_Aft': 20.5,\n",
        "        'Evening': 26,\n",
        "        'Prev_Week': 26,\n",
        "        '2WeeksE': 24,\n",
        "        'Prev_Entry': 20,\n",
        "        'Prev_Entry-2': 13,\n",
        "        'Mov_Avg_Eve': 16.5,\n",
        "        'Vert_Avg_Eve': 25,\n",
        "        'Night': 18,\n",
        "        'Prev_Week': 26,\n",
        "        '2WeeksN': 3,\n",
        "        'Prev_Entry': 26,\n",
        "        'Prev_Entry-2': 20,\n",
        "        'Mov_Avg_Nig': 23,\n",
        "        'Vert_Avg_Nig': 14.5\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1411,\n",
        "        'Morning': 21,\n",
        "        'Prev_Week': 33,\n",
        "        '2WeeksM': 12,\n",
        "        'Prev_Entry': 18,\n",
        "        'Prev_Entry-2': 26,\n",
        "        'Mov_Avg_Mor': 22,\n",
        "        'Vert_Avg_Mor': 22.5,\n",
        "        'Afternoon': 31,\n",
        "        'Prev_Week': 18,\n",
        "        '2WeeksA': 36,\n",
        "        'Prev_Entry': 21,\n",
        "        'Prev_Entry-2': 18,\n",
        "        'Mov_Avg_Aft': 19.5,\n",
        "        'Vert_Avg_Aft': 27,\n",
        "        'Evening': 7,\n",
        "        'Prev_Week': 9,\n",
        "        '2WeeksE': 3,\n",
        "        'Prev_Entry': 31,\n",
        "        'Prev_Entry-2': 21,\n",
        "        'Mov_Avg_Eve': 26,\n",
        "        'Vert_Avg_Eve': 6,\n",
        "        'Night': 28,\n",
        "        'Prev_Week': 8,\n",
        "        '2WeeksN': 5,\n",
        "        'Prev_Entry': 7,\n",
        "        'Prev_Entry-2': 31,\n",
        "        'Mov_Avg_Nig': 19,\n",
        "        'Vert_Avg_Nig': 6.5\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1412,\n",
        "        'Morning': 15,\n",
        "        'Prev_Week': 27,\n",
        "        '2WeeksM': 3,\n",
        "        'Prev_Entry': 28,\n",
        "        'Prev_Entry-2': 7,\n",
        "        'Mov_Avg_Mor': 17.5,\n",
        "        'Vert_Avg_Mor': 15,\n",
        "        'Afternoon': 5,\n",
        "        'Prev_Week': 22,\n",
        "        '2WeeksA': 10,\n",
        "        'Prev_Entry': 15,\n",
        "        'Prev_Entry-2': 28,\n",
        "        'Mov_Avg_Aft': 21.5,\n",
        "        'Vert_Avg_Aft': 16,\n",
        "        'Evening': 2,\n",
        "        'Prev_Week': 32,\n",
        "        '2WeeksE': 4,\n",
        "        'Prev_Entry': 5,\n",
        "        'Prev_Entry-2': 15,\n",
        "        'Mov_Avg_Eve': 10,\n",
        "        'Vert_Avg_Eve': 18,\n",
        "        'Night': 2,\n",
        "        'Prev_Week': 30,\n",
        "        '2WeeksN': 6,\n",
        "        'Prev_Entry': 2,\n",
        "        'Prev_Entry-2': 5,\n",
        "        'Mov_Avg_Nig': 3.5,\n",
        "        'Vert_Avg_Nig': 18\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1413,\n",
        "        'Morning': 13,\n",
        "        'Prev_Week': 20,\n",
        "        '2WeeksM': 11,\n",
        "        'Prev_Entry': 2,\n",
        "        'Prev_Entry-2': 2,\n",
        "        'Mov_Avg_Mor': 2,\n",
        "        'Vert_Avg_Mor': 15.5,\n",
        "        'Row Number': 1413,\n",
        "        'Afternoon': 28,\n",
        "        'Prev_Week': 29,\n",
        "        '2WeeksA': 19,\n",
        "        'Prev_Entry': 13,\n",
        "        'Prev_Entry-2': 2,\n",
        "        'Mov_Avg_Aft': 7.5,\n",
        "        'Vert_Avg_Aft': 24,\n",
        "        'Evening': 22,\n",
        "        'Prev_Week': 23,\n",
        "        '2WeeksE': 29,\n",
        "        'Prev_Entry': 28,\n",
        "        'Prev_Entry-2': 13,\n",
        "        'Mov_Avg_Eve': 20.5,\n",
        "        'Vert_Avg_Eve': 26,\n",
        "        'Night': 12,\n",
        "        'Prev_Week': 2,\n",
        "        '2WeeksN': 7,\n",
        "        'Prev_Entry': 22,\n",
        "        'Prev_Entry-2': 28,\n",
        "        'Mov_Avg_Nig': 25,\n",
        "        'Vert_Avg_Nig': 4.5\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1414,\n",
        "        'Morning': 12,\n",
        "        'Prev_Week': 29,\n",
        "        '2WeeksM': 14,\n",
        "        'Prev_Entry': 12,\n",
        "        'Prev_Entry-2': 22,\n",
        "        'Mov_Avg_Mor': 17,\n",
        "        'Vert_Avg_Mor': 21.5,\n",
        "        'Row Number': 1414,\n",
        "        'Afternoon': 35,\n",
        "        'Prev_Week': 7,\n",
        "        '2WeeksA': 31,\n",
        "        'Prev_Entry': 12,\n",
        "        'Prev_Entry-2': 12,\n",
        "        'Mov_Avg_Aft': 12,\n",
        "        'Vert_Avg_Aft': 19,\n",
        "        'Evening': 31,\n",
        "        'Prev_Week': 5,\n",
        "        '2WeeksE': 32,\n",
        "        'Prev_Entry': 35,\n",
        "        'Prev_Entry-2': 12,\n",
        "        'Mov_Avg_Eve': 23.5,\n",
        "        'Vert_Avg_Eve': 18.5,\n",
        "        'Night': 11,\n",
        "        'Prev_Week': 3,\n",
        "        '2WeeksN': 18,\n",
        "        'Prev_Entry': 31,\n",
        "        'Prev_Entry-2': 35,\n",
        "        'Mov_Avg_Nig': 33,\n",
        "        'Vert_Avg_Nig': 10.5\n",
        "    },\n",
        "    {\n",
        "        'Row Number': 1415,\n",
        "        'Morning': 14,\n",
        "        'Prev_Week': 25,\n",
        "        '2WeeksM': 5,\n",
        "        'Prev_Entry': 11,\n",
        "        'Prev_Entry-2': 31,\n",
        "        'Mov_Avg_Mor': 21,\n",
        "        'Vert_Avg_Mor': 15,\n",
        "        'Row Number': 1415,\n",
        "        'Afternoon': 2,\n",
        "        'Prev_Week': 9,\n",
        "        '2WeeksA': 14,\n",
        "        'Prev_Entry': 14,\n",
        "        'Prev_Entry-2': 11,\n",
        "        'Mov_Avg_Aft': 12.5,\n",
        "        'Vert_Avg_Aft': 11.5,\n",
        "        'Evening': 23,\n",
        "        'Prev_Week': 7,\n",
        "        '2WeeksE': 30,\n",
        "        'Prev_Entry': 2,\n",
        "        'Prev_Entry-2': 14,\n",
        "        'Mov_Avg_Eve': 8,\n",
        "        'Vert_Avg_Eve': 18.5,\n",
        "        'Row Number': 1415,\n",
        "        'Night': 25,\n",
        "        'Prev_Week': 5,\n",
        "        '2WeeksN': 22,\n",
        "        'Prev_Entry': 23,\n",
        "        'Prev_Entry-2': 2,\n",
        "        'Mov_Avg_Nig': 12.5,\n",
        "        'Vert_Avg_Nig': 13.5\n",
        "    }\n",
        "]\n",
        "\n",
        "# Iterate through the provided data to update the corresponding columns in the DataFrame\n",
        "for data in provided_data:\n",
        "    row_number = data['Row Number']\n",
        "    for column in data.keys():\n",
        "        if column != 'Row Number':\n",
        "            unseen_data.loc[unseen_data['Row Number'] == row_number, column] = data[column]\n",
        "\n",
        "# Display the dataset after NaN handling\n",
        "print(\"First few rows of unseen data after NaN handling:\")\n",
        "print(unseen_data.head())\n",
        "\n",
        "# Check for NaN values in the entire dataset\n",
        "nan_counts = unseen_data.isnull().sum()\n",
        "print(\"Count of NaN values in unseen data:\")\n",
        "print(nan_counts)\n",
        "\n",
        "# Save the updated unseen data\n",
        "updated_unseen_path = os.path.join(drive_dataset_directory, '2_preprocessed_unseen_data.csv')\n",
        "unseen_data.to_csv(updated_unseen_path, index=False)\n",
        "logger.info(\"Updated unseen data saved successfully.\")\n"
      ],
      "metadata": {
        "id": "Jt0eLKc5qADl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}