{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvinfranklyndavis/Project2023_v3/blob/main/Project2023_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5_mSX_NpQgo",
        "outputId": "18a986dc-592a-48db-d0b0-f8a5bf9916e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (3.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1o87z4evvCLwBtqX8ocZl3I2nIDYS8mtH\n",
            "To: /content/Training_Testing_Hybrid_Mod.csv\n",
            "100%|██████████| 71.9k/71.9k [00:00<00:00, 3.79MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Date  Day of the Week  Morning  Prev_Week  Rep_Prev_Week  \\\n",
            "0  8/1/2018                3       19          7              0   \n",
            "1  8/2/2018                4       31         11              0   \n",
            "2  8/3/2018                5       15         19              0   \n",
            "3  8/4/2018                6       31         35              0   \n",
            "4  8/6/2018                1       31         18              0   \n",
            "\n",
            "   Rep_Prev_Entry  Afternoon  Prev_Week.1  Rep_Prev_Week.1  Rep_Prev_Entry.1  \\\n",
            "0               0         14           13                0                 0   \n",
            "1               0          3           21                0                 0   \n",
            "2               0          9           19                0                 0   \n",
            "3               0         21           20                0                 0   \n",
            "4               0         31           30                0                 1   \n",
            "\n",
            "   Evening  Prev_Week.2  Rep_Prev_Week.2  Rep_Prev_Entry.2  Night  \\\n",
            "0       33           28                0                 0      9   \n",
            "1       35           31                0                 0     12   \n",
            "2       23            1                0                 0     35   \n",
            "3       29           27                0                 0     16   \n",
            "4       15           14                0                 0     18   \n",
            "\n",
            "   Prev_Week.3  Rep_Prev_Week.3  Rep_Prev_Entry.3  \n",
            "0            7                0                 0  \n",
            "1           11                0                 0  \n",
            "2           19                0                 0  \n",
            "3           35                0                 0  \n",
            "4           18                1                 0  \n",
            "Date                object\n",
            "Day of the Week      int64\n",
            "Morning              int64\n",
            "Prev_Week            int64\n",
            "Rep_Prev_Week        int64\n",
            "Rep_Prev_Entry       int64\n",
            "Afternoon            int64\n",
            "Prev_Week.1          int64\n",
            "Rep_Prev_Week.1      int64\n",
            "Rep_Prev_Entry.1     int64\n",
            "Evening              int64\n",
            "Prev_Week.2          int64\n",
            "Rep_Prev_Week.2      int64\n",
            "Rep_Prev_Entry.2     int64\n",
            "Night                int64\n",
            "Prev_Week.3          int64\n",
            "Rep_Prev_Week.3      int64\n",
            "Rep_Prev_Entry.3     int64\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Upgrade pip and install required packages\n",
        "!pip install -U --upgrade-strategy eager pip\n",
        "!pip install -U --upgrade-strategy eager pandas gdown numpy matplotlib scikit-learn xgboost shap\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import gdown\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import shap\n",
        "\n",
        "# Define the URL of the CSV file\n",
        "csv_url = 'https://drive.google.com/uc?id=1o87z4evvCLwBtqX8ocZl3I2nIDYS8mtH'\n",
        "\n",
        "# Define the local file path to save the CSV\n",
        "csv_path = 'Training_Testing_Hybrid_Mod.csv'\n",
        "\n",
        "# Download the CSV file from the Google Drive link\n",
        "gdown.download(csv_url, csv_path, quiet=False)\n",
        "\n",
        "# Load the dataset into a Pandas DataFrame\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Display the first few rows and data types\n",
        "print(df.head())\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kLEMu5Qqp4s",
        "outputId": "602494d4-6209-4394-bfa3-19aa7aa0b52d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Day of the Week  Morning  Prev_Week  Rep_Prev_Week  Rep_Prev_Entry  \\\n",
            "0                3       19          7              0               0   \n",
            "1                4       31         11              0               0   \n",
            "2                5       15         19              0               0   \n",
            "3                6       31         35              0               0   \n",
            "4                1       31         18              0               0   \n",
            "\n",
            "   Afternoon  Prev_Week.1  Rep_Prev_Week.1  Rep_Prev_Entry.1  Evening  ...  \\\n",
            "0         14           13                0                 0       33  ...   \n",
            "1          3           21                0                 0       35  ...   \n",
            "2          9           19                0                 0       23  ...   \n",
            "3         21           20                0                 0       29  ...   \n",
            "4         31           30                0                 1       15  ...   \n",
            "\n",
            "   Prev_Week.3  Rep_Prev_Week.3  Rep_Prev_Entry.3  Year  Month  Day  \\\n",
            "0            7                0                 0  2018      8    1   \n",
            "1           11                0                 0  2018      8    2   \n",
            "2           19                0                 0  2018      8    3   \n",
            "3           35                0                 0  2018      8    4   \n",
            "4           18                1                 0  2018      8    6   \n",
            "\n",
            "   Prediction1  Prediction2  Prediction3  Prediction4  \n",
            "0          NaN          NaN          NaN          NaN  \n",
            "1          NaN          NaN          NaN          NaN  \n",
            "2          NaN          NaN          NaN          NaN  \n",
            "3          NaN          NaN          NaN          NaN  \n",
            "4          NaN          NaN          NaN          NaN  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "Day of the Week       int64\n",
            "Morning               int64\n",
            "Prev_Week             int64\n",
            "Rep_Prev_Week         int64\n",
            "Rep_Prev_Entry        int64\n",
            "Afternoon             int64\n",
            "Prev_Week.1           int64\n",
            "Rep_Prev_Week.1       int64\n",
            "Rep_Prev_Entry.1      int64\n",
            "Evening               int64\n",
            "Prev_Week.2           int64\n",
            "Rep_Prev_Week.2       int64\n",
            "Rep_Prev_Entry.2      int64\n",
            "Night                 int64\n",
            "Prev_Week.3           int64\n",
            "Rep_Prev_Week.3       int64\n",
            "Rep_Prev_Entry.3      int64\n",
            "Year                  int32\n",
            "Month                 int32\n",
            "Day                   int32\n",
            "Prediction1         float64\n",
            "Prediction2         float64\n",
            "Prediction3         float64\n",
            "Prediction4         float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Convert 'Date' column to datetime type\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Extract relevant date features\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Day'] = df['Date'].dt.day\n",
        "\n",
        "# Drop the original 'Date' column\n",
        "df = df.drop(columns=['Date'])\n",
        "\n",
        "# Create Target Variable columns\n",
        "df['Prediction1'] = np.nan\n",
        "df['Prediction2'] = np.nan\n",
        "df['Prediction3'] = np.nan\n",
        "df['Prediction4'] = np.nan\n",
        "\n",
        "# Display the updated DataFrame with target variables\n",
        "print(df.head())\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-HHNFfZua6v",
        "outputId": "ab3949ab-b5b4-4be5-fbad-504e64892ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values:\n",
            " Day of the Week        0\n",
            "Morning                0\n",
            "Prev_Week              0\n",
            "Rep_Prev_Week          0\n",
            "Rep_Prev_Entry         0\n",
            "Afternoon              0\n",
            "Prev_Week.1            0\n",
            "Rep_Prev_Week.1        0\n",
            "Rep_Prev_Entry.1       0\n",
            "Evening                0\n",
            "Prev_Week.2            0\n",
            "Rep_Prev_Week.2        0\n",
            "Rep_Prev_Entry.2       0\n",
            "Night                  0\n",
            "Prev_Week.3            0\n",
            "Rep_Prev_Week.3        0\n",
            "Rep_Prev_Entry.3       0\n",
            "Year                   0\n",
            "Month                  0\n",
            "Day                    0\n",
            "Prediction1         1409\n",
            "Prediction2         1409\n",
            "Prediction3         1409\n",
            "Prediction4         1409\n",
            "dtype: int64\n",
            "Missing Values in Target Variables:\n",
            " Prediction1    1409\n",
            "Prediction2    1409\n",
            "Prediction3    1409\n",
            "Prediction4    1409\n",
            "dtype: int64\n",
            "   Day of the Week  Morning  Prev_Week  Rep_Prev_Week  Rep_Prev_Entry  \\\n",
            "0                3       19          7              0               0   \n",
            "1                4       31         11              0               0   \n",
            "2                5       15         19              0               0   \n",
            "3                6       31         35              0               0   \n",
            "4                1       31         18              0               0   \n",
            "\n",
            "   Afternoon  Prev_Week.1  Rep_Prev_Week.1  Rep_Prev_Entry.1  Evening  ...  \\\n",
            "0         14           13                0                 0       33  ...   \n",
            "1          3           21                0                 0       35  ...   \n",
            "2          9           19                0                 0       23  ...   \n",
            "3         21           20                0                 0       29  ...   \n",
            "4         31           30                0                 1       15  ...   \n",
            "\n",
            "   Prev_Week.3  Rep_Prev_Week.3  Rep_Prev_Entry.3  Year  Month  Day  \\\n",
            "0            7                0                 0  2018      8    1   \n",
            "1           11                0                 0  2018      8    2   \n",
            "2           19                0                 0  2018      8    3   \n",
            "3           35                0                 0  2018      8    4   \n",
            "4           18                1                 0  2018      8    6   \n",
            "\n",
            "   Prediction1  Prediction2  Prediction3  Prediction4  \n",
            "0         19.0         14.0         33.0          9.0  \n",
            "1         31.0          3.0         35.0         12.0  \n",
            "2         15.0          9.0         23.0         35.0  \n",
            "3         31.0         21.0         29.0         16.0  \n",
            "4         31.0         31.0         15.0         18.0  \n",
            "\n",
            "[5 rows x 24 columns]\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Display the count of missing values for each column\n",
        "print(\"Missing Values:\\n\", missing_values)\n",
        "\n",
        "# Identify missing values in target variables\n",
        "missing_values_targets = df[['Prediction1', 'Prediction2', 'Prediction3', 'Prediction4']].isnull().sum()\n",
        "print(\"Missing Values in Target Variables:\\n\", missing_values_targets)\n",
        "\n",
        "# Iterate through each row with missing values in target variables\n",
        "for index, row in df[df[['Prediction1', 'Prediction2', 'Prediction3', 'Prediction4']].isnull().any(axis=1)].iterrows():\n",
        "    # Fill missing values with the corresponding historical entry\n",
        "    df.at[index, 'Prediction1'] = df.at[index, 'Morning']\n",
        "    df.at[index, 'Prediction2'] = df.at[index, 'Afternoon']\n",
        "    df.at[index, 'Prediction3'] = df.at[index, 'Evening']\n",
        "    df.at[index, 'Prediction4'] = df.at[index, 'Night']\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5mRBmq7yClP",
        "outputId": "83caae8d-7ef8-498d-c5b9-655e8f45260b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (1127, 20)\n",
            "X_test shape: (282, 20)\n",
            "y_train shape: (1127, 4)\n",
            "y_test shape: (282, 4)\n"
          ]
        }
      ],
      "source": [
        "# Split the data into features (X) and target variables (y)\n",
        "X = df[['Day of the Week', 'Morning', 'Prev_Week', 'Rep_Prev_Week', 'Rep_Prev_Entry', 'Afternoon', 'Prev_Week.1', 'Rep_Prev_Week.1', 'Rep_Prev_Entry.1', 'Evening', 'Prev_Week.2', 'Rep_Prev_Week.2', 'Rep_Prev_Entry.2', 'Night', 'Prev_Week.3', 'Rep_Prev_Week.3', 'Rep_Prev_Entry.3', 'Year', 'Month', 'Day']]\n",
        "y = df[['Prediction1', 'Prediction2', 'Prediction3', 'Prediction4']]\n",
        "\n",
        "# Use an 80/20 split for training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Confirm the shapes of X_train, X_test, y_train, and y_test\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6oKQA3ZBP65",
        "outputId": "2d2d4563-8614-4423-ebb3-7c94240640e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values:\n",
            " Day of the Week     0\n",
            "Morning             0\n",
            "Prev_Week           0\n",
            "Rep_Prev_Week       0\n",
            "Rep_Prev_Entry      0\n",
            "Afternoon           0\n",
            "Prev_Week.1         0\n",
            "Rep_Prev_Week.1     0\n",
            "Rep_Prev_Entry.1    0\n",
            "Evening             0\n",
            "Prev_Week.2         0\n",
            "Rep_Prev_Week.2     0\n",
            "Rep_Prev_Entry.2    0\n",
            "Night               0\n",
            "Prev_Week.3         0\n",
            "Rep_Prev_Week.3     0\n",
            "Rep_Prev_Entry.3    0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "Prediction1         0\n",
            "Prediction2         0\n",
            "Prediction3         0\n",
            "Prediction4         0\n",
            "dtype: int64\n",
            "Missing Values in X_train:\n",
            " Day of the Week     0\n",
            "Morning             0\n",
            "Prev_Week           0\n",
            "Rep_Prev_Week       0\n",
            "Rep_Prev_Entry      0\n",
            "Afternoon           0\n",
            "Prev_Week.1         0\n",
            "Rep_Prev_Week.1     0\n",
            "Rep_Prev_Entry.1    0\n",
            "Evening             0\n",
            "Prev_Week.2         0\n",
            "Rep_Prev_Week.2     0\n",
            "Rep_Prev_Entry.2    0\n",
            "Night               0\n",
            "Prev_Week.3         0\n",
            "Rep_Prev_Week.3     0\n",
            "Rep_Prev_Entry.3    0\n",
            "Year                0\n",
            "Month               0\n",
            "Day                 0\n",
            "dtype: int64\n",
            "\n",
            "Missing Values in y_train:\n",
            " Prediction1    0\n",
            "Prediction2    0\n",
            "Prediction3    0\n",
            "Prediction4    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Display the count of missing values for each column\n",
        "print(\"Missing Values:\\n\", missing_values)\n",
        "\n",
        "# Display the count of missing values in the training sets\n",
        "print(\"Missing Values in X_train:\\n\", X_train.isnull().sum())\n",
        "print(\"\\nMissing Values in y_train:\\n\", y_train.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y_train shape:\", y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWYq5q7LJOp4",
        "outputId": "d9ecbb48-247b-45ff-f09f-94d548906287"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape: (1127, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UYjjn1kVXa1t"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # Import necessary libraries\n",
        "    from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "    from xgboost import XGBRegressor\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from sklearn.metrics import mean_squared_error, r2_score\n",
        "    import numpy as np\n",
        "except Exception as e:\n",
        "    print(f\"Error during library import: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Initialize individual models\n",
        "    rf_model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "    xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "    # Fit each individual model for Prediction1\n",
        "    rf_model.fit(X_train, y_train['Prediction1'])\n",
        "    xgb_model.fit(X_train, y_train['Prediction1'])\n",
        "\n",
        "    # Fit each individual model for Prediction2\n",
        "    rf_model.fit(X_train, y_train['Prediction2'])\n",
        "    xgb_model.fit(X_train, y_train['Prediction2'])\n",
        "\n",
        "    # Fit each individual model for Prediction3\n",
        "    rf_model.fit(X_train, y_train['Prediction3'])\n",
        "    xgb_model.fit(X_train, y_train['Prediction3'])\n",
        "\n",
        "    # Fit each individual model for Prediction4\n",
        "    rf_model.fit(X_train, y_train['Prediction4'])\n",
        "    xgb_model.fit(X_train, y_train['Prediction4'])\n",
        "except Exception as e:\n",
        "    print(f\"Error during model initialization and fitting: {e}\")\n"
      ],
      "metadata": {
        "id": "bKBHxUXvPzu3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Create a VotingRegressor with the specified models\n",
        "    ensemble_model = VotingRegressor(estimators=[\n",
        "        ('rf', rf_model),\n",
        "        ('xgb', xgb_model)\n",
        "    ])\n",
        "except Exception as e:\n",
        "    print(f\"Error during ensemble model creation: {e}\")\n"
      ],
      "metadata": {
        "id": "T34W4iDiQKEW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Use the individual models to create inputs for the ensemble model\n",
        "    rf_predictions = rf_model.predict(X_train)\n",
        "    xgb_predictions = xgb_model.predict(X_train)\n",
        "    ensemble_X_train = np.column_stack((rf_predictions, xgb_predictions))\n",
        "except Exception as e:\n",
        "    print(f\"Error during prediction and stacking: {e}\")\n"
      ],
      "metadata": {
        "id": "9unjbZ7cQvLA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Ensure y_train_ensemble has the same number of elements as X_train\n",
        "    # Flatten y_train to ensure consistency\n",
        "    y_train_ensemble = y_train[['Prediction1', 'Prediction2', 'Prediction3', 'Prediction4']].values.ravel()\n",
        "\n",
        "    # Check if the sizes match\n",
        "    if ensemble_X_train.shape[0] != len(y_train_ensemble):\n",
        "        # Handle the size mismatch (e.g., by truncating or padding)\n",
        "        min_size = min(ensemble_X_train.shape[0], len(y_train_ensemble))\n",
        "        ensemble_X_train = ensemble_X_train[:min_size, :]\n",
        "        y_train_ensemble = y_train_ensemble[:min_size]\n",
        "except Exception as e:\n",
        "    print(f\"Error during data preparation: {e}\")\n"
      ],
      "metadata": {
        "id": "RByO5eO6QziQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Fit the ensemble model\n",
        "    ensemble_model.fit(ensemble_X_train, y_train_ensemble)\n",
        "\n",
        "    print(\"Shape of ensemble_X_train:\", ensemble_X_train.shape)\n",
        "    print(\"Length of y_train_ensemble:\", len(y_train_ensemble))\n",
        "except Exception as e:\n",
        "    print(f\"Error during ensemble model fitting: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H591rKuVQ3mB",
        "outputId": "b155098a-dfae-45d7-f7ad-433073dcc086"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of ensemble_X_train: (1127, 2)\n",
            "Length of y_train_ensemble: 1127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Import KFold for cross-validation\n",
        "    from sklearn.model_selection import KFold\n",
        "except Exception as e:\n",
        "    print(f\"Error during KFold import: {e}\")\n"
      ],
      "metadata": {
        "id": "o0tawLt7Q7m1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    def evaluate_model(model, X, y, cv=5):\n",
        "        \"\"\"\n",
        "        Evaluate the performance of a predictive model.\n",
        "\n",
        "        Parameters:\n",
        "        - model: The predictive model to be evaluated.\n",
        "        - X: The input features for evaluation.\n",
        "        - y: The target variables for evaluation.\n",
        "        - cv: Number of cross-validation folds.\n",
        "\n",
        "        Returns:\n",
        "        A dictionary containing evaluation metrics.\n",
        "        \"\"\"\n",
        "        kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "\n",
        "        # Initialize evaluation metrics\n",
        "        mse_5fold = []\n",
        "        mse_10fold = []\n",
        "        r2_scores = []\n",
        "\n",
        "        # Loop through each target variable\n",
        "        for i in range(y.shape[1]):\n",
        "            # Initialize scores\n",
        "            mse_5fold_i = []\n",
        "            mse_10fold_i = []\n",
        "            r2_scores_i = []\n",
        "\n",
        "            # Perform cross-validation\n",
        "            for train_idx, test_idx in kf.split(X):\n",
        "                X_train_fold, X_test_fold = X[train_idx], X[test_idx]\n",
        "                y_train_fold, y_test_fold = y[train_idx, i], y[test_idx, i]\n",
        "\n",
        "                # Fit the model\n",
        "                model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "                # Predict on the test fold\n",
        "                y_pred_fold = model.predict(X_test_fold)\n",
        "\n",
        "                # Calculate MSE\n",
        "                mse_fold = mean_squared_error(y_test_fold, y_pred_fold)\n",
        "                if len(mse_5fold_i) < 5:\n",
        "                    mse_5fold_i.append(mse_fold)\n",
        "                mse_10fold_i.append(mse_fold)\n",
        "\n",
        "                # R-squared score\n",
        "                r2_fold = r2_score(y_test_fold, y_pred_fold)\n",
        "                r2_scores_i.append(r2_fold)\n",
        "\n",
        "            # Average scores over folds\n",
        "            mse_5fold.append(np.mean(mse_5fold_i))\n",
        "            mse_10fold.append(np.mean(mse_10fold_i))\n",
        "            r2_scores.append(np.mean(r2_scores_i))\n",
        "\n",
        "        return {\n",
        "            '5-Fold Cross-Validation MSE': mse_5fold,\n",
        "            '10-Fold Cross-Validation MSE': mse_10fold,\n",
        "            'R-squared Score': r2_scores\n",
        "        }\n",
        "except Exception as e:\n",
        "    print(f\"Error during model evaluation function definition: {e}\")\n"
      ],
      "metadata": {
        "id": "__B8-aEQQ_h7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'Prediction1', 'Prediction2', 'Prediction3', 'Prediction4' are your target variable names\n",
        "# and 'df' is your DataFrame\n",
        "\n",
        "# Step 1: Check data types of keys\n",
        "row_keys = ['Prediction1', 'Prediction2', 'Prediction3', 'Prediction4']\n",
        "row_keys_data_types = [type(key) for key in row_keys]\n",
        "print(\"Data types of keys:\", row_keys_data_types)\n",
        "\n",
        "# Step 2: Convert keys to int if needed\n",
        "try:\n",
        "    row_keys_as_int = [int(key[10:]) for key in row_keys]\n",
        "except ValueError as e:\n",
        "    print(f\"Error converting keys to int: {e}\")\n",
        "    # Handle the error as needed\n",
        "\n",
        "# Step 3: Check data type of the index\n",
        "try:\n",
        "    index_data_type = type(df.index[0])\n",
        "except IndexError as e:\n",
        "    print(f\"Error accessing index: {e}\")\n",
        "    # Handle the error as needed\n",
        "\n",
        "print(\"Data type of the index:\", index_data_type)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLX-QA-kpbh9",
        "outputId": "8327f2c9-a5b3-459a-9fc3-cddd13d683bd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types of keys: [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>]\n",
            "Data type of the index: <class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Check for missing or invalid values in the index\n",
        "try:\n",
        "    missing_values = df.index.isnull().sum()  # Check for NaN values\n",
        "    invalid_values = df.index[~df.index.isin(row_keys_as_int)]  # Check for values not in keys_as_int\n",
        "except Exception as e:\n",
        "    print(f\"Error checking index values: {e}\")\n",
        "    # Handle the error as needed\n",
        "\n",
        "# Step 5: Convert index values to integers\n",
        "try:\n",
        "    df.index = df.index.astype(int)\n",
        "except Exception as e:\n",
        "    print(f\"Error converting index values to integers: {e}\")\n",
        "    # Handle the error as needed\n",
        "\n",
        "print(\"Number of missing values in the index:\", missing_values)\n",
        "print(\"Invalid values in the index:\", invalid_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe6SFGSHrCTi",
        "outputId": "4e4cd0cf-5717-404b-b64b-61603169482b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of missing values in the index: 0\n",
            "Invalid values in the index: Index([   0,    5,    6,    7,    8,    9,   10,   11,   12,   13,\n",
            "       ...\n",
            "       1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408],\n",
            "      dtype='int64', length=1405)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Evaluate the ensemble model\n",
        "    ensemble_evaluation = evaluate_model(ensemble_model, ensemble_X_train, y_train.iloc[:, :2])\n",
        "\n",
        "    # Display the evaluation metrics\n",
        "    for metric, values in ensemble_evaluation.items():\n",
        "        print(f\"{metric}: {values}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during ensemble model evaluation: {e}\")\n",
        "\n",
        "    # Print specific rows in y_train using the problematic indices\n",
        "    if isinstance(e, tuple) and len(e) == 2 and isinstance(e[0], np.ndarray) and e[1] == 0:\n",
        "        problematic_indices = e[0]\n",
        "        problematic_rows = y_train.iloc[problematic_indices[0], :2]\n",
        "        print(\"Problematic Rows in y_train:\")\n",
        "        print(problematic_rows)\n",
        "\n",
        "    else:\n",
        "        print(\"Unable to retrieve problematic rows. Check the error type and message.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcV5HPTgRGch",
        "outputId": "e6a4dc26-36f6-4d21-a096-afec45e216c2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during ensemble model evaluation: (array([   0,    1,    2,    4,    5,    6,    7,    8,    9,   11,   13,\n",
            "         14,   15,   16,   17,   18,   19,   20,   21,   22,   24,   25,\n",
            "         26,   27,   28,   29,   32,   33,   34,   35,   36,   37,   38,\n",
            "         40,   41,   42,   43,   45,   46,   47,   48,   50,   52,   53,\n",
            "         55,   57,   60,   61,   62,   64,   65,   68,   69,   71,   72,\n",
            "         73,   74,   75,   77,   79,   80,   81,   82,   84,   85,   87,\n",
            "         89,   90,   91,   92,   93,   94,   95,   97,   98,   99,  102,\n",
            "        103,  104,  105,  106,  108,  110,  111,  112,  114,  115,  116,\n",
            "        117,  118,  119,  120,  121,  122,  123,  124,  125,  126,  127,\n",
            "        129,  130,  131,  132,  133,  134,  135,  137,  142,  143,  144,\n",
            "        145,  146,  147,  148,  149,  150,  151,  152,  153,  154,  155,\n",
            "        157,  159,  160,  161,  162,  163,  164,  165,  166,  167,  169,\n",
            "        170,  171,  172,  173,  175,  176,  177,  179,  180,  181,  182,\n",
            "        183,  184,  185,  186,  187,  188,  189,  190,  191,  193,  194,\n",
            "        195,  196,  197,  200,  201,  202,  203,  204,  205,  206,  207,\n",
            "        211,  212,  213,  214,  215,  216,  217,  219,  221,  222,  223,\n",
            "        224,  225,  226,  227,  228,  229,  230,  232,  233,  234,  235,\n",
            "        236,  237,  238,  239,  240,  241,  242,  245,  246,  248,  249,\n",
            "        250,  251,  252,  253,  254,  255,  256,  257,  258,  259,  260,\n",
            "        261,  262,  263,  264,  266,  267,  268,  269,  271,  272,  273,\n",
            "        274,  275,  276,  278,  279,  280,  281,  282,  283,  284,  285,\n",
            "        287,  288,  293,  295,  296,  297,  300,  301,  302,  303,  304,\n",
            "        305,  307,  308,  309,  310,  311,  312,  313,  314,  315,  316,\n",
            "        317,  320,  322,  323,  324,  325,  326,  329,  330,  331,  335,\n",
            "        337,  338,  339,  340,  341,  343,  344,  345,  347,  348,  349,\n",
            "        350,  353,  354,  356,  357,  358,  359,  360,  362,  364,  365,\n",
            "        366,  367,  368,  369,  370,  372,  373,  374,  375,  376,  378,\n",
            "        379,  380,  382,  383,  384,  385,  386,  387,  389,  390,  391,\n",
            "        392,  393,  395,  396,  397,  398,  399,  400,  401,  402,  403,\n",
            "        406,  407,  408,  409,  410,  412,  414,  415,  416,  417,  418,\n",
            "        419,  421,  422,  424,  426,  427,  430,  431,  432,  433,  434,\n",
            "        437,  438,  439,  440,  441,  443,  444,  446,  447,  448,  449,\n",
            "        450,  451,  452,  454,  455,  456,  459,  460,  461,  462,  463,\n",
            "        466,  467,  468,  469,  470,  471,  472,  473,  474,  475,  476,\n",
            "        477,  480,  483,  484,  485,  486,  487,  488,  489,  491,  492,\n",
            "        493,  494,  495,  496,  498,  499,  500,  502,  503,  504,  505,\n",
            "        506,  508,  509,  510,  511,  512,  513,  515,  516,  517,  518,\n",
            "        520,  521,  522,  524,  526,  528,  529,  530,  531,  532,  533,\n",
            "        534,  535,  537,  539,  540,  544,  545,  546,  547,  549,  550,\n",
            "        552,  553,  554,  555,  556,  558,  559,  560,  561,  562,  563,\n",
            "        564,  565,  566,  567,  568,  569,  571,  572,  573,  574,  575,\n",
            "        576,  577,  578,  579,  580,  581,  583,  584,  586,  587,  589,\n",
            "        592,  593,  594,  596,  597,  599,  600,  601,  602,  603,  604,\n",
            "        605,  606,  607,  608,  609,  610,  611,  612,  614,  615,  616,\n",
            "        617,  618,  619,  620,  621,  622,  623,  624,  625,  627,  628,\n",
            "        631,  632,  633,  635,  637,  638,  639,  640,  641,  642,  644,\n",
            "        645,  646,  647,  648,  650,  651,  652,  653,  654,  655,  656,\n",
            "        657,  658,  659,  660,  661,  662,  663,  664,  665,  667,  668,\n",
            "        669,  670,  671,  672,  673,  674,  675,  676,  677,  678,  679,\n",
            "        680,  681,  682,  683,  684,  685,  686,  687,  688,  689,  690,\n",
            "        691,  692,  694,  695,  697,  698,  699,  700,  702,  704,  705,\n",
            "        706,  707,  708,  709,  710,  711,  712,  715,  717,  718,  719,\n",
            "        721,  722,  723,  725,  726,  727,  728,  729,  731,  732,  733,\n",
            "        734,  735,  736,  737,  740,  742,  744,  745,  746,  747,  748,\n",
            "        749,  751,  752,  753,  754,  756,  757,  759,  760,  762,  763,\n",
            "        764,  766,  767,  769,  770,  771,  772,  774,  775,  776,  778,\n",
            "        779,  780,  781,  783,  785,  786,  787,  788,  790,  791,  792,\n",
            "        794,  795,  797,  798,  799,  800,  801,  803,  804,  805,  806,\n",
            "        807,  810,  811,  814,  815,  816,  817,  818,  819,  820,  821,\n",
            "        822,  823,  826,  827,  829,  830,  831,  832,  833,  834,  835,\n",
            "        836,  838,  839,  840,  841,  846,  847,  848,  849,  850,  851,\n",
            "        852,  853,  854,  855,  856,  857,  858,  859,  860,  861,  862,\n",
            "        863,  866,  867,  868,  869,  870,  871,  872,  873,  874,  875,\n",
            "        876,  877,  878,  879,  880,  881,  882,  883,  884,  885,  886,\n",
            "        887,  888,  889,  890,  891,  892,  893,  894,  895,  896,  897,\n",
            "        898,  899,  900,  901,  902,  903,  904,  906,  907,  908,  909,\n",
            "        910,  911,  912,  913,  914,  916,  918,  919,  920,  922,  924,\n",
            "        925,  926,  927,  928,  929,  930,  931,  932,  933,  934,  935,\n",
            "        936,  937,  938,  939,  940,  941,  943,  944,  945,  946,  947,\n",
            "        948,  949,  951,  952,  955,  956,  957,  959,  960,  961,  963,\n",
            "        964,  965,  967,  968,  969,  970,  971,  972,  974,  975,  976,\n",
            "        977,  978,  979,  980,  982,  983,  984,  985,  986,  987,  990,\n",
            "        991,  992,  993,  995,  996,  997,  998,  999, 1000, 1002, 1004,\n",
            "       1007, 1009, 1010, 1013, 1014, 1015, 1016, 1017, 1020, 1021, 1022,\n",
            "       1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033,\n",
            "       1034, 1036, 1037, 1038, 1040, 1041, 1042, 1044, 1045, 1046, 1048,\n",
            "       1049, 1050, 1052, 1053, 1054, 1055, 1057, 1058, 1059, 1060, 1061,\n",
            "       1062, 1064, 1065, 1066, 1068, 1069, 1070, 1071, 1072, 1073, 1074,\n",
            "       1075, 1076, 1078, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087,\n",
            "       1088, 1089, 1091, 1092, 1095, 1096, 1097, 1099, 1100, 1101, 1102,\n",
            "       1103, 1104, 1105, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114,\n",
            "       1115, 1117, 1118, 1120, 1121, 1122, 1123, 1124, 1125, 1126]), 0)\n",
            "Unable to retrieve problematic rows. Check the error type and message.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Step 1: Initial Training with warm_start\n",
        "    # Train the RandomForestRegressor with a small number of trees using placeholder values\n",
        "    # Adjust the number of trees and other hyperparameters as needed\n",
        "    rf_model.fit(X_train, y_train.iloc[:, 0])\n",
        "\n",
        "    # Evaluate its performance on the test set\n",
        "    y_pred_initial = rf_model.predict(X_test.iloc[:, :20])  # Assuming the first target variable is Prediction1\n",
        "    mse_initial = mean_squared_error(y_test.iloc[:, 0], y_pred_initial)\n",
        "    print(\"Mean Squared Error after Initial Training:\", mse_initial)\n",
        "except Exception as e:\n",
        "    print(f\"Error during initial training and evaluation: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syVSU2AaRL1n",
        "outputId": "eb851050-9b23-41b0-ced4-b984e9962f82"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error after Initial Training: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Step 2: Transition to Two-Step Approach\n",
        "    # Randomize the placeholder values for each target variable\n",
        "    y_train_randomized = y_train.apply(np.random.permutation, axis=0)\n",
        "\n",
        "    # Train the models on the randomized values\n",
        "    rf_model.fit(X_train, y_train_randomized.iloc[:, 0])\n",
        "    xgb_model.fit(X_train, y_train_randomized.iloc[:, 1])\n",
        "\n",
        "    # Evaluate their performance on the test set\n",
        "    y_pred_rf_randomized = rf_model.predict(X_test.iloc[:, :20])  # Assuming the first target variable is Prediction1\n",
        "    y_pred_xgb_randomized = xgb_model.predict(X_test)\n",
        "    mse_rf_randomized = mean_squared_error(y_test.iloc[:, 0], y_pred_rf_randomized)\n",
        "    mse_xgb_randomized = mean_squared_error(y_test.iloc[:, 1], y_pred_xgb_randomized)\n",
        "    print(\"Mean Squared Error after Training with Randomized Placeholders (RF):\", mse_rf_randomized)\n",
        "    print(\"Mean Squared Error after Training with Randomized Placeholders (XGB):\", mse_xgb_randomized)\n",
        "except Exception as e:\n",
        "    print(f\"Error during training with randomized placeholders and evaluation: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viGKrIXaRV51",
        "outputId": "4d85ae0c-71ca-42f8-8d31-c38d35f2f2ec"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error after Training with Randomized Placeholders (RF): 115.64086028368794\n",
            "Mean Squared Error after Training with Randomized Placeholders (XGB): 146.46224526226553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Step 3: Fine-Tuning with Actual Target Variables\n",
        "    # Fine-tune the models using the actual values\n",
        "    rf_model.fit(X_train, y_train.iloc[:, 0])\n",
        "    xgb_model.fit(X_train, y_train.iloc[:, 1])\n",
        "\n",
        "    # Evaluate their final performance on the test set\n",
        "    y_pred_rf_final = rf_model.predict(X_test.iloc[:, :20])  # Assuming the first target variable is Prediction1\n",
        "    y_pred_xgb_final = xgb_model.predict(X_test)\n",
        "    mse_rf_final = mean_squared_error(y_test.iloc[:, 0], y_pred_rf_final)\n",
        "    mse_xgb_final = mean_squared_error(y_test.iloc[:, 1], y_pred_xgb_final)\n",
        "    print(\"Mean Squared Error after Fine-Tuning with Actual Target Variables (RF):\", mse_rf_final)\n",
        "    print(\"Mean Squared Error after Fine-Tuning with Actual Target Variables (XGB):\", mse_xgb_final)\n",
        "except Exception as e:\n",
        "    print(f\"Error during fine-tuning and final evaluation: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYQVDJA0Ra5X",
        "outputId": "a135a52b-76ce-41ff-8f3e-85532575374f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error after Fine-Tuning with Actual Target Variables (RF): 0.0\n",
            "Mean Squared Error after Fine-Tuning with Actual Target Variables (XGB): 1.2040056856947442e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8thy2j3kRfcK",
        "outputId": "318a3482-39fc-4832-c3d2-9c9a6f593702"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Prediction1  Prediction2  Prediction3  Prediction4\n",
            "1034         34.0         26.0         12.0         29.0\n",
            "579           8.0         22.0          9.0         11.0\n",
            "1138         35.0          2.0         12.0         18.0\n",
            "48            8.0         24.0          3.0         24.0\n",
            "155          19.0         26.0         22.0         28.0\n",
            "...           ...          ...          ...          ...\n",
            "1095         11.0         15.0          6.0         32.0\n",
            "1130          6.0         21.0         18.0         20.0\n",
            "1294         16.0         20.0          2.0         31.0\n",
            "860          32.0         11.0          7.0         30.0\n",
            "1126         29.0         22.0         35.0          7.0\n",
            "\n",
            "[1127 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'Prediction1', 'Prediction2', 'Prediction3', 'Prediction4' are your target variable names\n",
        "# and 'df' is your DataFrame\n",
        "\n",
        "# Step 1: Check data types of keys\n",
        "row_keys = ['Prediction1', 'Prediction2', 'Prediction3', 'Prediction4']\n",
        "row_keys_data_types = [type(key) for key in row_keys]\n",
        "print(\"Data types of keys:\", row_keys_data_types)\n",
        "\n",
        "# Step 2: Check data type of the index\n",
        "index_data_type = type(df.index[0])\n",
        "print(\"Data type of the index:\", index_data_type)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wakaDGanf8nA",
        "outputId": "eb19e116-09d7-4640-8e06-f1bce48da2d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data types of keys: [<class 'str'>, <class 'str'>, <class 'str'>, <class 'str'>]\n",
            "Data type of the index: <class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ncLrqNGpewW7"
      },
      "outputs": [],
      "source": [
        "# Define a function for model evaluations\n",
        "def evaluate_model(model, X, y, cv=5):\n",
        "    # Ensure the model is fitted\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Initialize evaluation metrics\n",
        "    mse_5fold = []\n",
        "    mse_10fold = []\n",
        "    r2_scores = []\n",
        "\n",
        "    # Loop through each target variable\n",
        "    for i in range(y.shape[1]):\n",
        "        # 5-fold cross-validation\n",
        "        scores_5fold = cross_val_score(model, X, y.iloc[:, i], cv=cv, scoring='neg_mean_squared_error')\n",
        "        mse_5fold.append(-scores_5fold.mean())\n",
        "\n",
        "        # 10-fold cross-validation\n",
        "        scores_10fold = cross_val_score(model, X, y.iloc[:, i], cv=10, scoring='neg_mean_squared_error')\n",
        "        mse_10fold.append(-scores_10fold.mean())\n",
        "\n",
        "        # Ensure the model is fitted\n",
        "        model.fit(X, y.iloc[:, i])\n",
        "\n",
        "        # R-squared score\n",
        "        y_pred = model.predict(X)\n",
        "        r2 = r2_score(y.iloc[:, i], y_pred)\n",
        "        r2_scores.append(r2)\n",
        "\n",
        "    return {\n",
        "        '5-Fold Cross-Validation MSE': mse_5fold,\n",
        "        '10-Fold Cross-Validation MSE': mse_10fold,\n",
        "        'R-squared Score': r2_scores\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "UBppTfwRO5zi",
        "outputId": "d161a8b6-5923-4d6c-b382-80325dc687eb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-43a8828e8995>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the ensemble model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mensemble_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Evaluate the ensemble model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mensemble_evaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_voting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \"\"\"\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1245\u001b[0m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (1127, 4) instead."
          ]
        }
      ],
      "source": [
        "# Fit the ensemble model\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "ensemble_evaluation = evaluate_model(ensemble_model, X_train, y_train)\n",
        "\n",
        "# Display the evaluation metrics\n",
        "for metric, values in ensemble_evaluation.items():\n",
        "    print(f\"{metric}: {values}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Fp8fYgYWRFM"
      },
      "outputs": [],
      "source": [
        "# Evaluate the ensemble model\n",
        "evaluation_results = evaluate_model(ensemble_model, X_train, y_train)\n",
        "\n",
        "# Access the results from the evaluation\n",
        "mse_5fold = evaluation_results['5-Fold Cross-Validation MSE']\n",
        "mse_10fold = evaluation_results['10-Fold Cross-Validation MSE']\n",
        "r2_scores = evaluation_results['R-squared Score']\n",
        "\n",
        "# Display the results\n",
        "for i in range(len(mse_5fold)):\n",
        "    print(f\"Target Variable {i + 1}:\")\n",
        "    print(f\"5-Fold Cross-Validation MSE: {mse_5fold[i]}\")\n",
        "    print(f\"10-Fold Cross-Validation MSE: {mse_10fold[i]}\")\n",
        "    print(f\"R-squared Score: {r2_scores[i]}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of the predictions array\n",
        "print(\"Shape of predictions array:\", ensemble_model.predict(X_train).shape)\n"
      ],
      "metadata": {
        "id": "0w9Vzqvs7UnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1.1: Analyze Predictions and Visualize Results\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def analyze_predictions(model, X, y):\n",
        "    predictions = model.predict(X)\n",
        "\n",
        "    # Check if predictions are 1-dimensional\n",
        "    if len(predictions.shape) == 1:\n",
        "        predictions = predictions.reshape(-1, 1)\n",
        "\n",
        "    print(\"Shapes - y:\", y.shape, \"predictions:\", predictions.shape)  # Add this line for debugging\n",
        "\n",
        "    # Create subplots for each target variable\n",
        "    n_targets = y.shape[1]\n",
        "    n_subplots = min(n_targets * 2, 8)  # Limit to 8 subplots for better visualization\n",
        "    fig, axes = plt.subplots(nrows=n_subplots // 2, ncols=2, figsize=(15, 5 * (n_subplots // 2)))\n",
        "\n",
        "    # Flatten the axes array to handle the case of one target variable\n",
        "    axes = np.array(axes).flatten()\n",
        "\n",
        "    # Loop through each target variable\n",
        "    for i in range(n_targets):\n",
        "        # Check if there are available subplots\n",
        "        if i * 2 < n_subplots:\n",
        "            # Plot predicted vs. actual values\n",
        "            axes[i * 2].scatter(y.iloc[:, i], predictions[:, i], alpha=0.5)\n",
        "            axes[i * 2].set_title(f'Target Variable {i + 1}: Predicted vs. Actual')\n",
        "            axes[i * 2].set_xlabel('Actual Values')\n",
        "            axes[i * 2].set_ylabel('Predicted Values')\n",
        "\n",
        "        # Check if there are available subplots for residuals\n",
        "        if i * 2 + 1 < n_subplots:\n",
        "            # Plot residuals\n",
        "            residuals = y.iloc[:, i] - predictions[:, i]\n",
        "            axes[i * 2 + 1].scatter(predictions[:, i], residuals, alpha=0.5)\n",
        "            axes[i * 2 + 1].set_title(f'Target Variable {i + 1}: Residuals Plot')\n",
        "            axes[i * 2 + 1].set_xlabel('Predicted Values')\n",
        "            axes[i * 2 + 1].set_ylabel('Residuals')\n",
        "            axes[i * 2 + 1].axhline(y=0, color='red', linestyle='--')  # Add horizontal line at y=0\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function with your ensemble model and training data\n",
        "analyze_predictions(ensemble_model, X_train, y_train)\n"
      ],
      "metadata": {
        "id": "_dqBhRkAnp3u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4RYyqMewfwXr3wMa9IO+L",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}