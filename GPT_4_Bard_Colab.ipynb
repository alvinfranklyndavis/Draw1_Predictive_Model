{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrZEwNqMa9rUqkj1xh9h2F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvinfranklyndavis/Project2023_v3/blob/main/GPT_4_Bard_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1.1: Package Installation\n",
        "\n",
        "# Upgrade pip and install required packages\n",
        "!pip install -U --upgrade-strategy eager pip\n",
        "!pip install -U --upgrade-strategy eager pandas gdown numpy matplotlib scikit-learn xgboost shap\n",
        "!pip install -U scikit-learn\n",
        "!pip install -U imbalanced-learn\n",
        "!pip install black  # Install Black for code formatting\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plnc-ffhAUCk",
        "outputId": "09d19465-80d1-4670-b754-2eadc484095e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.44.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (3.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.2.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: black in /usr/local/lib/python3.10/dist-packages (23.12.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black) (1.0.0)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from black) (23.2)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black) (4.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black) (4.5.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 1.2: Import Libraries and Set Up Logging\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import logging\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import KNNImputer\n",
        "import shap\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n"
      ],
      "metadata": {
        "id": "fP_Q74gUBGQi"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2.1: Setup and File Path Definitions\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the directory for datasets in Google Drive\n",
        "drive_dataset_directory = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/'\n",
        "\n",
        "# Define the path to the comprehensive CSV files\n",
        "csv_filename_train_test = '1_Model_Train_Test_Data.csv'\n",
        "csv_filename_unseen = '2_Model_Unseen_Data.csv'\n",
        "\n",
        "# File paths\n",
        "drive_csv_path_train_test = os.path.join(drive_dataset_directory, csv_filename_train_test)\n",
        "drive_csv_path_unseen = os.path.join(drive_dataset_directory, csv_filename_unseen)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJo9WkRgmk5M",
        "outputId": "922df411-8c65-4885-84bc-cea2618e72ca"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2.2: Loading the Datasets\n",
        "\n",
        "# Load the datasets\n",
        "train_test_data = pd.read_csv(drive_csv_path_train_test)\n",
        "unseen_data = pd.read_csv(drive_csv_path_unseen)\n",
        "logger.info(\"Datasets loaded successfully from Google Drive.\")\n"
      ],
      "metadata": {
        "id": "-cUBoLuanG-r"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2.3: Data Preprocessing\n",
        "\n",
        "# Apply preprocessing to both datasets\n",
        "train_test_data = preprocess_data(train_test_data)\n",
        "unseen_data = preprocess_data(unseen_data)\n",
        "logger.info(\"Preprocessing applied to both training/testing and unseen datasets.\")\n"
      ],
      "metadata": {
        "id": "JwQT55q4nY5b"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2.4: Saving Preprocessed Data\n",
        "\n",
        "# Define the paths to save the preprocessed data\n",
        "preprocessed_train_test_path = os.path.join(drive_dataset_directory, '3_train_test_features.csv')\n",
        "preprocessed_train_test_target_path = os.path.join(drive_dataset_directory, '4_train_test_target.csv')\n",
        "preprocessed_unseen_features_path = os.path.join(drive_dataset_directory, '5_unseen_features.csv')\n",
        "preprocessed_unseen_target_path = os.path.join(drive_dataset_directory, '6_unseen_target.csv')\n",
        "\n",
        "# Save preprocessed training/testing data\n",
        "train_test_data.to_csv(preprocessed_train_test_path, index=False)\n",
        "logger.info(\"Preprocessed training/testing features saved to Google Drive.\")\n",
        "\n",
        "# Assuming 'Prediction1' is the target for training/testing data\n",
        "train_test_target = train_test_data[['Prediction1']]\n",
        "train_test_data.drop(columns=['Prediction1'], inplace=True)\n",
        "train_test_target.to_csv(preprocessed_train_test_target_path, index=False)\n",
        "logger.info(\"Preprocessed training/testing target saved to Google Drive.\")\n",
        "\n",
        "# Save preprocessed unseen data\n",
        "# Assuming we split features and target as we did with train_test_data\n",
        "unseen_target = unseen_data[['Prediction1']]\n",
        "unseen_data.drop(columns=['Prediction1'], inplace=True)\n",
        "unseen_data.to_csv(preprocessed_unseen_features_path, index=False)\n",
        "unseen_target.to_csv(preprocessed_unseen_target_path, index=False)\n",
        "logger.info(\"Preprocessed unseen features and target saved to Google Drive.\")\n",
        "\n",
        "# Print the first few rows of the preprocessed training/testing data for visual confirmation\n",
        "print(\"First few rows of the preprocessed training/testing features:\")\n",
        "print(train_test_data.head())\n",
        "print(\"\\nFirst few rows of the preprocessed training/testing target:\")\n",
        "print(train_test_target.head())\n",
        "\n",
        "# Print the first few rows of the preprocessed unseen data for visual confirmation\n",
        "print(\"\\nFirst few rows of the preprocessed unseen features:\")\n",
        "print(unseen_data.head())\n",
        "print(\"\\nFirst few rows of the preprocessed unseen target:\")\n",
        "print(unseen_target.head())\n",
        "\n",
        "# Optionally, print the shape and column names for further confirmation\n",
        "print(\"\\nShape of the training/testing features DataFrame:\", train_test_data.shape)\n",
        "print(\"Column names:\", train_test_data.columns)\n",
        "print(\"Shape of the training/testing target DataFrame:\", train_test_target.shape)\n",
        "print(\"Column names:\", train_test_target.columns)\n",
        "print(\"Shape of the unseen features DataFrame:\", unseen_data.shape)\n",
        "print(\"Column names:\", unseen_data.columns)\n",
        "print(\"Shape of the unseen target DataFrame:\", unseen_target.shape)\n",
        "print(\"Column names:\", unseen_target.columns)\n",
        "\n",
        "# [Continue with further data processing...]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2J6MXxcnlH5",
        "outputId": "3da65f3d-e422-45ff-bf7d-cdc44e3ac4d4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the preprocessed training/testing features:\n",
            "        Date  Row Number Data_Type  Morning  Prev_Week  Rep_Prev_Week  \\\n",
            "0 2018-08-02           2  Training       31         11              0   \n",
            "1 2018-08-03           3  Training       15         19              0   \n",
            "2 2018-08-04           4  Training       31         35              0   \n",
            "3 2018-08-06           5  Training       31         18              0   \n",
            "4 2018-08-07           6  Training       21         13              0   \n",
            "\n",
            "   Prev_Entry  Rep_Prev_Entry  Mov_Avg_Mor  Afternoon  ...  Rep_Prev_Week.3  \\\n",
            "0           9               0         25.0          3  ...                0   \n",
            "1          12               0         23.0          9  ...                0   \n",
            "2          35               0         23.0         21  ...                0   \n",
            "3          16               0         31.0         31  ...                1   \n",
            "4          18               0         26.0         17  ...                0   \n",
            "\n",
            "   Prev_Entry.3  Rep_Prev_Entry.3  Mov_Avg_Nig  Year  Month  Day  \\\n",
            "0            35                 0         10.5  2018      8    2   \n",
            "1            23                 0         23.5  2018      8    3   \n",
            "2            29                 0         25.5  2018      8    4   \n",
            "3            15                 0         17.0  2018      8    6   \n",
            "4             8                 0         23.0  2018      8    7   \n",
            "\n",
            "   Prev_Morning  Prev_Afternoon  Prev_Evening  \n",
            "0          19.0            14.0          33.0  \n",
            "1          31.0             3.0          35.0  \n",
            "2          15.0             9.0          23.0  \n",
            "3          31.0            21.0          29.0  \n",
            "4          31.0            31.0          15.0  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "\n",
            "First few rows of the preprocessed training/testing target:\n",
            "   Prediction1\n",
            "0           31\n",
            "1           15\n",
            "2           31\n",
            "3           31\n",
            "4           21\n",
            "\n",
            "First few rows of the preprocessed unseen features:\n",
            "        Date  Row Number Data_Type  Morning  Prev_Week  Rep_Prev_Week  \\\n",
            "0 2023-08-02        1411    Unseen      NaN         33           22.5   \n",
            "1 2023-08-03        1412    Unseen      NaN         27           15.0   \n",
            "2 2023-08-04        1413    Unseen      NaN         20           15.5   \n",
            "3 2023-08-05        1414    Unseen      NaN         29           21.5   \n",
            "4 2023-08-07        1415    Unseen      NaN         25           15.0   \n",
            "\n",
            "   Prev_Entry  2WeeksM  Mov_Avg_Mor  Afternoon  ...  Rep_Prev_Week.3  \\\n",
            "0          18     12.0          NaN         31  ...              NaN   \n",
            "1          28      3.0          NaN          5  ...              NaN   \n",
            "2           2     11.0          NaN         28  ...              NaN   \n",
            "3          12     14.0          NaN         35  ...              NaN   \n",
            "4          11      5.0          NaN          2  ...              NaN   \n",
            "\n",
            "   Prev_Entry.3  2WeeksN  Mov_Avg_Nig  Year  Month  Day  Prev_Morning  \\\n",
            "0             7      5.0         23.0  2023      8    2          18.0   \n",
            "1             2      6.0         15.0  2023      8    3          18.0   \n",
            "2            22      7.0          7.0  2023      8    4          18.0   \n",
            "3            31     18.0         11.5  2023      8    5          18.0   \n",
            "4            23     22.0         18.0  2023      8    7          18.0   \n",
            "\n",
            "   Prev_Afternoon  Prev_Evening  \n",
            "0            20.0          26.0  \n",
            "1            31.0           7.0  \n",
            "2             5.0           2.0  \n",
            "3            28.0          22.0  \n",
            "4            35.0          31.0  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "\n",
            "First few rows of the preprocessed unseen target:\n",
            "   Prediction1\n",
            "0          NaN\n",
            "1          NaN\n",
            "2          NaN\n",
            "3          NaN\n",
            "4          NaN\n",
            "\n",
            "Shape of the training/testing features DataFrame: (1407, 33)\n",
            "Column names: Index(['Date', 'Row Number', 'Data_Type', 'Morning', 'Prev_Week',\n",
            "       'Rep_Prev_Week', 'Prev_Entry', 'Rep_Prev_Entry', 'Mov_Avg_Mor',\n",
            "       'Afternoon', 'Prev_Week.1', 'Rep_Prev_Week.1', 'Prev_Entry.1',\n",
            "       'Rep_Prev_Entry.1', 'Mov_Avg_Aft', 'Evening', 'Prev_Week.2',\n",
            "       'Rep_Prev_Week.2', 'Prev_Entry.2', 'Rep_Prev_Entry.2', 'Mov_Avg_Eve',\n",
            "       'Night', 'Prev_Week.3', 'Rep_Prev_Week.3', 'Prev_Entry.3',\n",
            "       'Rep_Prev_Entry.3', 'Mov_Avg_Nig', 'Year', 'Month', 'Day',\n",
            "       'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening'],\n",
            "      dtype='object')\n",
            "Shape of the training/testing target DataFrame: (1407, 1)\n",
            "Column names: Index(['Prediction1'], dtype='object')\n",
            "Shape of the unseen features DataFrame: (5, 33)\n",
            "Column names: Index(['Date', 'Row Number', 'Data_Type', 'Morning', 'Prev_Week',\n",
            "       'Rep_Prev_Week', 'Prev_Entry', '2WeeksM', 'Mov_Avg_Mor', 'Afternoon',\n",
            "       'Prev_Week.1', 'Rep_Prev_Week.1', 'Prev_Entry.1', '2WeeksA',\n",
            "       'Mov_Avg_Aft', 'Evening', 'Prev_Week.2', 'Rep_Prev_Week.2',\n",
            "       'Prev_Entry.2', '2WeeksE', 'Mov_Avg_Eve', 'Night', 'Prev_Week.3',\n",
            "       'Rep_Prev_Week.3', 'Prev_Entry.3', '2WeeksN', 'Mov_Avg_Nig', 'Year',\n",
            "       'Month', 'Day', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening'],\n",
            "      dtype='object')\n",
            "Shape of the unseen target DataFrame: (5, 1)\n",
            "Column names: Index(['Prediction1'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3.1: Finalizing Features for Prediction1 and Saving Processed Data\n",
        "\n",
        "import logging\n",
        "import pandas as pd\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.info(\"Finalizing features for model input and saving processed data\")\n",
        "\n",
        "def finalize_and_save_features(data, filename_suffix):\n",
        "    logger.info(f\"Finalizing features for model input and saving processed data for {filename_suffix}\")\n",
        "\n",
        "    selected_columns = ['Year', 'Month', 'Day', 'Prev_Week', 'Prev_Entry', 'Mov_Avg_Mor', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening']\n",
        "    X = data[selected_columns]\n",
        "\n",
        "    # Save the processed data features to CSV\n",
        "    X.to_csv(f'/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/{filename_suffix}_features.csv', index=False)\n",
        "    logger.info(f\"Processed data features for {filename_suffix} saved to Google Drive.\")\n",
        "\n",
        "    # Print the first few rows for verification\n",
        "    print(f\"First few rows of {filename_suffix} features:\")\n",
        "    print(X.head())\n",
        "\n",
        "# Apply to training/testing data\n",
        "finalize_and_save_features(train_test_data, 'train_test')\n",
        "\n",
        "# Apply to unseen data\n",
        "finalize_and_save_features(unseen_data, 'unseen')\n"
      ],
      "metadata": {
        "id": "GGRPjzS2ILM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b36c905-825a-4fdc-b39b-2cb4c84c9cda"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of train_test features:\n",
            "   Year  Month  Day  Prev_Week  Prev_Entry  Mov_Avg_Mor  Prev_Morning  \\\n",
            "0  2018      8    2         11           9         25.0          19.0   \n",
            "1  2018      8    3         19          12         23.0          31.0   \n",
            "2  2018      8    4         35          35         23.0          15.0   \n",
            "3  2018      8    6         18          16         31.0          31.0   \n",
            "4  2018      8    7         13          18         26.0          31.0   \n",
            "\n",
            "   Prev_Afternoon  Prev_Evening  \n",
            "0            14.0          33.0  \n",
            "1             3.0          35.0  \n",
            "2             9.0          23.0  \n",
            "3            21.0          29.0  \n",
            "4            31.0          15.0  \n",
            "First few rows of unseen features:\n",
            "   Year  Month  Day  Prev_Week  Prev_Entry  Mov_Avg_Mor  Prev_Morning  \\\n",
            "0  2023      8    2         33          18          NaN          18.0   \n",
            "1  2023      8    3         27          28          NaN          18.0   \n",
            "2  2023      8    4         20           2          NaN          18.0   \n",
            "3  2023      8    5         29          12          NaN          18.0   \n",
            "4  2023      8    7         25          11          NaN          18.0   \n",
            "\n",
            "   Prev_Afternoon  Prev_Evening  \n",
            "0            20.0          26.0  \n",
            "1            31.0           7.0  \n",
            "2             5.0           2.0  \n",
            "3            28.0          22.0  \n",
            "4            35.0          31.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3.2: Additional Data Insights for CSVs\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.info(\"Exploring additional data insights for CSVs...\")\n",
        "\n",
        "# Read the CSV files\n",
        "train_test_features = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/train_test_features.csv')\n",
        "train_test_target = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/train_test_target.csv')\n",
        "unseen_features = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/unseen_features.csv')\n",
        "unseen_target = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/unseen_target.csv')\n",
        "\n",
        "# Function to print data insights\n",
        "def print_data_insights(df, df_name):\n",
        "    print(f\"Data Insights for {df_name}:\\n\")\n",
        "    print(\"Missing values in each column:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    print(\"\\nPercentage of missing values in each column:\")\n",
        "    print(df.isnull().mean() * 100)\n",
        "\n",
        "    print(\"\\nSummary statistics:\")\n",
        "    print(df.describe())\n",
        "\n",
        "    print(\"\\nFirst few rows of data:\")\n",
        "    print(df.head())\n",
        "\n",
        "    print(\"\\n-----------------------------------------\\n\")\n",
        "\n",
        "# Print insights for each DataFrame\n",
        "print_data_insights(train_test_features, \"Train/Test Features\")\n",
        "print_data_insights(train_test_target, \"Train/Test Target\")\n",
        "print_data_insights(unseen_features, \"Unseen Features\")\n",
        "print_data_insights(unseen_target, \"Unseen Target\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4mPofrAFRsH",
        "outputId": "ffba4bc3-1fb1-49ca-8380-c092a675d1aa"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Insights for Train/Test Features:\n",
            "\n",
            "Missing values in each column:\n",
            "Year              0\n",
            "Month             0\n",
            "Day               0\n",
            "Prev_Week         0\n",
            "Prev_Entry        0\n",
            "Mov_Avg_Mor       0\n",
            "Prev_Morning      0\n",
            "Prev_Afternoon    0\n",
            "Prev_Evening      0\n",
            "dtype: int64\n",
            "\n",
            "Percentage of missing values in each column:\n",
            "Year              0.0\n",
            "Month             0.0\n",
            "Day               0.0\n",
            "Prev_Week         0.0\n",
            "Prev_Entry        0.0\n",
            "Mov_Avg_Mor       0.0\n",
            "Prev_Morning      0.0\n",
            "Prev_Afternoon    0.0\n",
            "Prev_Evening      0.0\n",
            "dtype: float64\n",
            "\n",
            "Summary statistics:\n",
            "              Year        Month          Day    Prev_Week   Prev_Entry  \\\n",
            "count  1407.000000  1407.000000  1407.000000  1407.000000  1407.000000   \n",
            "mean   2020.577825     6.629709    15.626866    18.212509    18.130064   \n",
            "std       1.556254     3.565689     8.752854    10.568730    10.368159   \n",
            "min    2018.000000     1.000000     1.000000     0.000000     1.000000   \n",
            "25%    2019.000000     3.000000     8.000000     9.000000     9.000000   \n",
            "50%    2021.000000     7.000000    16.000000    18.000000    18.000000   \n",
            "75%    2022.000000    10.000000    23.000000    27.000000    27.000000   \n",
            "max    2023.000000    12.000000    31.000000    36.000000    36.000000   \n",
            "\n",
            "       Mov_Avg_Mor  Prev_Morning  Prev_Afternoon  Prev_Evening  \n",
            "count  1407.000000   1407.000000     1407.000000   1407.000000  \n",
            "mean     18.773632     18.770434       18.623312     18.528785  \n",
            "std       7.076781     10.277406       10.360101     10.240097  \n",
            "min       1.500000      1.000000        1.000000      1.000000  \n",
            "25%      13.500000     10.000000        9.000000     10.000000  \n",
            "50%      19.000000     19.000000       19.000000     19.000000  \n",
            "75%      24.000000     28.000000       27.000000     27.000000  \n",
            "max      35.500000     36.000000       36.000000     36.000000  \n",
            "\n",
            "First few rows of data:\n",
            "   Year  Month  Day  Prev_Week  Prev_Entry  Mov_Avg_Mor  Prev_Morning  \\\n",
            "0  2018      8    2         11           9         25.0          19.0   \n",
            "1  2018      8    3         19          12         23.0          31.0   \n",
            "2  2018      8    4         35          35         23.0          15.0   \n",
            "3  2018      8    6         18          16         31.0          31.0   \n",
            "4  2018      8    7         13          18         26.0          31.0   \n",
            "\n",
            "   Prev_Afternoon  Prev_Evening  \n",
            "0            14.0          33.0  \n",
            "1             3.0          35.0  \n",
            "2             9.0          23.0  \n",
            "3            21.0          29.0  \n",
            "4            31.0          15.0  \n",
            "\n",
            "-----------------------------------------\n",
            "\n",
            "Data Insights for Train/Test Target:\n",
            "\n",
            "Missing values in each column:\n",
            "Prediction1    0\n",
            "dtype: int64\n",
            "\n",
            "Percentage of missing values in each column:\n",
            "Prediction1    0.0\n",
            "dtype: float64\n",
            "\n",
            "Summary statistics:\n",
            "       Prediction1\n",
            "count   1407.00000\n",
            "mean      18.77683\n",
            "std       10.27599\n",
            "min        1.00000\n",
            "25%       10.00000\n",
            "50%       19.00000\n",
            "75%       28.00000\n",
            "max       36.00000\n",
            "\n",
            "First few rows of data:\n",
            "   Prediction1\n",
            "0           31\n",
            "1           15\n",
            "2           31\n",
            "3           31\n",
            "4           21\n",
            "\n",
            "-----------------------------------------\n",
            "\n",
            "Data Insights for Unseen Features:\n",
            "\n",
            "Missing values in each column:\n",
            "Year              0\n",
            "Month             0\n",
            "Day               0\n",
            "Prev_Week         0\n",
            "Prev_Entry        0\n",
            "Mov_Avg_Mor       5\n",
            "Prev_Morning      0\n",
            "Prev_Afternoon    0\n",
            "Prev_Evening      0\n",
            "dtype: int64\n",
            "\n",
            "Percentage of missing values in each column:\n",
            "Year                0.0\n",
            "Month               0.0\n",
            "Day                 0.0\n",
            "Prev_Week           0.0\n",
            "Prev_Entry          0.0\n",
            "Mov_Avg_Mor       100.0\n",
            "Prev_Morning        0.0\n",
            "Prev_Afternoon      0.0\n",
            "Prev_Evening        0.0\n",
            "dtype: float64\n",
            "\n",
            "Summary statistics:\n",
            "         Year  Month       Day  Prev_Week  Prev_Entry  Mov_Avg_Mor  \\\n",
            "count     5.0    5.0  5.000000   5.000000    5.000000          0.0   \n",
            "mean   2023.0    8.0  4.200000  26.800000   14.200000          NaN   \n",
            "std       0.0    0.0  1.923538   4.816638    9.602083          NaN   \n",
            "min    2023.0    8.0  2.000000  20.000000    2.000000          NaN   \n",
            "25%    2023.0    8.0  3.000000  25.000000   11.000000          NaN   \n",
            "50%    2023.0    8.0  4.000000  27.000000   12.000000          NaN   \n",
            "75%    2023.0    8.0  5.000000  29.000000   18.000000          NaN   \n",
            "max    2023.0    8.0  7.000000  33.000000   28.000000          NaN   \n",
            "\n",
            "       Prev_Morning  Prev_Afternoon  Prev_Evening  \n",
            "count           5.0        5.000000         5.000  \n",
            "mean           18.0       23.800000        17.600  \n",
            "std             0.0       11.861703        12.502  \n",
            "min            18.0        5.000000         2.000  \n",
            "25%            18.0       20.000000         7.000  \n",
            "50%            18.0       28.000000        22.000  \n",
            "75%            18.0       31.000000        26.000  \n",
            "max            18.0       35.000000        31.000  \n",
            "\n",
            "First few rows of data:\n",
            "   Year  Month  Day  Prev_Week  Prev_Entry  Mov_Avg_Mor  Prev_Morning  \\\n",
            "0  2023      8    2         33          18          NaN          18.0   \n",
            "1  2023      8    3         27          28          NaN          18.0   \n",
            "2  2023      8    4         20           2          NaN          18.0   \n",
            "3  2023      8    5         29          12          NaN          18.0   \n",
            "4  2023      8    7         25          11          NaN          18.0   \n",
            "\n",
            "   Prev_Afternoon  Prev_Evening  \n",
            "0            20.0          26.0  \n",
            "1            31.0           7.0  \n",
            "2             5.0           2.0  \n",
            "3            28.0          22.0  \n",
            "4            35.0          31.0  \n",
            "\n",
            "-----------------------------------------\n",
            "\n",
            "Data Insights for Unseen Target:\n",
            "\n",
            "Missing values in each column:\n",
            "Prediction1    5\n",
            "dtype: int64\n",
            "\n",
            "Percentage of missing values in each column:\n",
            "Prediction1    100.0\n",
            "dtype: float64\n",
            "\n",
            "Summary statistics:\n",
            "       Prediction1\n",
            "count          0.0\n",
            "mean           NaN\n",
            "std            NaN\n",
            "min            NaN\n",
            "25%            NaN\n",
            "50%            NaN\n",
            "75%            NaN\n",
            "max            NaN\n",
            "\n",
            "First few rows of data:\n",
            "   Prediction1\n",
            "0          NaN\n",
            "1          NaN\n",
            "2          NaN\n",
            "3          NaN\n",
            "4          NaN\n",
            "\n",
            "-----------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3.3: Setting Bounds for Numerical Range and Preparing Data for Prediction\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Load the dataset first\n",
        "data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/preprocessed_train_test_data.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "logger.info(\"Enforcing numerical bounds...\")\n",
        "\n",
        "# Define all columns that should have values in the range of 1 to 36\n",
        "columns_to_check = [\n",
        "    'Morning', 'Prev_Week', 'Prev_Entry', 'Mov_Avg_Mor', 'Afternoon',\n",
        "    'Prev_Week.1', 'Prev_Entry.1', 'Mov_Avg_Aft', 'Evening', 'Prev_Week.2',\n",
        "    'Prev_Entry.2', 'Mov_Avg_Eve', 'Night', 'Prev_Week.3', 'Prev_Entry.3',\n",
        "    'Mov_Avg_Nig', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening', 'Prediction1'\n",
        "]\n",
        "\n",
        "# Loop through these columns and enforce the range if they exist in the DataFrame\n",
        "for col in columns_to_check:\n",
        "    if col in data.columns:\n",
        "        # Find values outside the range and enforce the range by clipping values\n",
        "        data[col] = data[col].clip(lower=1, upper=36)\n",
        "\n",
        "# Ensure changes are reflected\n",
        "print(data.describe())\n",
        "\n",
        "# Prepare the current data with NaNs in 'Prediction1' for testing\n",
        "selected_columns = ['Year', 'Month', 'Day', 'Prev_Week', 'Prev_Entry', 'Mov_Avg_Mor', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening']\n",
        "current_data = data[selected_columns].copy()  # Use .copy() to create an independent copy\n",
        "current_data['Prediction1'] = np.nan  # Initialize 'Prediction1' with NaN\n",
        "\n",
        "# After initializing 'Prediction1' with NaN\n",
        "print(\"\\nFirst few rows of current data with 'Prediction1' initialized as NaN:\")\n",
        "print(current_data.head())\n",
        "\n",
        "# Display Row 1406 (End of Testing Data)\n",
        "print(\"Row 1406 (End of Testing Data):\")\n",
        "print(data.iloc[1406])  # Remember, Python indexing starts at 0\n",
        "\n",
        "# Saving the prepared current data\n",
        "prepared_current_data_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/7_prepared_current_data_for_prediction1.csv'\n",
        "current_data.to_csv(prepared_current_data_path, index=False)\n",
        "logger.info(\"Prepared current data saved to Google Drive.\")\n",
        "\n",
        "# Confirming the file saving by reading and displaying the first few rows\n",
        "logger.info(\"Verifying saved prepared current data:\")\n",
        "saved_current_data = pd.read_csv(prepared_current_data_path)\n",
        "print(saved_current_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi7kZT26PrzA",
        "outputId": "90ee04a6-0d05-4511-f752-5282fc654f20"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Row Number     Morning    Prev_Week  Rep_Prev_Week   Prev_Entry  \\\n",
            "count  1407.000000  1407.00000  1407.000000    1407.000000  1407.000000   \n",
            "mean    705.632552    18.77683    18.240938       0.027008    18.130064   \n",
            "std     406.713037    10.27599    10.520904       0.162164    10.368159   \n",
            "min       2.000000     1.00000     1.000000       0.000000     1.000000   \n",
            "25%     353.500000    10.00000     9.000000       0.000000     9.000000   \n",
            "50%     706.000000    19.00000    18.000000       0.000000    18.000000   \n",
            "75%    1057.500000    28.00000    27.000000       0.000000    27.000000   \n",
            "max    1409.000000    36.00000    36.000000       1.000000    36.000000   \n",
            "\n",
            "       Rep_Prev_Entry  Mov_Avg_Mor    Afternoon  Prev_Week.1  Rep_Prev_Week.1  \\\n",
            "count     1407.000000  1407.000000  1407.000000  1407.000000      1407.000000   \n",
            "mean         0.014925    18.773632    18.613362    18.156361         0.022033   \n",
            "std          0.121297     7.076781    10.361999    10.601390         0.146842   \n",
            "min          0.000000     1.500000     1.000000     1.000000         0.000000   \n",
            "25%          0.000000    13.500000     9.000000     9.000000         0.000000   \n",
            "50%          0.000000    19.000000    19.000000    19.000000         0.000000   \n",
            "75%          0.000000    24.000000    27.000000    27.000000         0.000000   \n",
            "max          1.000000    35.500000    36.000000    36.000000         1.000000   \n",
            "\n",
            "       ...  Prev_Entry.3  Rep_Prev_Entry.3  Mov_Avg_Nig         Year  \\\n",
            "count  ...   1407.000000       1407.000000  1407.000000  1407.000000   \n",
            "mean   ...     18.506041          0.026297    18.119048  2020.577825   \n",
            "std    ...     10.232215          0.160074     7.420336     1.556254   \n",
            "min    ...      1.000000          0.000000     1.000000  2018.000000   \n",
            "25%    ...     10.000000          0.000000    12.500000  2019.000000   \n",
            "50%    ...     19.000000          0.000000    18.000000  2021.000000   \n",
            "75%    ...     27.000000          0.000000    23.250000  2022.000000   \n",
            "max    ...     36.000000          1.000000    35.000000  2023.000000   \n",
            "\n",
            "             Month          Day  Prev_Morning  Prev_Afternoon  Prev_Evening  \\\n",
            "count  1407.000000  1407.000000   1407.000000     1407.000000   1407.000000   \n",
            "mean      6.629709    15.626866     18.770434       18.623312     18.528785   \n",
            "std       3.565689     8.752854     10.277406       10.360101     10.240097   \n",
            "min       1.000000     1.000000      1.000000        1.000000      1.000000   \n",
            "25%       3.000000     8.000000     10.000000        9.000000     10.000000   \n",
            "50%       7.000000    16.000000     19.000000       19.000000     19.000000   \n",
            "75%      10.000000    23.000000     28.000000       27.000000     27.000000   \n",
            "max      12.000000    31.000000     36.000000       36.000000     36.000000   \n",
            "\n",
            "       Prediction1  \n",
            "count   1407.00000  \n",
            "mean      18.77683  \n",
            "std       10.27599  \n",
            "min        1.00000  \n",
            "25%       10.00000  \n",
            "50%       19.00000  \n",
            "75%       28.00000  \n",
            "max       36.00000  \n",
            "\n",
            "[8 rows x 32 columns]\n",
            "\n",
            "First few rows of current data with 'Prediction1' initialized as NaN:\n",
            "   Year  Month  Day  Prev_Week  Prev_Entry  Mov_Avg_Mor  Prev_Morning  \\\n",
            "0  2018      8    2         11           9         25.0          19.0   \n",
            "1  2018      8    3         19          12         23.0          31.0   \n",
            "2  2018      8    4         35          35         23.0          15.0   \n",
            "3  2018      8    6         18          16         31.0          31.0   \n",
            "4  2018      8    7         13          18         26.0          31.0   \n",
            "\n",
            "   Prev_Afternoon  Prev_Evening  Prediction1  \n",
            "0            14.0          33.0          NaN  \n",
            "1             3.0          35.0          NaN  \n",
            "2             9.0          23.0          NaN  \n",
            "3            21.0          29.0          NaN  \n",
            "4            31.0          15.0          NaN  \n",
            "Row 1406 (End of Testing Data):\n",
            "Date                2023-07-31\n",
            "Row Number                1409\n",
            "Data_Type              Testing\n",
            "Morning                     25\n",
            "Prev_Week                    5\n",
            "Rep_Prev_Week                0\n",
            "Prev_Entry                   3\n",
            "Rep_Prev_Entry               0\n",
            "Mov_Avg_Mor               27.0\n",
            "Afternoon                    9\n",
            "Prev_Week.1                 14\n",
            "Rep_Prev_Week.1              0\n",
            "Prev_Entry.1                25\n",
            "Rep_Prev_Entry.1             0\n",
            "Mov_Avg_Aft                8.0\n",
            "Evening                      7\n",
            "Prev_Week.2                 30\n",
            "Rep_Prev_Week.2              0\n",
            "Prev_Entry.2                 9\n",
            "Rep_Prev_Entry.2             0\n",
            "Mov_Avg_Eve                6.0\n",
            "Night                        5\n",
            "Prev_Week.3                 22\n",
            "Rep_Prev_Week.3              0\n",
            "Prev_Entry.3                 7\n",
            "Rep_Prev_Entry.3             0\n",
            "Mov_Avg_Nig                4.0\n",
            "Year                      2023\n",
            "Month                        7\n",
            "Day                         31\n",
            "Prev_Morning              29.0\n",
            "Prev_Afternoon             7.0\n",
            "Prev_Evening               5.0\n",
            "Prediction1                 25\n",
            "Name: 1406, dtype: object\n",
            "   Year  Month  Day  Prev_Week  Prev_Entry  Mov_Avg_Mor  Prev_Morning  \\\n",
            "0  2018      8    2         11           9         25.0          19.0   \n",
            "1  2018      8    3         19          12         23.0          31.0   \n",
            "2  2018      8    4         35          35         23.0          15.0   \n",
            "3  2018      8    6         18          16         31.0          31.0   \n",
            "4  2018      8    7         13          18         26.0          31.0   \n",
            "\n",
            "   Prev_Afternoon  Prev_Evening  Prediction1  \n",
            "0            14.0          33.0          NaN  \n",
            "1             3.0          35.0          NaN  \n",
            "2             9.0          23.0          NaN  \n",
            "3            21.0          29.0          NaN  \n",
            "4            31.0          15.0          NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4.1: Data Preparation for Prediction\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define the preprocessing function for feature datasets\n",
        "def preprocess_features(data):\n",
        "    \"\"\"Preprocess feature data.\"\"\"\n",
        "    logger.info(\"Starting preprocessing for feature dataset\")\n",
        "\n",
        "    # Check if 'Date' column exists and convert it to datetime, then extract 'Year', 'Month', 'Day'\n",
        "    if 'Date' in data.columns:\n",
        "        data['Date'] = pd.to_datetime(data['Date'])\n",
        "        data['Year'] = data['Date'].dt.year\n",
        "        data['Month'] = data['Date'].dt.month\n",
        "        data['Day'] = data['Date'].dt.day\n",
        "        data.drop('Date', axis=1, inplace=True)  # Drop the 'Date' column after extraction\n",
        "\n",
        "    # Select relevant columns\n",
        "    selected_columns = ['Year', 'Month', 'Day', 'Prev_Week', 'Prev_Entry', 'Mov_Avg_Mor', 'Prev_Morning', 'Prev_Afternoon', 'Prev_Evening']\n",
        "    data = data[selected_columns]\n",
        "\n",
        "    return data\n",
        "\n",
        "# Paths to CSV files\n",
        "paths = {\n",
        "    \"train_test_features\": '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/3_train_test_features.csv',\n",
        "    \"train_test_target\": '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/4_train_test_target.csv',\n",
        "    \"unseen_features\": '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/5_unseen_features.csv',\n",
        "    \"unseen_target\": '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/6_unseen_target.csv'\n",
        "}\n",
        "\n",
        "# Load and preprocess feature datasets\n",
        "X_train_test = preprocess_features(pd.read_csv(paths[\"train_test_features\"]))\n",
        "X_unseen = preprocess_features(pd.read_csv(paths[\"unseen_features\"]))\n",
        "\n",
        "# Load target datasets without preprocessing\n",
        "y_train_test = pd.read_csv(paths[\"train_test_target\"])\n",
        "y_unseen = pd.read_csv(paths[\"unseen_target\"])\n",
        "\n",
        "# Quick check of data structures\n",
        "logger.info(\"Train/Test Features Shape: %s, Unseen Features Shape: %s\", X_train_test.shape, X_unseen.shape)\n",
        "logger.info(\"Train/Test Target Shape: %s, Unseen Target Shape: %s\", y_train_test.shape, y_unseen.shape)\n",
        "\n",
        "# Further processing (if necessary)\n",
        "# Example: Feature scaling, handling categorical variables, etc.\n",
        "\n",
        "# Prepare for unseen data processing (to be done at a later stage)\n"
      ],
      "metadata": {
        "id": "VshK68czukkS"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4.1: Data Preparation for Prediction\n",
        "# ... [previous setup and preprocessing code] ...\n",
        "\n",
        "# Load and preprocess feature datasets\n",
        "X_train_test = preprocess_features(pd.read_csv(paths[\"train_test_features\"]))\n",
        "X_unseen = preprocess_features(pd.read_csv(paths[\"unseen_features\"]))\n",
        "\n",
        "# Load target datasets without preprocessing\n",
        "y_train_test = pd.read_csv(paths[\"train_test_target\"])\n",
        "y_unseen = pd.read_csv(paths[\"unseen_target\"])\n",
        "\n",
        "# Quick integrity check at the end\n",
        "print(\"\\nIntegrity Check for Train/Test Features\")\n",
        "print(\"Shape of Features:\", X_train_test.shape)\n",
        "print(\"First few rows of Features:\")\n",
        "print(X_train_test.head())\n",
        "\n",
        "print(\"\\nIntegrity Check for Train/Test Target\")\n",
        "print(\"Shape of Target:\", y_train_test.shape)\n",
        "print(\"First few rows of Target:\")\n",
        "print(y_train_test.head())\n",
        "\n",
        "print(\"\\nIntegrity Check for Unseen Features\")\n",
        "print(\"Shape of Features:\", X_unseen.shape)\n",
        "print(\"First few rows of Features:\")\n",
        "print(X_unseen.head())\n",
        "\n",
        "print(\"\\nIntegrity Check for Unseen Target\")\n",
        "print(\"Shape of Target:\", y_unseen.shape)\n",
        "print(\"First few rows of Target:\")\n",
        "print(y_unseen.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZM73PaRUGKn",
        "outputId": "bbb8b5b8-e1a8-4949-c8f3-e68f5266ba7d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Integrity Check for Train/Test Features\n",
            "Shape of Features: (1407, 9)\n",
            "First few rows of Features:\n",
            "   Year  Month  Day  Prev_Week  Prev_Entry  Mov_Avg_Mor  Prev_Morning  \\\n",
            "0  2018      8    2         11           9         25.0          19.0   \n",
            "1  2018      8    3         19          12         23.0          31.0   \n",
            "2  2018      8    4         35          35         23.0          15.0   \n",
            "3  2018      8    6         18          16         31.0          31.0   \n",
            "4  2018      8    7         13          18         26.0          31.0   \n",
            "\n",
            "   Prev_Afternoon  Prev_Evening  \n",
            "0            14.0          33.0  \n",
            "1             3.0          35.0  \n",
            "2             9.0          23.0  \n",
            "3            21.0          29.0  \n",
            "4            31.0          15.0  \n",
            "\n",
            "Integrity Check for Train/Test Target\n",
            "Shape of Target: (1407, 1)\n",
            "First few rows of Target:\n",
            "   Prediction1\n",
            "0           31\n",
            "1           15\n",
            "2           31\n",
            "3           31\n",
            "4           21\n",
            "\n",
            "Integrity Check for Unseen Features\n",
            "Shape of Features: (5, 9)\n",
            "First few rows of Features:\n",
            "   Year  Month  Day  Prev_Week  Prev_Entry  Mov_Avg_Mor  Prev_Morning  \\\n",
            "0  2023      8    2         33          18          NaN          18.0   \n",
            "1  2023      8    3         27          28          NaN          18.0   \n",
            "2  2023      8    4         20           2          NaN          18.0   \n",
            "3  2023      8    5         29          12          NaN          18.0   \n",
            "4  2023      8    7         25          11          NaN          18.0   \n",
            "\n",
            "   Prev_Afternoon  Prev_Evening  \n",
            "0            20.0          26.0  \n",
            "1            31.0           7.0  \n",
            "2             5.0           2.0  \n",
            "3            28.0          22.0  \n",
            "4            35.0          31.0  \n",
            "\n",
            "Integrity Check for Unseen Target\n",
            "Shape of Target: (5, 1)\n",
            "First few rows of Target:\n",
            "   Prediction1\n",
            "0          NaN\n",
            "1          NaN\n",
            "2          NaN\n",
            "3          NaN\n",
            "4          NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4.2: Model Training, Prediction, and Unseen Data Loading\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import joblib\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def train_and_evaluate_model(X_train, y_train, X_val, y_val):\n",
        "    \"\"\"Train Random Forest model and evaluate it on validation data.\"\"\"\n",
        "    model = RandomForestRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train.values.ravel())\n",
        "    logger.info(\"Random Forest model trained.\")\n",
        "\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    logger.info(f\"Validation MSE: {mean_squared_error(y_val, y_val_pred)}, R2 Score: {r2_score(y_val, y_val_pred)}\")\n",
        "    return model\n",
        "\n",
        "# Paths to data\n",
        "data_paths = {\n",
        "    \"X_train\": '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/3_train_test_features.csv',\n",
        "    \"y_train\": '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/4_train_test_target.csv',\n",
        "    \"X_val\": '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/3_train_test_features.csv',\n",
        "    \"y_val\": '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/4_train_test_target.csv',\n",
        "    \"current_data\": '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/7_prepared_current_data_for_prediction1.csv',\n",
        "    \"original_unseen_data\": '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/5_unseen_features.csv'  # Adjust to original unseen data file\n",
        "}\n",
        "\n",
        "# Load and process data\n",
        "X_train = pd.read_csv(data_paths[\"X_train\"])\n",
        "y_train = pd.read_csv(data_paths[\"y_train\"])\n",
        "X_val = pd.read_csv(data_paths[\"X_val\"])\n",
        "y_val = pd.read_csv(data_paths[\"y_val\"])\n",
        "current_data = pd.read_csv(data_paths[\"current_data\"])\n",
        "original_unseen_data = pd.read_csv(data_paths[\"original_unseen_data\"])\n",
        "\n",
        "# Train and save model\n",
        "model = train_and_evaluate_model(X_train, y_train, X_val, y_val)\n",
        "joblib.dump(model, '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/random_forest_model.pkl')\n",
        "logger.info(\"Model saved to Google Drive.\")\n",
        "\n",
        "# Predict and save current data\n",
        "current_data['Prediction1'] = np.round(model.predict(current_data.drop('Prediction1', axis=1)))\n",
        "current_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/current_data_with_prediction1.csv', index=False)\n",
        "logger.info(\"Current data predictions saved.\")\n",
        "\n",
        "# Predict unseen data\n",
        "original_unseen_data['Prediction1'] = model.predict(original_unseen_data[selected_columns])\n",
        "\n",
        "# Save unseen data with predictions\n",
        "original_unseen_data.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/Model_Unseen_Data_with_Predictions.csv', index=False)\n",
        "logger.info(\"Unseen data predictions saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "oMiB868RwRYx",
        "outputId": "92903ab6-7c27-49d0-a11a-c7ec33ba47cb"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-6113a6dba101>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Train and save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/My Drive/Predictive_Modeling_Four_Draws/Morning_Draw_Model_Docs/random_forest_model.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model saved to Google Drive.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-78-6113a6dba101>\u001b[0m in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m\"\"\"Train Random Forest model and evaluate it on validation data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random Forest model trained.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         )\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2082\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m         if (\n\u001b[1;32m   2086\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2018-08-02'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load and display the first few rows of '8_current_data_with_prediction1.csv'\n",
        "current_data_with_predictions_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/current_data_with_prediction1.csv'\n",
        "current_data_with_predictions = pd.read_csv(current_data_with_predictions_path)\n",
        "\n",
        "print(\"First few rows of current data with predictions ('8_current_data_with_prediction1.csv'):\")\n",
        "print(current_data_with_predictions.head())\n",
        "\n",
        "# Load and display the first few rows of '9_Model_Unseen_Data_with_Predictions.csv'\n",
        "unseen_data_with_predictions_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/Model_Unseen_Data_with_Predictions.csv'\n",
        "unseen_data_with_predictions = pd.read_csv(unseen_data_with_predictions_path)\n",
        "\n",
        "print(\"\\nFirst few rows of unseen data with predictions ('9_Model_Unseen_Data_with_Predictions.csv'):\")\n",
        "print(unseen_data_with_predictions.head())\n"
      ],
      "metadata": {
        "id": "hvkKukSx7rVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.3: Filter Unseen Data to Match Previous Dataset Structure\n",
        "\n",
        "# Define the columns to keep\n",
        "columns_to_keep = ['Year', 'Month', 'Day', 'Prev_Week', 'Prev_Entry',\n",
        "                   'Mov_Avg_Mor', 'Prev_Morning', 'Prev_Afternoon',\n",
        "                   'Prev_Evening', 'Prediction1']\n",
        "\n",
        "# Drop irrelevant columns\n",
        "unseen_data_filtered = unseen_data[columns_to_keep]\n",
        "\n",
        "# Print the first few rows of the filtered unseen data\n",
        "print(\"First few rows of filtered unseen data:\")\n",
        "print(unseen_data_filtered.head())\n"
      ],
      "metadata": {
        "id": "c-RtF3NUOrH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3.3: Enhanced NaN Check and Handling in 'Prediction1'\n",
        "\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "logger.info(\"Loading current data with predictions for enhanced NaN handling...\")\n",
        "\n",
        "# Load the current data with predictions\n",
        "current_data_with_predictions = pd.read_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/current_data_with_prediction1.csv')\n",
        "\n",
        "# Forward fill NaNs in the first row\n",
        "current_data_with_predictions.iloc[0] = current_data_with_predictions.iloc[0].fillna(method='ffill')\n",
        "\n",
        "# Print the first few rows to verify NaN handling\n",
        "print(\"First few rows of current data after NaN handling:\\n\", current_data_with_predictions.head())\n",
        "\n",
        "# Check for NaN values in 'Prediction1'\n",
        "nan_count_prediction1 = current_data_with_predictions['Prediction1'].isnull().sum()\n",
        "logger.info(f\"Number of NaN values in 'Prediction1': {nan_count_prediction1}\")\n",
        "\n",
        "if nan_count_prediction1 > 0:\n",
        "    logger.warning(\"NaNs detected in 'Prediction1'. Here are the details:\")\n",
        "    nan_rows = current_data_with_predictions[current_data_with_predictions['Prediction1'].isnull()]\n",
        "    print(\"Rows with NaN in 'Prediction1':\\n\", nan_rows)\n",
        "else:\n",
        "    print(\"No NaN values found in 'Prediction1'.\")\n",
        "\n",
        "# Additional analysis or handling of NaNs can be added here if needed\n"
      ],
      "metadata": {
        "id": "lm8OBUPe0MN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4.1. Model Interpretation\n",
        "\n",
        "import shap\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Load the finalized model\n",
        "final_model = joblib.load('/content/drive/My Drive/Predictive_Modeling_Four_Draws/random_forest_prediction_model.pkl')\n",
        "\n",
        "logger.info(\"Interpreting the model with SHAP values...\")\n",
        "\n",
        "# Assuming X_val is already prepared in previous cells\n",
        "# Using SHAP to interpret the model\n",
        "explainer = shap.TreeExplainer(final_model)\n",
        "shap_values = explainer.shap_values(X_val)\n",
        "shap.summary_plot(shap_values, X_val, plot_type=\"bar\")\n",
        "\n",
        "# STEP 4.2. FINAL MODEL SELECTION AND REPORTING\n",
        "\n",
        "logger.info(\"Evaluating final model performance with regression metrics...\")\n",
        "\n",
        "# Flatten y_val to ensure it's 1-dimensional\n",
        "y_val_flat = y_val.values.ravel() if isinstance(y_val, pd.DataFrame) else y_val\n",
        "\n",
        "# Generate predictions for the validation set\n",
        "y_pred_val = final_model.predict(X_val)\n",
        "y_pred_val_rounded = np.round(y_pred_val)\n",
        "\n",
        "# Flatten y_pred_val_rounded to ensure it's 1-dimensional\n",
        "y_pred_val_flat = y_pred_val_rounded.ravel() if isinstance(y_pred_val_rounded, pd.DataFrame) else y_pred_val_rounded\n",
        "\n",
        "# Create the DataFrame\n",
        "predictions_df = pd.DataFrame({'Actual': y_val_flat, 'Predicted': y_pred_val_flat})\n",
        "\n",
        "# Save the DataFrame as CSV\n",
        "predictions_df.to_csv('/content/drive/My Drive/Predictive_Modeling_Four_Draws/predictions_df.csv', index=False)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) and R2 Score for the validation set\n",
        "mse_val = mean_squared_error(y_val_flat, y_pred_val_flat)\n",
        "r2_val = r2_score(y_val_flat, y_pred_val_flat)\n",
        "\n",
        "logger.info(f\"Validation MSE: {mse_val}, R2 Score: {r2_val}\")\n",
        "\n",
        "logger.info(f\"Regression Metrics:\\nMSE: {mse_val}\\nR2 Score: {r2_val}\")\n",
        "\n",
        "# STEP 4.3. PREPARATION FOR DEPLOYMENT\n",
        "\n",
        "# ...[Include steps for preparing the model for deployment]...\n",
        "\n",
        "# STEP 4.4. DOCUMENTATION AND REPORTING\n",
        "\n",
        "# ...[Prepare a comprehensive report on the model's performance, limitations, and deployment steps]...\n",
        "\n",
        "logger.info(\"Model documentation and reporting completed.\")\n",
        "\n",
        "# Final Checks and Tests (if applicable)\n",
        "# ...[Include any final testing or checks before deployment]...\n",
        "\n",
        "logger.info(\"Final checks and tests completed.\")\n",
        "logger.info(\"Cell 4 tasks completed successfully.\")\n"
      ],
      "metadata": {
        "id": "V28FJ39EHF8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5. Cross-Validation and  additional metrics analysis\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import joblib\n",
        "import shap\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Assuming you are using RandomForestRegressor as your model\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Define your scoring metrics for regression\n",
        "scoring_metrics = {\n",
        "    'MSE': make_scorer(mean_squared_error, greater_is_better=False),\n",
        "    'R2': make_scorer(r2_score)\n",
        "}\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Assuming 'data' is sorted by date and 'model' is your trained model\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "for train_index, test_index in tscv.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    model.fit(X_train, y_train)  # Train your model\n",
        "    predictions = model.predict(X_test)  # Make predictions\n",
        "\n",
        "    mse = mean_squared_error(y_test, predictions)  # Calculate MSE\n",
        "    print(f\"MSE for the current fold: {mse}\")\n",
        "\n",
        "# Given the list of MSE scores from each fold\n",
        "mse_scores = [3.4702196581196585, 1.9403478632478632, 1.051690170940171, 0.7291717948717948, 0.4926722222222223]\n",
        "\n",
        "# Calculate the average MSE\n",
        "average_mse = sum(mse_scores) / len(mse_scores)\n",
        "print(f\"Average MSE across all folds: {average_mse}\")\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "k_folds = 10  # Number of folds\n",
        "cv_results = {}\n",
        "for metric_name, scorer in scoring_metrics.items():\n",
        "    scores = cross_val_score(model, X, y.fillna(y.mean()), scoring=scorer, cv=k_folds)\n",
        "    cv_results[metric_name] = scores\n",
        "    logger.info(f\"{metric_name} scores for each fold: {scores}\")\n",
        "    logger.info(f\"Average {metric_name} over {k_folds} folds: {np.mean(scores)}\")\n",
        "\n",
        "# Additional metrics analysis and error/bias exploration\n",
        "# ... Add your code for detailed analysis of errors, biases, etc. ...\n",
        "logger.info(\"Cross-validation and additional metrics analysis completed.\")\n",
        "\n",
        "# Feature Importance Analysis using SHAP\n",
        "# Assuming 'final_model' is your trained RandomForestRegressor model\n",
        "\n",
        "# Load the trained model (if not already loaded)\n",
        "final_model = joblib.load('/content/drive/My Drive/Predictive_Modeling_Four_Draws/random_forest_prediction_model.pkl')\n",
        "\n",
        "# Explain the model's predictions using SHAP\n",
        "explainer = shap.TreeExplainer(final_model)\n",
        "shap_values = explainer.shap_values(X)\n",
        "\n",
        "# Plot summary plot using SHAP values\n",
        "shap.summary_plot(shap_values, X)\n",
        "\n",
        "logger.info(\"Feature importance analysis using SHAP completed.\")\n"
      ],
      "metadata": {
        "id": "YupgSJuhz3iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6. Detailed error and bias analysis\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "from google.colab import drive\n",
        "\n",
        "# Set up logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Ensure Google Drive is mounted\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define the path in Google Drive where the predictions DataFrame is saved\n",
        "predictions_df_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/predictions_df.csv'\n",
        "\n",
        "# Load or create the predictions DataFrame\n",
        "if os.path.exists(predictions_df_path):\n",
        "    predictions_df = pd.read_csv(predictions_df_path)\n",
        "else:\n",
        "    # Assuming predictions were made in a previous step and saved as 'predictions_df.csv'\n",
        "    raise FileNotFoundError(\"predictions_df.csv not found. Ensure it's created in previous steps.\")\n",
        "\n",
        "logger.info(\"Predictions DataFrame loaded successfully for error and bias analysis.\")\n",
        "print(predictions_df.columns)\n",
        "\n",
        "# Error Analysis\n",
        "predictions_df['Error'] = predictions_df['Predicted'] - predictions_df['Actual']\n",
        "predictions_df['Absolute_Error'] = predictions_df['Error'].abs()\n",
        "\n",
        "# Plotting error distribution\n",
        "plt.hist(predictions_df['Error'], bins=30)\n",
        "plt.title('Error Distribution')\n",
        "plt.xlabel('Prediction Error')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# Subgroup Analysis\n",
        "# Ensure that 'Prev_Week' and 'Prev_Entry' are in predictions_df\n",
        "if 'Prev_Week' in predictions_df and 'Prev_Entry' in predictions_df:\n",
        "    # Subgroup analysis based on 'Prev_Week'\n",
        "    prev_week_performance = predictions_df.groupby('Prev_Week').mean()['Absolute_Error']\n",
        "    prev_week_performance.plot(kind='bar', figsize=(10, 6))\n",
        "    plt.title('Performance by Previous Week')\n",
        "    plt.xlabel('Previous Week')\n",
        "    plt.ylabel('Average Absolute Error')\n",
        "    plt.show()\n",
        "\n",
        "    # Subgroup analysis based on 'Prev_Entry'\n",
        "    prev_entry_performance = predictions_df.groupby('Prev_Entry').mean()['Absolute_Error']\n",
        "    prev_entry_performance.plot(kind='bar', figsize=(10, 6))\n",
        "    plt.title('Performance by Previous Entry')\n",
        "    plt.xlabel('Previous Entry')\n",
        "    plt.ylabel('Average Absolute Error')\n",
        "    plt.show()\n",
        "\n",
        "# Document findings\n",
        "error_bias_report = \"\"\"\n",
        "Detailed Error Analysis:\n",
        "- Error Distribution Insights: {'Describe your findings from the error distribution here'}\n",
        "- Largest Errors: {'Describe characteristics of instances with largest errors here'}\n",
        "\n",
        "Bias Exploration:\n",
        "- Performance by Previous Week: {'Describe performance variations based on the previous week here'}\n",
        "- Performance by Previous Entry: {'Describe performance variations based on the previous entry here'}\n",
        "\"\"\"\n",
        "\n",
        "logger.info(\"Error and bias analysis completed.\")\n",
        "logger.info(error_bias_report)\n"
      ],
      "metadata": {
        "id": "mr21I98826sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7. Final review, deployment preparation, and documentation\n",
        "\n",
        "import joblib\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Final Model Review and Refinement\n",
        "# ... Code/comments for any last adjustments to the model ...\n",
        "\n",
        "# Deployment Preparation\n",
        "# Serialize the final model\n",
        "# Ensure that 'final_model' is the variable name for your trained model to be deployed\n",
        "final_model_path = '/content/drive/My Drive/Predictive_Modeling_Four_Draws/random_forest_prediction_model.pkl'\n",
        "joblib.dump(final_model, final_model_path)\n",
        "logger.info(f\"Final model serialized and saved for deployment at: {final_model_path}\")\n",
        "\n",
        "# Comprehensive Documentation Update\n",
        "# ... Update your comprehensive report with all final findings and methodologies ...\n",
        "# Include details on model performance, SHAP interpretation, error analysis, etc.\n",
        "\n",
        "# Final Checks and Tests\n",
        "# ... Code/comments for final tests and checks to ensure model is ready for deployment ...\n",
        "\n",
        "# Planning for Future Improvements\n",
        "# Describe areas where further research could be beneficial, and methodologies to explore in future iterations of the project\n",
        "future_improvement_plan = \"\"\"\n",
        "Future Improvement Plans:\n",
        "- Areas for further research: {describe areas where additional data, feature engineering, or alternative modeling techniques could be explored}\n",
        "- Methodologies to explore: {describe potential methodologies, like deep learning or ensemble methods, for future iterations}\n",
        "\"\"\"\n",
        "\n",
        "logger.info(\"Final review and deployment preparation completed.\")\n",
        "logger.info(future_improvement_plan)\n"
      ],
      "metadata": {
        "id": "qssa3uxO9tru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "u8Y77oV7koS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "WsQJRnWtkpPO"
      }
    }
  ]
}