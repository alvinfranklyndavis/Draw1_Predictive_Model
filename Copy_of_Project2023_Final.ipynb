{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvinfranklyndavis/Project2023_v3/blob/main/Copy_of_Project2023_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5_mSX_NpQgo",
        "outputId": "0724bd9e-7dee-478d-f70f-d7ac578ca80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.44.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (3.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Aa4qkI_xffvqUve1PG-CSMQgVc617qL9\n",
            "To: /content/Training_Testing_Hybrid_MA.csv\n",
            "100%|██████████| 93.1k/93.1k [00:00<00:00, 57.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# STEP 1. INSTALL PACKAGES AND IMPORT DATA\n",
        "\n",
        "# Upgrade pip and install required packages\n",
        "!pip install -U --upgrade-strategy eager pip\n",
        "!pip install -U --upgrade-strategy eager pandas gdown numpy matplotlib scikit-learn xgboost shap\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import gdown\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import KNNImputer\n",
        "import shap\n",
        "\n",
        "# Set up logging\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define the Google Drive file ID\n",
        "file_id = '1Aa4qkI_xffvqUve1PG-CSMQgVc617qL9'\n",
        "\n",
        "# Define the URL of the CSV file\n",
        "csv_url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "# Define the local file path to save the CSV\n",
        "csv_path = 'Training_Testing_Hybrid_MA.csv'\n",
        "\n",
        "# Log the start of the dataset download\n",
        "logger.info(\"Downloading the dataset...\")\n",
        "\n",
        "# Download the CSV file from the Google Drive link\n",
        "gdown.download(csv_url, csv_path, quiet=False)\n",
        "\n",
        "# Log the successful download\n",
        "logger.info(\"Dataset downloaded successfully.\")\n",
        "\n",
        "# Read your Original dataset\n",
        "logger.info(\"Reading the dataset...\")\n",
        "data = pd.read_csv(\"Training_Testing_Hybrid_MA.csv\")  # Update with your dataset path\n",
        "logger.info(\"Dataset loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fXLj_hZYbvp",
        "outputId": "eb89798d-8717-4477-9b64-e86d3e3abc96"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Day of the Week', 'Morning', 'Prev_Week', 'Rep_Prev_Week',\n",
            "       'Prev_Entry', 'Rep_Prev_Entry', 'Mov_Avg_Mor', 'Afternoon',\n",
            "       'Prev_Week.1', 'Rep_Prev_Week.1', 'Prev_Entry.1', 'Rep_Prev_Entry.1',\n",
            "       'Mov_Avg_Aft', 'Evening', 'Prev_Week.2', 'Rep_Prev_Week.2',\n",
            "       'Prev_Entry.2', 'Rep_Prev_Entry.2', 'Mov_Avg_Eve', 'Night',\n",
            "       'Prev_Week.3', 'Rep_Prev_Week.3', 'Prev_Entry.3', 'Rep_Prev_Entry.3',\n",
            "       'Mov_Avg_Nig', 'Year', 'Month', 'Day', 'Prediction1'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2. PROCESS DATE FEATURES AND SET UP PREDICTION1 COLUMN\n",
        "\n",
        "# Extract Date features\n",
        "# 'Date' has already been dropped, and 'Year', 'Month', 'Day' have been extracted\n",
        "# data['Date'] = pd.to_datetime(data['Date'])\n",
        "# data = data.drop(columns=['Date'])  # No need to drop 'Date' again\n",
        "\n",
        "# Set up logging\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Log the start of date feature extraction\n",
        "logger.info(\"Processing date features...\")\n",
        "\n",
        "# Display data types and check for missing values\n",
        "logger.info(\"Data types:\\n%s\", data.dtypes)\n",
        "logger.info(\"Missing values:\\n%s\", data.isnull().sum())\n",
        "\n",
        "# Calculate Moving Averages for specified columns\n",
        "# Define the window size for the moving average\n",
        "window_size = 3  # You can adjust this as needed\n",
        "\n",
        "# Columns to calculate moving averages for and their corresponding target columns\n",
        "columns_to_average = ['Morning', 'Afternoon', 'Evening', 'Night']\n",
        "target_columns = ['Mov_Avg_Mor', 'Mov_Avg_Aft', 'Mov_Avg_Eve', 'Mov_Avg_Nig']\n",
        "\n",
        "# Initialize a dictionary to keep track of the window size for each column\n",
        "window_sizes = {col: 1 for col in columns_to_average}\n",
        "\n",
        "# Calculate the moving averages and fill the target columns iteratively\n",
        "for index, row in data.iterrows():\n",
        "    for col, target_col in zip(columns_to_average, target_columns):\n",
        "        window_size = window_sizes[col]\n",
        "        current_value = row[col]\n",
        "        current_avg = row[target_col]\n",
        "\n",
        "        # Calculate the updated moving average\n",
        "        updated_avg = ((window_size - 1) * current_avg + current_value) / window_size\n",
        "\n",
        "        # Update the target column with the new moving average\n",
        "        data.at[index, target_col] = updated_avg\n",
        "\n",
        "        # Increment the window size for the current column\n",
        "        window_sizes[col] += 1\n",
        "\n",
        "# Create Target Variable Column for Prediction1\n",
        "data['Prediction1'] = np.nan\n",
        "\n",
        "# Keep only relevant columns for Prediction1\n",
        "selected_columns_p1 = ['Morning', 'Prev_Week', 'Prev_Entry','Mov_Avg_Mor','Year', 'Month', 'Day', 'Prediction1']\n",
        "data_p1 = data[selected_columns_p1]\n",
        "\n",
        "# Save the train dataframe to a CSV file\n",
        "logger.info(\"Saving the Prediction1 data to CSV...\")\n",
        "data_p1.to_csv('/content/train_data_prediction1.csv', index=False)\n",
        "\n",
        "# Log the completion of date feature processing\n",
        "logger.info(\"Date features processed successfully.\")\n",
        "\n",
        "# Display the first few rows of Prediction1 data\n",
        "logger.info(\"First few rows of Prediction1 data:\\n%s\", data_p1.head())\n",
        "\n",
        "# Print Data Types if needed\n",
        "logger.info(\"Data types after conversion:\\n%s\", data.dtypes)\n"
      ],
      "metadata": {
        "id": "C-SlZ9jqZuzn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3.1. LOAD TRAIN DATAFRAME FOR PREDICTION1\n",
        "\n",
        "# Load the train dataframe\n",
        "train_data = pd.read_csv('/content/train_data_prediction1.csv')\n",
        "\n",
        "# Log the start of loading the train dataframe\n",
        "logger.info(\"Loading train dataframe for Prediction1...\")\n",
        "\n",
        "# Separate features and create a placeholder for the target variable for Prediction1\n",
        "X_p1 = train_data.drop('Prediction1', axis=1)  # Features\n",
        "y_p1_placeholder = np.full(X_p1.shape[0], np.nan)  # Placeholder for target variable 'Prediction1'\n",
        "\n",
        "# Log the completion of loading the train dataframe\n",
        "logger.info(\"Train dataframe for Prediction1 loaded successfully.\")\n",
        "\n",
        "# STEP 3.2. SPLIT DATA INTO TRAINING AND TESTING SETS FOR PREDICTION1\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "random_seed = 42  # You can use any integer value\n",
        "\n",
        "# Split the data into training and testing sets for Prediction1\n",
        "X_train_p1, X_test_p1, y_train_p1_placeholder, y_test_p1_placeholder = train_test_split(\n",
        "    X_p1,  # Features for 'Prediction1'\n",
        "    y_p1_placeholder,  # Placeholder for target variable 'Prediction1'\n",
        "    test_size=0.2,\n",
        "    random_state=random_seed  # Set random seed\n",
        ")\n",
        "\n",
        "# Log the completion of splitting data for Prediction1\n",
        "logger.info(\"Data split into training and testing sets for Prediction1.\")\n",
        "\n",
        "# STEP 3.3. HANDLE MISSING VALUES IN THE TARGET VARIABLE FOR PREDICTION1\n",
        "\n",
        "# Check missing values in the target variable for Prediction1\n",
        "logger.info(\"Missing values in Prediction1 target variable:\\n%s\", np.isnan(y_train_p1_placeholder).sum())\n",
        "# Check for missing values in the feature data for Prediction1\n",
        "logger.info(\"Missing values in feature data for Prediction1:\")\n",
        "missing_values_train = X_train_p1.isnull().sum()\n",
        "missing_values_test = X_test_p1.isnull().sum()\n",
        "\n",
        "logger.info(\"Training set missing values:\\n%s\", missing_values_train)\n",
        "logger.info(\"Testing set missing values:\\n%s\", missing_values_test)\n",
        "\n",
        "\n",
        "# STEP 3.4. TRAIN RANDOM FOREST REGRESSOR MODEL FOR PREDICTION1\n",
        "\n",
        "# Print the size of X_train_p1 and y_train_p1 before model training\n",
        "print(\"Size of X_train_p1:\", X_train_p1.shape)\n",
        "print(\"Size of y_train_p1:\", y_train_p1.shape)\n",
        "\n",
        "# ... previous code ...\n",
        "\n",
        "try:\n",
        "    # Train a RandomForestRegressor model\n",
        "    model_p1 = RandomForestRegressor(random_state=42)\n",
        "    model_p1.fit(X_train_p1, y_train_p1)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_p1 = model_p1.predict(X_test_p1)\n",
        "\n",
        "    # Apply numpy.clip to constrain predictions within the desired range\n",
        "    lower_bound = 1\n",
        "    upper_bound = 36\n",
        "    y_pred_p1_clipped = np.clip(y_pred_p1, lower_bound, upper_bound)\n",
        "\n",
        "    # Evaluate the model using clipped predictions\n",
        "    mse_p1 = mean_squared_error(y_test_p1, y_pred_p1_clipped)\n",
        "    logger.info(\"Mean Squared Error for Prediction1 (Clipped):\\n%s\", mse_p1)\n",
        "    print(\"Mean Squared Error for Prediction1 (Clipped):\", mse_p1)\n",
        "\n",
        "except Exception as e:\n",
        "    logger.error(\"Error during model training for Prediction1: %s\", e)\n",
        "    print(\"Error during model training or evaluation:\", e)\n"
      ],
      "metadata": {
        "id": "q5WD6zcSWc09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5de1bb6-71cd-442b-b5cd-0749bda6d75d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error during model training for Prediction1: Input X contains NaN.\n",
            "RandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X_train_p1: (1127, 7)\n",
            "Size of y_train_p1: (1127,)\n",
            "Error during model training or evaluation: Input X contains NaN.\n",
            "RandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the column names in X_p1\n",
        "print(X_p1.columns)"
      ],
      "metadata": {
        "id": "WLMcuRvk3fFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4.1. FEATURE ANALYSIS\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Check the column names in X_p1\n",
        "print(X_p1.columns)\n",
        "\n",
        "# Visualize the distributions of the actual features\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(X_p1['Morning'], bins=30, kde=True, color='blue', label='Morning')\n",
        "sns.histplot(X_p1['Rep_Prev_Week'], bins=30, kde=True, color='orange', label='Rep_Prev_Week')\n",
        "sns.histplot(X_p1['Rep_Prev_Entry'], bins=30, kde=True, color='blue', label='Rep_Prev_Entry')\n",
        "sns.histplot(X_p1['Year'], bins=30, kde=True, color='orange', label='Year')\n",
        "sns.histplot(X_p1['Month'], bins=30, kde=True, color='blue', label='Month')\n",
        "sns.histplot(X_p1['Day'], bins=30, kde=True, color='orange', label='Day')\n",
        "plt.title('Distribution of Actual Features')\n",
        "plt.xlabel('Feature Values')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Calculate key statistics for each feature\n",
        "for feature in X_p1.columns:\n",
        "    feature_stats = X_p1[feature].describe()\n",
        "    print(f\"{feature} Statistics:\\n\", feature_stats)\n",
        "\n",
        "# STEP 4.2. KNN PARAMETER REVIEW\n",
        "\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Calculate Z-scores for each feature\n",
        "for feature in X_p1.columns:\n",
        "    X_p1[f\"{feature}_zscore\"] = zscore(X_p1[feature])\n",
        "\n",
        "print(\"Columns of X_p1:\\n\", X_p1.columns)\n",
        "\n",
        "# Identify outliers using a threshold (e.g., Z-score > 3 or < -3)\n",
        "outliers = pd.DataFrame()\n",
        "for feature in ['Feature1', 'Feature2']:\n",
        "    outliers_feature = X_p1[X_p1[f\"{feature}_zscore\"].abs() > 3]\n",
        "    outliers = pd.concat([outliers, outliers_feature], axis=0)\n",
        "\n",
        "# Display the identified outliers\n",
        "print(\"Outliers:\\n\", outliers)\n",
        "\n",
        "# Remove the temporary Z-score columns\n",
        "X_p1 = X_p1.drop([f\"{feature}_zscore\" for feature in ['Feature1', 'Feature2']], axis=1)\n",
        "\n",
        "# STEP 4.3. ADAPTED APPROACH FOR REAL WORLD CONSTRAINTS\n",
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Function to experiment with KNN imputation and visualize results\n",
        "def knn_imputation_experiment(k_value):\n",
        "    imputer = KNNImputer(n_neighbors=k_value)\n",
        "    imputed_data = imputer.fit_transform(X_p1[['Feature1', 'Feature2']])\n",
        "\n",
        "    # Visualize the imputed distributions\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.histplot(imputed_data[:, 0], bins=30, kde=True, color='blue', label='Imputed Feature1')\n",
        "    sns.histplot(imputed_data[:, 1], bins=30, kde=True, color='orange', label='Imputed Feature2')\n",
        "    plt.title(f'Imputed Distributions (k={k_value})')\n",
        "    plt.xlabel('Imputed Feature Values')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Experiment with different values of k (e.g., 3, 5, 7)\n",
        "for k_value in [3, 5, 7]:\n",
        "    knn_imputation_experiment(k_value)\n"
      ],
      "metadata": {
        "id": "S0RKB391_G2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Handling Missing Values for all Predictions\n",
        "\n",
        "# Combine DataFrames for easy iteration\n",
        "prediction_dfs = [data_p1, data_p2, data_p3, data_p4]\n",
        "\n",
        "for i, data_p in enumerate(prediction_dfs, start=1):\n",
        "    # Print Error: Confirm data types and check for unexpected values\n",
        "    print(f\"Data types for Prediction{i}:\\n\", data_p.dtypes)\n",
        "    print(\"Unique values in all columns for Prediction1:\\n\", data_p1.apply(lambda x: x.unique()))\n",
        "    print(\"Unique values in all columns for Prediction2:\\n\", data_p1.apply(lambda x: x.unique()))\n",
        "    print(\"Unique values in all columns for Prediction3:\\n\", data_p1.apply(lambda x: x.unique()))\n",
        "    print(\"Unique values in all columns for Prediction4:\\n\", data_p1.apply(lambda x: x.unique()))\n",
        "\n",
        "    # Print Error: Check for missing values before handling\n",
        "    print(f\"Missing values before handling Prediction{i}:\\n\", data_p.isnull().sum())\n",
        "\n",
        "# Print columns before imputation\n",
        "print(\"Columns before imputation:\", data_p.columns)\n",
        "\n",
        "# Impute missing values using a strategy (e.g., mean, median, or a constant)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Try imputation and print columns after imputation\n",
        "try:\n",
        "    data_p_imputed = pd.DataFrame(imputer.fit_transform(data_p), columns=data_p.columns)\n",
        "    print(\"Columns after imputation:\", data_p_imputed.columns)\n",
        "except Exception as e:\n",
        "    print(f\"Error during imputation: {e}\")\n",
        "\n",
        "    # Update the original DataFrame with imputed values\n",
        "    prediction_dfs[i-1] = data_p_imputed\n",
        "\n",
        "    # Print Error: Confirm missing values are handled\n",
        "    print(f\"Missing values after handling Prediction{i}:\\n\", data_p_imputed.isnull().sum())\n",
        "\n",
        "# Retrieve updated DataFrames after handling missing values\n",
        "train_data_imputed = data_p_imputed\n",
        "test_data_imputed = test_data  # Assuming you want to keep the original test_data as is\n"
      ],
      "metadata": {
        "id": "16A1x4aHvAV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kLEMu5Qqp4s"
      },
      "outputs": [],
      "source": [
        "# Step 3: Data Splitting\n",
        "\n",
        "# Data Splitting for each Prediction\n",
        "test_size = 0.2  # 80% train / 20% test split\n",
        "\n",
        "train_dfs = []  # List to store training dataframes\n",
        "test_dfs = []   # List to store testing dataframes\n",
        "\n",
        "for i, data_p in enumerate(prediction_dfs, start=1):\n",
        "    # Split data into train and test sets\n",
        "    train_data, test_data = train_test_split(data_p, test_size=test_size, shuffle=False)\n",
        "\n",
        "    # Append the dataframes to the respective lists\n",
        "    train_dfs.append(train_data)\n",
        "    test_dfs.append(test_data)\n",
        "\n",
        "    # Save the train and test dataframes to CSV files\n",
        "    train_data.to_csv(f'train_data_prediction{i}.csv', index=False, columns=data_p.columns)\n",
        "    test_data.to_csv(f'test_data_prediction{i}.csv', index=False, columns=data_p.columns)\n",
        "\n",
        "    # Print Error: Confirm the shapes of train and test sets\n",
        "    print(f\"Train set shape for Prediction{i}: {train_data.shape}\")\n",
        "    print(f\"Test set shape for Prediction{i}: {test_data.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-HHNFfZua6v"
      },
      "outputs": [],
      "source": [
        "# Step 4: Model Training\n",
        "\n",
        "for i, data_p in enumerate(prediction_dfs, start=1):\n",
        "    # Load train set\n",
        "    train_data = pd.read_csv(f'train_data_prediction{i}.csv')\n",
        "\n",
        "    # Print Error: Confirm column names in the DataFrame\n",
        "    print(f\"Columns in train_data for Prediction{i}:\", train_data.columns)\n",
        "\n",
        "    print(f\"Columns in train_data for Prediction{i} before dropping the target column:\", train_data.columns)\n",
        "\n",
        "    # Separate features and target variable\n",
        "    target_column = f'Prediction{i}'\n",
        "    if target_column not in train_data.columns:\n",
        "        print(f\"Target column '{target_column}' not found. Please check your data preparation steps.\")\n",
        "    else:\n",
        "        X_train = train_data.drop(columns=[target_column])\n",
        "        y_train = train_data[target_column]\n",
        "\n",
        "        print(f\"Columns in train_data for Prediction{i} after dropping the target column:\", X_train.columns)\n",
        "\n",
        "        # Initialize the model\n",
        "        model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Save the model\n",
        "        joblib.dump(model, f'model_prediction{i}.joblib')\n",
        "\n",
        "        # Print Error: Confirm model is trained\n",
        "        print(f\"Model for Prediction{i} is trained.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5mRBmq7yClP"
      },
      "outputs": [],
      "source": [
        "# Step 5\n",
        "for i, data_p in enumerate(test_dfs, start=1):\n",
        "    # Load test set\n",
        "    test_data = pd.read_csv(f'test_data_prediction{i}.csv')\n",
        "\n",
        "    # Print Error: Confirm column names in the DataFrame\n",
        "    print(f\"Columns in test_data for Prediction{i}:\", test_data.columns)\n",
        "\n",
        "    # Separate features\n",
        "    X_test = test_data.drop(columns=['Prediction{i}'])\n",
        "\n",
        "    # Load the trained model\n",
        "    model = joblib.load(f'model_prediction{i}.joblib')\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Assuming 'predictions' is a NumPy array, update the test_data DataFrame with the predictions\n",
        "    test_data[f'Prediction{i}'] = predictions\n",
        "\n",
        "    # Save the predictions to a CSV file or perform further analysis\n",
        "    test_data.to_csv(f'predictions_prediction{i}.csv', index=False)\n",
        "\n",
        "    # Print a message indicating successful prediction\n",
        "    print(f\"Predictions for Prediction{i} are saved.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6oKQA3ZBP65"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Display the count of missing values for each column\n",
        "print(\"Missing Values:\\n\", missing_values)\n",
        "\n",
        "# Display the count of missing values in the training sets\n",
        "print(\"Missing Values in X_train:\\n\", X_train.isnull().sum())\n",
        "print(\"\\nMissing Values in y_train:\\n\", y_train.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y_train shape:\", y_train.shape)\n"
      ],
      "metadata": {
        "id": "FWYq5q7LJOp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYjjn1kVXa1t"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # Import necessary libraries\n",
        "    from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
        "    from xgboost import XGBRegressor\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "    from sklearn.metrics import mean_squared_error, r2_score\n",
        "    import numpy as np\n",
        "except Exception as e:\n",
        "    print(f\"Error during library import: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Initialize individual models\n",
        "    rf_model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
        "    xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "    # Fit each individual model for Prediction1\n",
        "    rf_model.fit(X_train, y_train['Prediction1'])\n",
        "    xgb_model.fit(X_train, y_train['Prediction1'])\n",
        "\n",
        "    # Fit each individual model for Prediction2\n",
        "    rf_model.fit(X_train, y_train['Prediction2'])\n",
        "    xgb_model.fit(X_train, y_train['Prediction2'])\n",
        "\n",
        "    # Fit each individual model for Prediction3\n",
        "    rf_model.fit(X_train, y_train['Prediction3'])\n",
        "    xgb_model.fit(X_train, y_train['Prediction3'])\n",
        "\n",
        "    # Fit each individual model for Prediction4\n",
        "    rf_model.fit(X_train, y_train['Prediction4'])\n",
        "    xgb_model.fit(X_train, y_train['Prediction4'])\n",
        "except Exception as e:\n",
        "    print(f\"Error during model initialization and fitting: {e}\")\n"
      ],
      "metadata": {
        "id": "bKBHxUXvPzu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Create a VotingRegressor with the specified models\n",
        "    ensemble_model = VotingRegressor(estimators=[\n",
        "        ('rf', rf_model),\n",
        "        ('xgb', xgb_model)\n",
        "    ])\n",
        "except Exception as e:\n",
        "    print(f\"Error during ensemble model creation: {e}\")\n"
      ],
      "metadata": {
        "id": "T34W4iDiQKEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Use the individual models to create inputs for the ensemble model\n",
        "    rf_predictions = rf_model.predict(X_train)\n",
        "    xgb_predictions = xgb_model.predict(X_train)\n",
        "    ensemble_X_train = np.column_stack((rf_predictions, xgb_predictions))\n",
        "except Exception as e:\n",
        "    print(f\"Error during prediction and stacking: {e}\")\n"
      ],
      "metadata": {
        "id": "9unjbZ7cQvLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Ensure y_train_ensemble has the same number of elements as X_train\n",
        "    # Flatten y_train to ensure consistency\n",
        "    y_train_ensemble = y_train[['Prediction1', 'Prediction2', 'Prediction3', 'Prediction4']].values.ravel()\n",
        "\n",
        "    # Check if the sizes match\n",
        "    if ensemble_X_train.shape[0] != len(y_train_ensemble):\n",
        "        # Handle the size mismatch (e.g., by truncating or padding)\n",
        "        min_size = min(ensemble_X_train.shape[0], len(y_train_ensemble))\n",
        "        ensemble_X_train = ensemble_X_train[:min_size, :]\n",
        "        y_train_ensemble = y_train_ensemble[:min_size]\n",
        "except Exception as e:\n",
        "    print(f\"Error during data preparation: {e}\")\n"
      ],
      "metadata": {
        "id": "RByO5eO6QziQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Fit the ensemble model\n",
        "    ensemble_model.fit(ensemble_X_train, y_train_ensemble)\n",
        "\n",
        "    print(\"Shape of ensemble_X_train:\", ensemble_X_train.shape)\n",
        "    print(\"Length of y_train_ensemble:\", len(y_train_ensemble))\n",
        "except Exception as e:\n",
        "    print(f\"Error during ensemble model fitting: {e}\")\n"
      ],
      "metadata": {
        "id": "H591rKuVQ3mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Import KFold for cross-validation\n",
        "    from sklearn.model_selection import KFold\n",
        "except Exception as e:\n",
        "    print(f\"Error during KFold import: {e}\")\n"
      ],
      "metadata": {
        "id": "o0tawLt7Q7m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    def evaluate_model(model, X, y, cv=5):\n",
        "        \"\"\"\n",
        "        Evaluate the performance of a predictive model.\n",
        "\n",
        "        Parameters:\n",
        "        - model: The predictive model to be evaluated.\n",
        "        - X: The input features for evaluation.\n",
        "        - y: The target variables for evaluation.\n",
        "        - cv: Number of cross-validation folds.\n",
        "\n",
        "        Returns:\n",
        "        A dictionary containing evaluation metrics.\n",
        "        \"\"\"\n",
        "        kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
        "\n",
        "        # Initialize evaluation metrics\n",
        "        mse_5fold = []\n",
        "        mse_10fold = []\n",
        "        r2_scores = []\n",
        "\n",
        "        # Loop through each target variable\n",
        "        for i in range(y.shape[1]):\n",
        "            # Initialize scores\n",
        "            mse_5fold_i = []\n",
        "            mse_10fold_i = []\n",
        "            r2_scores_i = []\n",
        "\n",
        "            # Perform cross-validation\n",
        "            for train_idx, test_idx in kf.split(X):\n",
        "                X_train_fold, X_test_fold = X[train_idx], X[test_idx]\n",
        "                y_train_fold, y_test_fold = y[train_idx, i], y[test_idx, i]\n",
        "\n",
        "                # Fit the model\n",
        "                model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "                # Predict on the test fold\n",
        "                y_pred_fold = model.predict(X_test_fold)\n",
        "\n",
        "                # Calculate MSE\n",
        "                mse_fold = mean_squared_error(y_test_fold, y_pred_fold)\n",
        "                if len(mse_5fold_i) < 5:\n",
        "                    mse_5fold_i.append(mse_fold)\n",
        "                mse_10fold_i.append(mse_fold)\n",
        "\n",
        "                # R-squared score\n",
        "                r2_fold = r2_score(y_test_fold, y_pred_fold)\n",
        "                r2_scores_i.append(r2_fold)\n",
        "\n",
        "            # Average scores over folds\n",
        "            mse_5fold.append(np.mean(mse_5fold_i))\n",
        "            mse_10fold.append(np.mean(mse_10fold_i))\n",
        "            r2_scores.append(np.mean(r2_scores_i))\n",
        "\n",
        "        return {\n",
        "            '5-Fold Cross-Validation MSE': mse_5fold,\n",
        "            '10-Fold Cross-Validation MSE': mse_10fold,\n",
        "            'R-squared Score': r2_scores\n",
        "        }\n",
        "except Exception as e:\n",
        "    print(f\"Error during model evaluation function definition: {e}\")\n"
      ],
      "metadata": {
        "id": "__B8-aEQQ_h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'Prediction1', 'Prediction2', 'Prediction3', 'Prediction4' are your target variable names\n",
        "# and 'df' is your DataFrame\n",
        "\n",
        "# Step 1: Check data types of keys\n",
        "row_keys = ['Prediction1', 'Prediction2', 'Prediction3', 'Prediction4']\n",
        "row_keys_data_types = [type(key) for key in row_keys]\n",
        "print(\"Data types of keys:\", row_keys_data_types)\n",
        "\n",
        "# Step 2: Convert keys to int if needed\n",
        "try:\n",
        "    row_keys_as_int = [int(key[10:]) for key in row_keys]\n",
        "except ValueError as e:\n",
        "    print(f\"Error converting keys to int: {e}\")\n",
        "    # Handle the error as needed\n",
        "\n",
        "# Step 3: Check data type of the index\n",
        "try:\n",
        "    index_data_type = type(df.index[0])\n",
        "except IndexError as e:\n",
        "    print(f\"Error accessing index: {e}\")\n",
        "    # Handle the error as needed\n",
        "\n",
        "print(\"Data type of the index:\", index_data_type)\n"
      ],
      "metadata": {
        "id": "NLX-QA-kpbh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Check for missing or invalid values in the index\n",
        "try:\n",
        "    missing_values = df.index.isnull().sum()  # Check for NaN values\n",
        "    invalid_values = df.index[~df.index.isin(row_keys_as_int)]  # Check for values not in keys_as_int\n",
        "except Exception as e:\n",
        "    print(f\"Error checking index values: {e}\")\n",
        "    # Handle the error as needed\n",
        "\n",
        "# Step 5: Convert index values to integers\n",
        "try:\n",
        "    df.index = df.index.astype(int)\n",
        "except Exception as e:\n",
        "    print(f\"Error converting index values to integers: {e}\")\n",
        "    # Handle the error as needed\n",
        "\n",
        "print(\"Number of missing values in the index:\", missing_values)\n",
        "print(\"Invalid values in the index:\", invalid_values)\n"
      ],
      "metadata": {
        "id": "Qe6SFGSHrCTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Evaluate the ensemble model\n",
        "    ensemble_evaluation = evaluate_model(ensemble_model, ensemble_X_train, y_train.iloc[:, :2])\n",
        "\n",
        "    # Display the evaluation metrics\n",
        "    for metric, values in ensemble_evaluation.items():\n",
        "        print(f\"{metric}: {values}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during ensemble model evaluation: {e}\")\n",
        "\n",
        "    # Print specific rows in y_train using the problematic indices\n",
        "    if isinstance(e, tuple) and len(e) == 2 and isinstance(e[0], np.ndarray) and e[1] == 0:\n",
        "        problematic_indices = e[0]\n",
        "        problematic_rows = y_train.iloc[problematic_indices[0], :2]\n",
        "        print(\"Problematic Rows in y_train:\")\n",
        "        print(problematic_rows)\n",
        "\n",
        "    else:\n",
        "        print(\"Unable to retrieve problematic rows. Check the error type and message.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IcV5HPTgRGch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Step 1: Initial Training with warm_start\n",
        "    # Train the RandomForestRegressor with a small number of trees using placeholder values\n",
        "    # Adjust the number of trees and other hyperparameters as needed\n",
        "    rf_model.fit(X_train, y_train.iloc[:, 0])\n",
        "\n",
        "    # Evaluate its performance on the test set\n",
        "    y_pred_initial = rf_model.predict(X_test.iloc[:, :20])  # Assuming the first target variable is Prediction1\n",
        "    mse_initial = mean_squared_error(y_test.iloc[:, 0], y_pred_initial)\n",
        "    print(\"Mean Squared Error after Initial Training:\", mse_initial)\n",
        "except Exception as e:\n",
        "    print(f\"Error during initial training and evaluation: {e}\")\n"
      ],
      "metadata": {
        "id": "syVSU2AaRL1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Step 2: Transition to Two-Step Approach\n",
        "    # Randomize the placeholder values for each target variable\n",
        "    y_train_randomized = y_train.apply(np.random.permutation, axis=0)\n",
        "\n",
        "    # Train the models on the randomized values\n",
        "    rf_model.fit(X_train, y_train_randomized.iloc[:, 0])\n",
        "    xgb_model.fit(X_train, y_train_randomized.iloc[:, 1])\n",
        "\n",
        "    # Evaluate their performance on the test set\n",
        "    y_pred_rf_randomized = rf_model.predict(X_test.iloc[:, :20])  # Assuming the first target variable is Prediction1\n",
        "    y_pred_xgb_randomized = xgb_model.predict(X_test)\n",
        "    mse_rf_randomized = mean_squared_error(y_test.iloc[:, 0], y_pred_rf_randomized)\n",
        "    mse_xgb_randomized = mean_squared_error(y_test.iloc[:, 1], y_pred_xgb_randomized)\n",
        "    print(\"Mean Squared Error after Training with Randomized Placeholders (RF):\", mse_rf_randomized)\n",
        "    print(\"Mean Squared Error after Training with Randomized Placeholders (XGB):\", mse_xgb_randomized)\n",
        "except Exception as e:\n",
        "    print(f\"Error during training with randomized placeholders and evaluation: {e}\")\n"
      ],
      "metadata": {
        "id": "viGKrIXaRV51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Step 3: Fine-Tuning with Actual Target Variables\n",
        "    # Fine-tune the models using the actual values\n",
        "    rf_model.fit(X_train, y_train.iloc[:, 0])\n",
        "    xgb_model.fit(X_train, y_train.iloc[:, 1])\n",
        "\n",
        "    # Evaluate their final performance on the test set\n",
        "    y_pred_rf_final = rf_model.predict(X_test.iloc[:, :20])  # Assuming the first target variable is Prediction1\n",
        "    y_pred_xgb_final = xgb_model.predict(X_test)\n",
        "    mse_rf_final = mean_squared_error(y_test.iloc[:, 0], y_pred_rf_final)\n",
        "    mse_xgb_final = mean_squared_error(y_test.iloc[:, 1], y_pred_xgb_final)\n",
        "    print(\"Mean Squared Error after Fine-Tuning with Actual Target Variables (RF):\", mse_rf_final)\n",
        "    print(\"Mean Squared Error after Fine-Tuning with Actual Target Variables (XGB):\", mse_xgb_final)\n",
        "except Exception as e:\n",
        "    print(f\"Error during fine-tuning and final evaluation: {e}\")\n"
      ],
      "metadata": {
        "id": "tYQVDJA0Ra5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "id": "8thy2j3kRfcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'Prediction1', 'Prediction2', 'Prediction3', 'Prediction4' are your target variable names\n",
        "# and 'df' is your DataFrame\n",
        "\n",
        "# Step 1: Check data types of keys\n",
        "row_keys = ['Prediction1', 'Prediction2', 'Prediction3', 'Prediction4']\n",
        "row_keys_data_types = [type(key) for key in row_keys]\n",
        "print(\"Data types of keys:\", row_keys_data_types)\n",
        "\n",
        "# Step 2: Check data type of the index\n",
        "index_data_type = type(df.index[0])\n",
        "print(\"Data type of the index:\", index_data_type)\n"
      ],
      "metadata": {
        "id": "wakaDGanf8nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncLrqNGpewW7"
      },
      "outputs": [],
      "source": [
        "# Define a function for model evaluations\n",
        "def evaluate_model(model, X, y, cv=5):\n",
        "    # Ensure the model is fitted\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Initialize evaluation metrics\n",
        "    mse_5fold = []\n",
        "    mse_10fold = []\n",
        "    r2_scores = []\n",
        "\n",
        "    # Loop through each target variable\n",
        "    for i in range(y.shape[1]):\n",
        "        # 5-fold cross-validation\n",
        "        scores_5fold = cross_val_score(model, X, y.iloc[:, i], cv=cv, scoring='neg_mean_squared_error')\n",
        "        mse_5fold.append(-scores_5fold.mean())\n",
        "\n",
        "        # 10-fold cross-validation\n",
        "        scores_10fold = cross_val_score(model, X, y.iloc[:, i], cv=10, scoring='neg_mean_squared_error')\n",
        "        mse_10fold.append(-scores_10fold.mean())\n",
        "\n",
        "        # Ensure the model is fitted\n",
        "        model.fit(X, y.iloc[:, i])\n",
        "\n",
        "        # R-squared score\n",
        "        y_pred = model.predict(X)\n",
        "        r2 = r2_score(y.iloc[:, i], y_pred)\n",
        "        r2_scores.append(r2)\n",
        "\n",
        "    return {\n",
        "        '5-Fold Cross-Validation MSE': mse_5fold,\n",
        "        '10-Fold Cross-Validation MSE': mse_10fold,\n",
        "        'R-squared Score': r2_scores\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBppTfwRO5zi"
      },
      "outputs": [],
      "source": [
        "# Fit the ensemble model\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the ensemble model\n",
        "ensemble_evaluation = evaluate_model(ensemble_model, X_train, y_train)\n",
        "\n",
        "# Display the evaluation metrics\n",
        "for metric, values in ensemble_evaluation.items():\n",
        "    print(f\"{metric}: {values}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Fp8fYgYWRFM"
      },
      "outputs": [],
      "source": [
        "# Evaluate the ensemble model\n",
        "evaluation_results = evaluate_model(ensemble_model, X_train, y_train)\n",
        "\n",
        "# Access the results from the evaluation\n",
        "mse_5fold = evaluation_results['5-Fold Cross-Validation MSE']\n",
        "mse_10fold = evaluation_results['10-Fold Cross-Validation MSE']\n",
        "r2_scores = evaluation_results['R-squared Score']\n",
        "\n",
        "# Display the results\n",
        "for i in range(len(mse_5fold)):\n",
        "    print(f\"Target Variable {i + 1}:\")\n",
        "    print(f\"5-Fold Cross-Validation MSE: {mse_5fold[i]}\")\n",
        "    print(f\"10-Fold Cross-Validation MSE: {mse_10fold[i]}\")\n",
        "    print(f\"R-squared Score: {r2_scores[i]}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of the predictions array\n",
        "print(\"Shape of predictions array:\", ensemble_model.predict(X_train).shape)\n"
      ],
      "metadata": {
        "id": "0w9Vzqvs7UnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1.1: Analyze Predictions and Visualize Results\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def analyze_predictions(model, X, y):\n",
        "    predictions = model.predict(X)\n",
        "\n",
        "    # Check if predictions are 1-dimensional\n",
        "    if len(predictions.shape) == 1:\n",
        "        predictions = predictions.reshape(-1, 1)\n",
        "\n",
        "    print(\"Shapes - y:\", y.shape, \"predictions:\", predictions.shape)  # Add this line for debugging\n",
        "\n",
        "    # Create subplots for each target variable\n",
        "    n_targets = y.shape[1]\n",
        "    n_subplots = min(n_targets * 2, 8)  # Limit to 8 subplots for better visualization\n",
        "    fig, axes = plt.subplots(nrows=n_subplots // 2, ncols=2, figsize=(15, 5 * (n_subplots // 2)))\n",
        "\n",
        "    # Flatten the axes array to handle the case of one target variable\n",
        "    axes = np.array(axes).flatten()\n",
        "\n",
        "    # Loop through each target variable\n",
        "    for i in range(n_targets):\n",
        "        # Check if there are available subplots\n",
        "        if i * 2 < n_subplots:\n",
        "            # Plot predicted vs. actual values\n",
        "            axes[i * 2].scatter(y.iloc[:, i], predictions[:, i], alpha=0.5)\n",
        "            axes[i * 2].set_title(f'Target Variable {i + 1}: Predicted vs. Actual')\n",
        "            axes[i * 2].set_xlabel('Actual Values')\n",
        "            axes[i * 2].set_ylabel('Predicted Values')\n",
        "\n",
        "        # Check if there are available subplots for residuals\n",
        "        if i * 2 + 1 < n_subplots:\n",
        "            # Plot residuals\n",
        "            residuals = y.iloc[:, i] - predictions[:, i]\n",
        "            axes[i * 2 + 1].scatter(predictions[:, i], residuals, alpha=0.5)\n",
        "            axes[i * 2 + 1].set_title(f'Target Variable {i + 1}: Residuals Plot')\n",
        "            axes[i * 2 + 1].set_xlabel('Predicted Values')\n",
        "            axes[i * 2 + 1].set_ylabel('Residuals')\n",
        "            axes[i * 2 + 1].axhline(y=0, color='red', linestyle='--')  # Add horizontal line at y=0\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function with your ensemble model and training data\n",
        "analyze_predictions(ensemble_model, X_train, y_train)\n"
      ],
      "metadata": {
        "id": "_dqBhRkAnp3u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6dNBGSfQPr2Mt/bgLh5uD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}